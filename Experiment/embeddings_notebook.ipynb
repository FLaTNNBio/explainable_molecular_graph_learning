{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtVle8RHNqON"
      },
      "source": [
        "# Installation and Common Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLTzxU_DNzLi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install pysmiles\n",
        "  !pip install git+https://github.com/VenkateshwaranB/stellargraph.git\n",
        "  !pip install rdkit\n",
        "  !pip install torch_geometric\n",
        "  !pip install datasets\n",
        "  !pip3 install mxnet-mkl==1.6.0 numpy==1.23.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcuv1AHaNqOR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stellargraph import datasets\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv8jU7ilW-6t"
      },
      "outputs": [],
      "source": [
        "!pip install ogb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you run on colab"
      ],
      "metadata": {
        "id": "LwlFi6nUSOyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2IcVbx3jwCr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C1O3XD3xibZ"
      },
      "source": [
        "###Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download the HIV Dataset from OGBG"
      ],
      "metadata": {
        "id": "i1ACg7kHSR34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjfW3Bz-qAr-"
      },
      "outputs": [],
      "source": [
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
        "\n",
        "#qua sta anche clintox e altri vedere bene documntazione però il codice funziona anche con uun proprio dataset, però il clintox ha la y diversa dalla nostra quindi in molti casi conviene avere a che fare con db propri, dove settiamo noi la y per bene e usiamo lo script SMILEs-MOL-OGB\n",
        "all_data = dataset[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load experimental .pt dataset: Choose pre-processed *dataset.pt* (clintox.pt,bace_classification.pt,bbbp.pt) from Experiments/exp_datasets and replace the path *content/exp_dataset/dataset.pt* with the choosen dataset."
      ],
      "metadata": {
        "id": "o2wNm_oISWgA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4sCu2-XWLin"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch_geometric\n",
        "# Load Data object from file\n",
        "with open('content/exp_dataset/dataset.pt', 'rb') as f:\n",
        "    all_data = pickle.load(f)\n",
        "\n",
        "# Now loaded_data contains the Data object\n",
        "print(all_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create NetworkX graph"
      ],
      "metadata": {
        "id": "5P8z0ytkLFpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzQS4IfKzcC9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import stellargraph as sg\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "from stellargraph.data import BiasedRandomWalk\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, features=node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, attributes=edge_attributes)\n",
        "\n",
        "    return G, y.item()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
        "    \"\"\"\n",
        "    Plots the confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (list or array): True labels.\n",
        "    y_pred (list or array): Predicted labels.\n",
        "    class_names (list): List of class names. If None, integer labels are used.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# y_true = [0, 1, 1, 0, 1, 0]\n",
        "# y_pred = [0, 1, 0, 0, 1, 1]\n",
        "# class_names = ['Class 0', 'Class 1']\n",
        "# plot_confusion_matrix(y_true, y_pred, class_names)\n"
      ],
      "metadata": {
        "id": "e_Ix2PETlKT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZBWOStOXUU8"
      },
      "source": [
        "#Node2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxkjURhnXcIv"
      },
      "source": [
        "Construction of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I_OdnXOCqE8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import copy\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "label_0_indices = []\n",
        "label_1_indices = []\n",
        "dfs = []\n",
        "\n",
        "for i in range(len(all_data)):\n",
        "  if all_data[i].y == 0:\n",
        "    label_0_indices.append(i)\n",
        "  elif all_data[i].y == 1:\n",
        "    label_1_indices.append(i)\n",
        "\n",
        "for iter in range(1):\n",
        "  print('iter:', iter)\n",
        "\n",
        "  min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "  random.shuffle(label_0_indices)\n",
        "  random.shuffle(label_1_indices)\n",
        "  label_0_indices = label_0_indices[:min_size_dataset]\n",
        "  label_1_indices = label_1_indices[:min_size_dataset]\n",
        "  print('size 0 data:' , len(label_0_indices))\n",
        "  print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "  balanced_indices = label_0_indices + label_1_indices\n",
        "  print('size total dataset:' , len(balanced_indices))\n",
        "\n",
        "  balanced_data = [all_data[i] for i in balanced_indices]\n",
        "  print(len(balanced_data))\n",
        "\n",
        "  df = pd.DataFrame(columns = ['emb','label'])\n",
        "\n",
        "  for dtb in balanced_data:\n",
        "    graph,y = create_networkx_graph(dtb.edge_index, dtb.edge_attr, dtb.x, dtb.y, dtb.num_nodes)\n",
        "        # Convert node features to DataFrame\n",
        "    node_features_dict = {node: graph.nodes[node]['features'] for node in graph.nodes}\n",
        "    node_df = pd.DataFrame.from_dict(node_features_dict, orient='index')\n",
        "\n",
        "        # Convert edge attributes to DataFrame\n",
        "    edge_features_dict = {(src, dst): data['attributes'] for src, dst, data in graph.edges(data=True)}\n",
        "    edge_df = pd.DataFrame.from_dict(edge_features_dict, orient='index')\n",
        "\n",
        "        # Create 'source', 'target' columns in the edge DataFrame\n",
        "    edge_df['source'] = [edge[0] for edge in edge_df.index]\n",
        "    edge_df['target'] = [edge[1] for edge in edge_df.index]\n",
        "\n",
        "        # Create a StellarGraph from the NetworkX graph and DataFrames\n",
        "    Gs = sg.StellarGraph(nodes=node_df, edges=edge_df)\n",
        "\n",
        "    rw = BiasedRandomWalk(Gs)\n",
        "\n",
        "    walks = rw.run(\n",
        "        nodes=list(Gs.nodes()),  # root nodes\n",
        "        length=100,  # maximum length of a random walk\n",
        "        n=10,  # number of random walks per root node\n",
        "        p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
        "        q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
        "        weighted=True,\n",
        "        seed = 42\n",
        "    )\n",
        "\n",
        "    str_walks = [[str(n) for n in walk] for walk in walks]\n",
        "    model = Word2Vec(str_walks, window=5, min_count=0, sg=1, workers=2)\n",
        "\n",
        "        # Retrieve node embeddings and corresponding subjects\n",
        "    node_ids = model.wv.index_to_key  # list of node IDs\n",
        "    node_embeddings = (\n",
        "        model.wv.vectors\n",
        "    )  # numpy.ndarray of size number of nodes times embeddings dimensionality\n",
        "\n",
        "    df.loc[len(df)] = [node_embeddings, y]\n",
        "  #df.to_pickle('/content/drive/MyDrive/emb_bbbp_node2vec_data_' + str(iter + 1) + '.pkl')\n",
        "  #print(df)\n",
        "  dfs.append(df)\n",
        "  #se va tutto bene poi questo break si toglie e si fa per tuti i kfold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Udl-HSNsLnu"
      },
      "source": [
        "Creation of the Model for classification on the Embedding data given from node2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMg83xsGuhn7"
      },
      "outputs": [],
      "source": [
        "# Define a function to create and compile your model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def create_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(222, 100)),\n",
        "    layers.Dropout(0.3),  # Adding dropout for regularization\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),  # Adding dropout for regularization\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.3),  # Adding dropout for regularization\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVeC_w4UsjDq"
      },
      "source": [
        "5 k-fold on 5 datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AvjMtzYbuJxl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize dictionary to store best models and their performances\n",
        "best_models = {}\n",
        "\n",
        "for df_idx, df in enumerate(dfs):\n",
        "    best_accuracy = 0\n",
        "    best_model = None\n",
        "\n",
        "    # Prepare data\n",
        "    X_emb = pad_sequences(df['emb'], dtype='float32', padding='post')\n",
        "    y = np.array(df['label'])\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(kf.split(X_emb)):\n",
        "        X_emb_train, X_emb_val = X_emb[train_index], X_emb[val_index]\n",
        "        y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "        model = create_model()\n",
        "        print(len((y_train.reshape(-1, 1))))\n",
        "        history = model.fit(X_emb_train, y_train.reshape(-1, 1), epochs=100, batch_size=32, validation_data=(X_emb_val, y_val.reshape(-1, 1)))\n",
        "\n",
        "        # Evaluate model performance\n",
        "        _, accuracy = model.evaluate(X_emb_val, y_val)\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    # Save the best model for this dataset\n",
        "    best_models[f'df_{df_idx}'] = best_model\n",
        "    print(f\"Best accuracy for dataset {df_idx}: {best_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFwkcgJmoUv3"
      },
      "outputs": [],
      "source": [
        "for idx, (name, model) in enumerate(best_models.items()):\n",
        "    model.save(f'/content/drive/MyDrive/best_model_bbbp{name}.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DIvTuGoETnp"
      },
      "source": [
        "load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9QKaH5dESs-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "best_models = []\n",
        "for cnt in range(5):\n",
        "  best_models.append(load_model('/content/drive/MyDrive/best_model_bbbpdf_' + str(cnt) + '.h5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0LqXD5WXxTc"
      },
      "source": [
        "Evaluating the performances of the best models using ROC\n",
        "fare file log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EVM5KRu---_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Open a file to write the results, modify path if you are in local\n",
        "with open(\"/content/drive/MyDrive/metrics_results_bbbp_models.txt\", \"w\") as file:\n",
        "\n",
        "    # Loop through best models\n",
        "    for idx, model in enumerate(best_models):\n",
        "        file.write(f\"\\nModel {idx + 1}\\n\")\n",
        "\n",
        "        df = dfs[idx]\n",
        "        X_emb = pad_sequences(df['emb'], dtype='float32', padding='post')\n",
        "        y = np.array(df['label'])\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        X_emb_train, X_emb_test, y_train, y_test = train_test_split(X_emb, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "        # Pad sequences if necessary\n",
        "        X_emb_train = pad_sequences(X_emb_train, dtype='float32', padding='post')\n",
        "        X_emb_test = pad_sequences(X_emb_test, dtype='float32', padding='post')\n",
        "\n",
        "        # Reshape labels if necessary\n",
        "        y_train_reshaped = y_train.reshape(-1, 1)\n",
        "        y_test_reshaped = y_test.reshape(-1, 1)\n",
        "\n",
        "        # predict probabilities for test set\n",
        "        yhat_probs = model.predict(X_emb_test, verbose=0)\n",
        "        # predict crisp classes for test set\n",
        "        y_classes = np.argmax(yhat_probs, axis=1)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_classes)\n",
        "        precision = precision_score(y_test, y_classes, labels=[1] , average = 'weighted')\n",
        "        recall = recall_score(y_test, y_classes, labels=[1], average = 'weighted')\n",
        "        f1 = f1_score(y_test, y_classes, labels=[1], average = 'weighted')\n",
        "        conf_matrix = confusion_matrix(y_test, y_classes)\n",
        "\n",
        "        file.write(\"Accuracy: {}\\n\".format(accuracy))\n",
        "        file.write(\"Precision: {}\\n\".format(precision))\n",
        "        file.write(\"Recall: {}\\n\".format(recall))\n",
        "        file.write(\"F1 Score: {}\\n\".format(f1))\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        roc_auc = roc_auc_score(y_test, y_classes)\n",
        "        file.write(\"ROC AUC: {}\\n\".format(roc_auc))\n",
        "\n",
        "        # Plot ROC curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_classes)\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic (ROC)')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.savefig(\"ROC_Model{}.png\".format(idx + 1))  # Save ROC curve plot\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plot_confusion_matrix(y_test, y_classes, class_names=['Class 0', 'Class 1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOsT4DIMB35f"
      },
      "source": [
        "Integrated Gradients - on the classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb4mR4N3mhhi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def integrated_gradients(input_data, model):\n",
        "    \"\"\"\n",
        "    Calculate integrated gradients for a given input_data and model\n",
        "    \"\"\"\n",
        "    # Define the baseline as all zeros\n",
        "    baseline = np.zeros_like(input_data)\n",
        "\n",
        "    # Create a linear interpolation path from baseline to the actual input\n",
        "    steps = 50\n",
        "    interpolated_points = [baseline + (i/steps) * (input_data - baseline) for i in range(steps+1)]\n",
        "\n",
        "    # Convert to numpy array\n",
        "    interpolated_points = np.array(interpolated_points)\n",
        "\n",
        "    # Convert to TensorFlow tensor\n",
        "    interpolated_points = tf.convert_to_tensor(interpolated_points, dtype=tf.float32)\n",
        "\n",
        "    # Get model predictions for the interpolated points\n",
        "    preds = model.predict(interpolated_points)\n",
        "\n",
        "    # Create a GradientTape to record operations for automatic differentiation\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_points)\n",
        "        predictions = model(interpolated_points)\n",
        "\n",
        "    # Calculate gradients with respect to input\n",
        "    gradients = tape.gradient(predictions, interpolated_points)\n",
        "\n",
        "    # Define the integrated gradients\n",
        "    integrated_grads = np.mean(gradients.numpy(), axis=0) * (input_data - baseline)\n",
        "\n",
        "    # Sum along the path to approximate the integral\n",
        "    integrated_grads = np.sum(integrated_grads, axis=1)\n",
        "\n",
        "    return integrated_grads\n",
        "\n",
        "# Example usage\n",
        "index_to_explain = 4  # Choose an index to explain\n",
        "embedding_to_explain = X_emb[index_to_explain]\n",
        "integrated_grads_result = integrated_gradients(embedding_to_explain, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1FqpJ0Q-5bR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create an array of indices to use as x-axis\n",
        "indices = np.arange(len(integrated_grads_result))\n",
        "\n",
        "# Filter out non-zero values and their corresponding indices\n",
        "non_zero_indices = [i for i, val in enumerate(integrated_grads_result) if val != 0]\n",
        "non_zero_values = [val for val in integrated_grads_result if val != 0]\n",
        "\n",
        "# Plot non-zero integrated gradients\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(non_zero_indices, non_zero_values, marker='o', linestyle='-', color='b')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Integrated Gradients (Non-zero)')\n",
        "plt.title('Non-zero Integrated Gradients for Explaining Model Prediction')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SDNE"
      ],
      "metadata": {
        "id": "-Bs0fWiRsIlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation for SDNE Experiment"
      ],
      "metadata": {
        "id": "qzDLTttsTF5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch import nn, optim\n",
        "\n",
        "# Assuming 'all_data' is already defined and contains the graph data\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, **node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, **edge_attributes)\n",
        "\n",
        "    return G, y.item()\n",
        "\n",
        "class SDNE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, alpha=1e-5, beta=5):\n",
        "        super(SDNE, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dims[1], hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # Encode\n",
        "        y = self.encoder(x)\n",
        "        # Decode\n",
        "        x_hat = self.decoder(y)\n",
        "        return x_hat, y\n",
        "\n",
        "    def loss_function(self, x, x_hat, y, adj):\n",
        "        # Reconstruction loss\n",
        "        mse = nn.MSELoss()\n",
        "        L_1st = mse(x_hat, x)\n",
        "\n",
        "        # Laplacian regularization\n",
        "        L_2nd = torch.sum(adj * torch.norm(y.unsqueeze(1) - y, dim=2))\n",
        "\n",
        "        return L_1st + self.alpha * L_1st + self.beta * L_2nd\n",
        "\n",
        "def train_sdne(graph, hidden_dims=[128, 64], epochs=100, lr=0.01):\n",
        "    # Create adjacency matrix\n",
        "    adj = nx.adjacency_matrix(graph).todense()\n",
        "    adj = torch.tensor(adj, dtype=torch.float32)\n",
        "\n",
        "    # Get node features\n",
        "    node_features = np.array([list(graph.nodes[i].values()) for i in range(graph.number_of_nodes())])\n",
        "\n",
        "    # Check if node features are empty\n",
        "    if node_features.shape[1] == 0:\n",
        "        raise ValueError(\"Node features are empty. Ensure nodes have features.\")\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    node_features = scaler.fit_transform(node_features)\n",
        "    node_features = torch.tensor(node_features, dtype=torch.float32)\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = node_features.shape[1]\n",
        "    model = SDNE(input_dim, hidden_dims)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, y = model(node_features, adj)\n",
        "        loss = model.loss_function(node_features, x_hat, y, adj)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #if (epoch + 1) % 10 == 0:\n",
        "            #print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    return model, y\n",
        "\n",
        "def balance_dataset(all_data, seed=42):\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    label_0_indices = [i for i, data in enumerate(all_data) if data.y.item() == 0]\n",
        "    label_1_indices = [i for i, data in enumerate(all_data) if data.y.item() == 1]\n",
        "\n",
        "    min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "    random.shuffle(label_0_indices)\n",
        "    random.shuffle(label_1_indices)\n",
        "\n",
        "    label_0_indices = label_0_indices[:min_size_dataset]\n",
        "    label_1_indices = label_1_indices[:min_size_dataset]\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    balanced_indices = label_0_indices + label_1_indices\n",
        "    random.shuffle(balanced_indices)\n",
        "\n",
        "    balanced_data = [all_data[i] for i in balanced_indices]\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "# Generate and save embeddings for the balanced datasets\n",
        "if __name__ == \"__main__\":\n",
        "    all_graph_embeddings = []\n",
        "\n",
        "    for i in range(1):  # Loop to generate 5 different datasets\n",
        "        print(f'Generating dataset {i + 1}')\n",
        "        balanced_data = balance_dataset(all_data)\n",
        "\n",
        "        for data in balanced_data:\n",
        "            num_nodes = data.num_nodes\n",
        "            edge_index = data.edge_index\n",
        "            edge_attr = data.edge_attr\n",
        "            x = data.x\n",
        "            y = data.y\n",
        "\n",
        "            # Create graph\n",
        "            G, y_label = create_networkx_graph(edge_index, edge_attr, x, y, num_nodes)\n",
        "\n",
        "            # Train SDNE\n",
        "            model, embeddings = train_sdne(G, epochs=100)\n",
        "\n",
        "            # Collect node embeddings and aggregate them to obtain a graph-level embedding\n",
        "            embeddings_np = embeddings.detach().numpy()\n",
        "            graph_embedding = np.mean(embeddings_np, axis=0)  # Averaging node embeddings\n",
        "            all_graph_embeddings.append((graph_embedding.tolist(), y_label))\n",
        "\n",
        "    # Convert graph-level embeddings to DataFrame\n",
        "    df_graph_embeddings = pd.DataFrame(all_graph_embeddings, columns=[\"embedding\", \"label\"])\n",
        "\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df_graph_embeddings)\n"
      ],
      "metadata": {
        "id": "xxLnsdjK-Y2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import ast\n",
        "\n",
        "\n",
        "# Extract features and labels\n",
        "def extract_features_labels(df):\n",
        "    embeddings = []\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    for emb in df['embedding']:\n",
        "        if isinstance(emb, str):\n",
        "            # Convert string representation of list back to list\n",
        "            emb = ast.literal_eval(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n",
        "\n",
        "X, y = extract_features_labels(df_graph_embeddings)\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "    raise ValueError(\"No valid embeddings found. Please check the DataFrame for formatting issues.\")\n",
        "\n",
        "# Define the neural network model\n",
        "def create_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Perform 5-fold cross-validation on the entire dataset\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "roc_aucs = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "histories = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f'Fold {fold_no}')\n",
        "\n",
        "    X_train_val, X_test = X[train_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Perform an additional split to get a validation set from the training+validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Create and train the neural network\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = create_model(input_dim)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy:.4f}')\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    histories.append(history.history)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Fold {fold_no} Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Predict probabilities and calculate metrics for the test set\n",
        "    y_test_pred_proba = model.predict(X_test).flatten()\n",
        "    y_test_pred = (y_test_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f'Fold {fold_no} ROC-AUC: {roc_auc:.4f}')\n",
        "    print(f'Fold {fold_no} Precision: {precision:.4f}')\n",
        "    print(f'Fold {fold_no} Recall: {recall:.4f}')\n",
        "    print(f'Fold {fold_no} F1-Score: {f1:.4f}')\n",
        "\n",
        "    roc_aucs.append(roc_auc)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Plot confusion matrix for each fold\n",
        "    plot_confusion_matrix(y_test, y_test_pred, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Calculate and print the average validation accuracy and variance\n",
        "average_val_accuracy = np.mean(val_accuracies)\n",
        "variance_val_accuracy = np.var(val_accuracies)\n",
        "print(f'Average Validation Accuracy: {average_val_accuracy:.4f}')\n",
        "print(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}')\n",
        "\n",
        "# Calculate and print the average test accuracy and variance\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "variance_test_accuracy = np.var(test_accuracies)\n",
        "print(f'Average Test Accuracy: {average_test_accuracy:.4f}')\n",
        "print(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}')\n",
        "\n",
        "# Calculate and print the average ROC-AUC, Precision, Recall, and F1-Score\n",
        "average_roc_auc = np.mean(roc_aucs)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recall = np.mean(recalls)\n",
        "average_f1_score = np.mean(f1_scores)\n",
        "\n",
        "print(f'Average ROC-AUC: {average_roc_auc:.4f}')\n",
        "print(f'Average Precision: {average_precision:.4f}')\n",
        "print(f'Average Recall: {average_recall:.4f}')\n",
        "print(f'Average F1-Score: {average_f1_score:.4f}')\n",
        "\n",
        "# Save the average validation accuracy, variance, test accuracy, and metrics to a file\n",
        "with open(\"model_accuracies.txt\", \"w\") as f:\n",
        "    f.write(f'Average Validation Accuracy: {average_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Average Test Accuracy: {average_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Average ROC-AUC: {average_roc_auc:.4f}\\n')\n",
        "    f.write(f'Average Precision: {average_precision:.4f}\\n')\n",
        "    f.write(f'Average Recall: {average_recall:.4f}\\n')\n",
        "    f.write(f'Average F1-Score: {average_f1_score:.4f}\\n')\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Save training history for each fold (optional)\n",
        "with open(\"training_histories.txt\", \"w\") as f:\n",
        "    for i, history in enumerate(histories):\n",
        "        f.write(f'\\nFold {i + 1} History:\\n')\n",
        "        f.write(str(history))\n"
      ],
      "metadata": {
        "id": "EAqVMiFSQA_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HOPE"
      ],
      "metadata": {
        "id": "oNeNbrv3xjgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation for HOPE Experiment"
      ],
      "metadata": {
        "id": "a9AV-8VNTfS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, **node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, **edge_attributes)\n",
        "\n",
        "    return G, y.item()\n",
        "\n",
        "def balance_dataset(all_data, seed=42):\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    label_0_indices = [i for i, data in enumerate(all_data) if data.y.item() == 0]\n",
        "    label_1_indices = [i for i, data in enumerate(all_data) if data.y.item() == 1]\n",
        "\n",
        "    min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "    random.shuffle(label_0_indices)\n",
        "    random.shuffle(label_1_indices)\n",
        "\n",
        "    label_0_indices = label_0_indices[:min_size_dataset]\n",
        "    label_1_indices = label_1_indices[:min_size_dataset]\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    balanced_indices = label_0_indices + label_1_indices\n",
        "    random.shuffle(balanced_indices)\n",
        "\n",
        "    balanced_data = [all_data[i] for i in balanced_indices]\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "def compute_hope_embedding(G, d=128, beta=0.01):\n",
        "    # Create adjacency matrix\n",
        "    A = nx.to_numpy_array(G)\n",
        "\n",
        "    # Compute the Katz similarity matrix\n",
        "    I = np.eye(A.shape[0])\n",
        "    S = np.linalg.inv(I - beta * A) - I\n",
        "\n",
        "    # Ensure k is valid for SVD\n",
        "    k = min(d // 2, min(S.shape) - 1)\n",
        "\n",
        "    if k <= 0:\n",
        "        # If k is invalid, return trivial embeddings\n",
        "        return np.zeros((S.shape[0], d))\n",
        "\n",
        "    # Compute SVD\n",
        "    U, s, Vt = svds(S, k=k)\n",
        "    S_sqrt = np.diag(np.sqrt(s))\n",
        "    X1 = np.dot(U, S_sqrt)\n",
        "    X2 = np.dot(Vt.T, S_sqrt)\n",
        "    X = np.concatenate((X1, X2), axis=1)\n",
        "\n",
        "    # Ensure the final embedding dimension matches d\n",
        "    if X.shape[1] < d:\n",
        "        X = np.pad(X, ((0, 0), (0, d - X.shape[1])), 'constant')\n",
        "    elif X.shape[1] > d:\n",
        "        X = X[:, :d]\n",
        "\n",
        "    return X\n",
        "\n",
        "# Generate and save embeddings for the balanced datasets\n",
        "if __name__ == \"__main__\":\n",
        "    all_graph_embeddings = []\n",
        "\n",
        "    for i in range(1):  # Loop to generate embeddings from 5 different balanced datasets\n",
        "        print(f'Generating embeddings for dataset {i + 1}')\n",
        "        balanced_data = balance_dataset(all_data)\n",
        "\n",
        "        for data in balanced_data:\n",
        "            num_nodes = data.num_nodes\n",
        "            edge_index = data.edge_index\n",
        "            edge_attr = data.edge_attr\n",
        "            x = data.x\n",
        "            y = data.y\n",
        "\n",
        "            # Create graph\n",
        "            G, y_label = create_networkx_graph(edge_index, edge_attr, x, y, num_nodes)\n",
        "\n",
        "            # Compute HOPE embeddings\n",
        "            embeddings = compute_hope_embedding(G, d=128, beta=0.01)\n",
        "\n",
        "            # Collect node embeddings and aggregate them to obtain a graph-level embedding\n",
        "            graph_embedding = np.mean(embeddings, axis=0)  # Averaging node embeddings\n",
        "            all_graph_embeddings.append((graph_embedding.tolist(), y_label))\n",
        "\n",
        "    # Convert graph-level embeddings to DataFrame\n",
        "    df_graph_embeddings = pd.DataFrame(all_graph_embeddings, columns=[\"embedding\", \"label\"])\n",
        "\n",
        "    # Save the DataFrame to a CSV file (optional)\n",
        "    df_graph_embeddings.to_csv(\"graph_embeddings.csv\", index=False)\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df_graph_embeddings)\n"
      ],
      "metadata": {
        "id": "oEJnUWgaxksk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import ast\n",
        "\n",
        "\n",
        "# Extract features and labels\n",
        "def extract_features_labels(df):\n",
        "    embeddings = []\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    for emb in df['embedding']:\n",
        "        if isinstance(emb, str):\n",
        "            # Convert string representation of list back to list\n",
        "            emb = ast.literal_eval(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n",
        "\n",
        "# Assuming df_graph_embeddings is already defined and loaded\n",
        "X, y = extract_features_labels(df_graph_embeddings)\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "    raise ValueError(\"No valid embeddings found. Please check the DataFrame for formatting issues.\")\n",
        "\n",
        "# Define the neural network model\n",
        "def create_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Perform 5-fold cross-validation on the entire dataset\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "histories = []\n",
        "\n",
        "roc_aucs = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f'Fold {fold_no}')\n",
        "\n",
        "    X_train_val, X_test = X[train_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Perform an additional split to get a validation set from the training+validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Create and train the neural network\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = create_model(input_dim)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy:.4f}')\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    histories.append(history.history)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Fold {fold_no} Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_proba = model.predict(X_test).flatten()\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # Compute and store metrics\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    roc_aucs.append(roc_auc)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Plot confusion matrix for each fold\n",
        "    plot_confusion_matrix(y_test, y_test_pred, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "    print(f'Fold {fold_no} ROC AUC: {roc_auc:.4f}')\n",
        "    print(f'Fold {fold_no} Precision: {precision:.4f}')\n",
        "    print(f'Fold {fold_no} Recall: {recall:.4f}')\n",
        "    print(f'Fold {fold_no} F1-Score: {f1:.4f}')\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Calculate and print the average metrics\n",
        "average_val_accuracy = np.mean(val_accuracies)\n",
        "variance_val_accuracy = np.var(val_accuracies)\n",
        "print(f'Average Validation Accuracy: {average_val_accuracy:.4f}')\n",
        "print(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}')\n",
        "\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "variance_test_accuracy = np.var(test_accuracies)\n",
        "print(f'Average Test Accuracy: {average_test_accuracy:.4f}')\n",
        "print(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}')\n",
        "\n",
        "average_roc_auc = np.mean(roc_aucs)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recall = np.mean(recalls)\n",
        "average_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f'Average ROC AUC: {average_roc_auc:.4f}')\n",
        "print(f'Average Precision: {average_precision:.4f}')\n",
        "print(f'Average Recall: {average_recall:.4f}')\n",
        "print(f'Average F1-Score: {average_f1:.4f}')\n",
        "\n",
        "# Save the average metrics to a file\n",
        "with open(\"model_accuracies.txt\", \"w\") as f:\n",
        "    f.write(f'Average Validation Accuracy: {average_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Average Test Accuracy: {average_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Average ROC AUC: {average_roc_auc:.4f}\\n')\n",
        "    f.write(f'Average Precision: {average_precision:.4f}\\n')\n",
        "    f.write(f'Average Recall: {average_recall:.4f}\\n')\n",
        "    f.write(f'Average F1-Score: {average_f1:.4f}\\n')\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Save training history for each fold (optional)\n",
        "with open(\"training_histories.txt\", \"w\") as f:\n",
        "    for i, history in enumerate(histories):\n",
        "        f.write(f'\\nFold {i + 1} History:\\n')\n",
        "        f.write(str(history))\n"
      ],
      "metadata": {
        "id": "B6Zb2A9Q1QJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GNN"
      ],
      "metadata": {
        "id": "zLayspS9Mv_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg5yiVjbJkkI"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install torch_geometric\n",
        "!pip install ogb\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzzeRkGQJxK3"
      },
      "source": [
        "Model creation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv, GINConv, global_mean_pool, global_add_pool, global_max_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import matplotlib\n",
        "from rdkit import Chem\n",
        "import pickle\n",
        "import torch_geometric\n",
        "import io  # Import io for in-memory file operations\n"
      ],
      "metadata": {
        "id": "LAFwe7CyXxxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cells to define:\n",
        "\n",
        "\n",
        "*   GCN\n",
        "*   GIN\n",
        "*   GAT\n",
        "\n"
      ],
      "metadata": {
        "id": "fGFx9RRaQVHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9dF2Z8uJwPw"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 2)  # Output will be 2 classes\n",
        "\n",
        "        # Register hook on the last layer (conv3)\n",
        "        self.hook_handle = self.conv4.register_forward_hook(self._store_gradients)\n",
        "\n",
        "    def _store_gradients(self, module, input, output):\n",
        "        # Store gradients during forward pass\n",
        "        self.gradients = output\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = global_max_pool(x, batch)  # Global pooling\n",
        "        x = self.lin(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GATConv, global_max_pool\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_channels, heads=1)\n",
        "        self.conv2 = GATConv(hidden_channels, hidden_channels, heads=1)\n",
        "        self.conv3 = GATConv(hidden_channels, hidden_channels, heads=1)\n",
        "        self.conv4 = GATConv(hidden_channels, hidden_channels, heads=1)\n",
        "        self.lin = Linear(hidden_channels, 2)  # Output will be 2 classes\n",
        "\n",
        "        # Register hook on the last layer (conv3)\n",
        "        self.hook_handle = self.conv4.register_forward_hook(self._store_gradients)\n",
        "\n",
        "    def _store_gradients(self, module, input, output):\n",
        "        # Store gradients during forward pass\n",
        "        self.gradients = output\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = global_max_pool(x, batch)  # Global pooling\n",
        "        x = self.lin(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "O4-wM4JmKs1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GINConv, global_max_pool\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_channels):\n",
        "        super(GIN, self).__init__()\n",
        "        self.conv1 = GINConv(Linear(input_dim, hidden_channels))\n",
        "        self.conv2 = GINConv(Linear(hidden_channels, hidden_channels))\n",
        "        self.conv3 = GINConv(Linear(hidden_channels, hidden_channels))\n",
        "        self.conv4 = GINConv(Linear(hidden_channels, hidden_channels))\n",
        "        self.lin = Linear(hidden_channels, 2)  # Output will be 2 classes\n",
        "\n",
        "        # Register hook on the last layer (conv4)\n",
        "        self.hook_handle = self.conv4.register_forward_hook(self._store_gradients)\n",
        "\n",
        "    def _store_gradients(self, module, input, output):\n",
        "        # Store gradients during forward pass\n",
        "        self.gradients = output\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = global_max_pool(x, batch)  # Global pooling\n",
        "        x = self.lin(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "anlkMau5opFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Suw-k2LVJ8Pz"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x.float(), data.edge_index, data.batch)\n",
        "        loss = F.cross_entropy(out, data.y.view(-1).long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += int((pred == data.y.view(-1)).sum())\n",
        "        total += data.y.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            pred = model(data.x.float(), data.edge_index, data.batch)\n",
        "            pred = pred.argmax(dim=1)\n",
        "            correct += int((pred == data.y.view(-1)).sum())\n",
        "            total += data.y.size(0)\n",
        "            all_predictions.extend(pred.tolist())\n",
        "            all_labels.extend(data.y.view(-1).tolist())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy, all_predictions, all_labels\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_roc_auc(model, loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            pred = model(data.x.float(), data.edge_index, data.batch)\n",
        "            all_predictions.extend(pred[:, 1].cpu().numpy())\n",
        "            all_labels.extend(data.y.view(-1).cpu().numpy())\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels, all_predictions)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print('AUC:', roc_auc)\n",
        "    return roc_auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL3saI6HNKux"
      },
      "source": [
        "Methods for train and test the models:\n",
        "\n",
        "\n",
        "*   k fold balance\n",
        "*   k fold no balanced\n",
        "*   scatterfold balanced\n",
        "*   scatterfold no balanced\n",
        "\n",
        "The balance is based on the idea to train the model on a balanced dataset (the same number of elements for classes) or no balanced dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDVFiiQUJ45b"
      },
      "outputs": [],
      "source": [
        "def k_fold_balanced(data, num_classes, hidden_channels, iteration, k_folds, model_choosed):\n",
        "    all_best_train_acc = []\n",
        "    all_best_val_acc = []\n",
        "    all_auc = []\n",
        "    label_0_indices = []\n",
        "    label_1_indices = []\n",
        "    all_best_models = {'model':[], 'val_ACC': [], 'AUC':[]}\n",
        "\n",
        "    for i in range(len(data)):\n",
        "      if data[i].y == 0:\n",
        "        label_0_indices.append(i)\n",
        "      elif data[i].y == 1:\n",
        "        label_1_indices.append(i)\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    for iter in range(iteration):\n",
        "      all_data = copy.deepcopy(data)\n",
        "      print('iter:', iter)\n",
        "      # Define cross-validation settings\n",
        "      kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "      best_train_accuracies = []\n",
        "      best_val_accuracies = []\n",
        "      best_models = []\n",
        "\n",
        "      # Collect evaluation metrics for all folds\n",
        "      all_accuracies = []\n",
        "      all_precisions = []\n",
        "      all_recalls = []\n",
        "      all_f1_scores = []\n",
        "\n",
        "      min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "      random.shuffle(label_0_indices)\n",
        "      random.shuffle(label_1_indices)\n",
        "      label_0_indices = label_0_indices[:min_size_dataset]\n",
        "      label_1_indices = label_1_indices[:min_size_dataset]\n",
        "      print('size 0 data:' , len(label_0_indices))\n",
        "      print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "      balanced_indices = label_0_indices + label_1_indices\n",
        "      print('size total dataset:' , len(balanced_indices))\n",
        "\n",
        "      balanced_data = [all_data[i] for i in balanced_indices]\n",
        "      print(len(balanced_data))\n",
        "\n",
        "      for btd in balanced_data:\n",
        "       # Apply one-hot encoding for each column\n",
        "        one_hot_encoded = [F.one_hot(btd.x[:, i].long(), num_classes[i]) for i in range(btd.x.shape[1])]\n",
        "        one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "        btd.x = one_hot_encoded_tensor\n",
        "\n",
        "      # Training loop with cross-validation\n",
        "      for fold, (train_idx, val_idx) in enumerate(kf.split(balanced_indices)):\n",
        "          print(f\"Fold [{fold+1}/{k_folds}]\")\n",
        "          # Subset the data for this fold\n",
        "          train_data = [balanced_data[i] for i in train_idx]\n",
        "          val_data = [balanced_data[i] for i in val_idx]\n",
        "\n",
        "          train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "          val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "\n",
        "          total_features = sum(num_classes)\n",
        "          # Define the model with the correct input dimension\n",
        "          if model_choosed == 1:\n",
        "            model = GCN(total_features, hidden_channels=hidden_channels)\n",
        "          elif model_choosed == 2:\n",
        "            model = GIN(total_features, hidden_channels=hidden_channels)\n",
        "          elif model_choosed == 3:\n",
        "            model = GAT(total_features, hidden_channels=hidden_channels)\n",
        "\n",
        "          optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "          # Early stopping variables\n",
        "          best_val_acc = 0.0\n",
        "          best_train_acc = 0.0\n",
        "          patience = 25  # Stop after no improvement for 25 epochs\n",
        "          counter = 0\n",
        "\n",
        "          # Collect evaluation metrics for this fold\n",
        "          fold_accuracies = []\n",
        "          fold_precisions = []\n",
        "          fold_recalls = []\n",
        "          fold_f1_scores = []\n",
        "\n",
        "          # Training loop with validation and early stopping\n",
        "          for epoch in range(1, 200):  # Train for maximum 100 epochs\n",
        "              # Train the model and get train accuracy\n",
        "              train_acc = train(model, optimizer, train_loader)\n",
        "\n",
        "              # Validate the model\n",
        "              val_acc, _, _ = validate(model, val_loader)\n",
        "\n",
        "              print(f'Fold [{fold+1}/{k_folds}] Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "              # Check for improvement in validation accuracy\n",
        "              if val_acc > best_val_acc:\n",
        "                  best_val_acc = val_acc\n",
        "                  best_train_acc = train_acc\n",
        "                  counter = 0  # Reset counter\n",
        "              else:\n",
        "                  counter += 1  # No improvement, increase counter\n",
        "\n",
        "              # If no improvement for \"patience\" number of epochs, stop training\n",
        "              if counter >= patience:\n",
        "                  print(f'Fold [{fold+1}/{k_folds}] Early stopping at epoch {epoch}')\n",
        "                  break\n",
        "\n",
        "\n",
        "          # Store the best train and val accuracies for this fold\n",
        "          best_train_accuracies.append(best_train_acc)\n",
        "          best_val_accuracies.append(best_val_acc)\n",
        "          best_models.append(model)\n",
        "\n",
        "          # Append metrics for this fold\n",
        "          all_accuracies.append(fold_accuracies)\n",
        "          all_precisions.append(fold_precisions)\n",
        "          all_recalls.append(fold_recalls)\n",
        "          all_f1_scores.append(fold_f1_scores)\n",
        "\n",
        "          # Final evaluation on the test set\n",
        "          test_acc, all_test_predictions, all_test_labels = validate(model, val_loader)\n",
        "\n",
        "          print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "          # Convert predictions and labels to numpy arrays\n",
        "          all_test_predictions = np.array(all_test_predictions)\n",
        "          all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "          # Plot confusion matrix\n",
        "          plot_confusion_matrix(all_test_labels, all_test_predictions, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "\n",
        "          # Calculate True Positives (TP), False Positives (FP),\n",
        "          # True Negatives (TN), False Negatives (FN)\n",
        "          TP = np.sum((all_test_predictions == 1) & (all_test_labels == 1))\n",
        "          FP = np.sum((all_test_predictions == 1) & (all_test_labels == 0))\n",
        "          TN = np.sum((all_test_predictions == 0) & (all_test_labels == 0))\n",
        "          FN = np.sum((all_test_predictions == 0) & (all_test_labels == 1))\n",
        "\n",
        "          print(\"True Positives (TP):\", TP)\n",
        "          print(\"False Positives (FP):\", FP)\n",
        "          print(\"True Negatives (TN):\", TN)\n",
        "          print(\"False Negatives (FN):\", FN)\n",
        "\n",
        "          # Calculate accuracy, precision, recall, and F1-score\n",
        "          accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "          precision = TP / (TP + FP)\n",
        "          recall = TP / (TP + FN)\n",
        "          f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "          print(\"Accuracy:\", accuracy)\n",
        "          print(\"Precision:\", precision)\n",
        "          print(\"Recall:\", recall)\n",
        "          print(\"F1-Score:\", f1_score)\n",
        "\n",
        "          # Append metrics for this epoch\n",
        "          fold_accuracies.append(val_acc)\n",
        "          fold_precisions.append(precision)\n",
        "          fold_recalls.append(recall)\n",
        "          fold_f1_scores.append(f1_score)\n",
        "\n",
        "          all_best_models['model'].append(model)\n",
        "          all_best_models['val_ACC'].append(max(best_val_accuracies))\n",
        "          all_best_models['AUC'].append(evaluate_roc_auc(model, val_loader))\n",
        "\n",
        "      # Calculate median of best train and val accuracies\n",
        "      median_best_train_acc = np.median(best_train_accuracies)\n",
        "      median_best_val_acc = np.median(best_val_accuracies)\n",
        "      all_best_train_acc.append(median_best_train_acc)\n",
        "      all_best_val_acc.append(median_best_val_acc)\n",
        "\n",
        "      print(\"\\nMedian of Best Train Accuracies:\", median_best_train_acc)\n",
        "      print(\"Median of Best Validation Accuracies:\", median_best_val_acc)\n",
        "\n",
        "      # Compare median validation accuracies to choose the better model\n",
        "      if median_best_val_acc == max(median_best_train_acc, median_best_val_acc):\n",
        "          best_model_idx = best_val_accuracies.index(max(best_val_accuracies))\n",
        "      else:\n",
        "          best_model_idx = best_train_accuracies.index(max(best_train_accuracies))\n",
        "\n",
        "      best_model = best_models[best_model_idx]\n",
        "\n",
        "      # Calculate median of all metrics across all folds\n",
        "      median_accuracy = np.median(np.concatenate(all_accuracies))\n",
        "      median_precision = np.median(np.concatenate(all_precisions))\n",
        "      median_recall = np.median(np.concatenate(all_recalls))\n",
        "      median_f1_score = np.median(np.concatenate(all_f1_scores))\n",
        "\n",
        "      print(\"\\nMedian of All Accuracies:\", median_accuracy)\n",
        "      print(\"Median of All Precisions:\", median_precision)\n",
        "      print(\"Median of All Recalls:\", median_recall)\n",
        "      print(\"Median of All F1-Scores:\", median_f1_score)\n",
        "      print('\\n')\n",
        "\n",
        "    return all_best_models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_no_balanced(data, num_classes, hidden_channels, iteration, k_folds, model_choosed):\n",
        "    all_best_train_acc = []\n",
        "    all_best_val_acc = []\n",
        "    all_auc = []\n",
        "    label_0_indices = []\n",
        "    label_1_indices = []\n",
        "    all_best_models = {'model':[], 'val_ACC': [], 'AUC':[]}\n",
        "\n",
        "    for i in range(len(data)):\n",
        "      if data[i].y == 0:\n",
        "        label_0_indices.append(i)\n",
        "      elif data[i].y == 1:\n",
        "        label_1_indices.append(i)\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    for iter in range(iteration):\n",
        "      all_data = copy.deepcopy(data)\n",
        "      print('iter:', iter)\n",
        "      # Define cross-validation settings\n",
        "      kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "      best_train_accuracies = []\n",
        "      best_val_accuracies = []\n",
        "      best_models = []\n",
        "\n",
        "      # Collect evaluation metrics for all folds\n",
        "      all_accuracies = []\n",
        "      all_precisions = []\n",
        "      all_recalls = []\n",
        "      all_f1_scores = []\n",
        "\n",
        "      min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "      random.shuffle(label_0_indices)\n",
        "      random.shuffle(label_1_indices)\n",
        "      label_0_indices = label_0_indices[:]\n",
        "      label_1_indices = label_1_indices[:]\n",
        "      print('size 0 data:' , len(label_0_indices))\n",
        "      print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "      no_balanced_indices = label_0_indices + label_1_indices\n",
        "      print('size total dataset:' , len(no_balanced_indices))\n",
        "\n",
        "      no_balanced_data = [all_data[i] for i in no_balanced_indices]\n",
        "      print(len(no_balanced_data))\n",
        "\n",
        "      for btd in no_balanced_data:\n",
        "       # Apply one-hot encoding for each column\n",
        "        one_hot_encoded = [F.one_hot(btd.x[:, i].long(), num_classes[i]) for i in range(btd.x.shape[1])]\n",
        "        one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "        btd.x = one_hot_encoded_tensor\n",
        "\n",
        "      # Training loop with cross-validation\n",
        "      for fold, (train_idx, val_idx) in enumerate(kf.split(no_balanced_indices)):\n",
        "          print(f\"Fold [{fold+1}/{k_folds}]\")\n",
        "          # Subset the data for this fold\n",
        "          train_data = [no_balanced_data[i] for i in train_idx]\n",
        "          val_data = [no_balanced_data[i] for i in val_idx]\n",
        "\n",
        "          train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "          val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "\n",
        "          total_features = sum(num_classes)\n",
        "          # Define the model with the correct input dimension\n",
        "          if model_choosed == 1:\n",
        "            model = GCN(total_features, hidden_channels=hidden_channels)\n",
        "          elif model_choosed == 2:\n",
        "            model = GIN(total_features, hidden_channels=hidden_channels)\n",
        "          elif model_choosed == 3:\n",
        "            model = GAT(total_features, hidden_channels=hidden_channels)\n",
        "\n",
        "          optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "          # Early stopping variables\n",
        "          best_val_acc = 0.0\n",
        "          best_train_acc = 0.0\n",
        "          patience = 25  # Stop after no improvement for 25 epochs\n",
        "          counter = 0\n",
        "\n",
        "          # Collect evaluation metrics for this fold\n",
        "          fold_accuracies = []\n",
        "          fold_precisions = []\n",
        "          fold_recalls = []\n",
        "          fold_f1_scores = []\n",
        "\n",
        "          # Training loop with validation and early stopping\n",
        "          for epoch in range(1, 200):  # Train for maximum 100 epochs\n",
        "              # Train the model and get train accuracy\n",
        "              train_acc = train(model, optimizer, train_loader)\n",
        "\n",
        "              # Validate the model\n",
        "              val_acc, _, _ = validate(model, val_loader)\n",
        "\n",
        "              print(f'Fold [{fold+1}/{k_folds}] Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "              # Check for improvement in validation accuracy\n",
        "              if val_acc > best_val_acc:\n",
        "                  best_val_acc = val_acc\n",
        "                  best_train_acc = train_acc\n",
        "                  counter = 0  # Reset counter\n",
        "              else:\n",
        "                  counter += 1  # No improvement, increase counter\n",
        "\n",
        "              # If no improvement for \"patience\" number of epochs, stop training\n",
        "              if counter >= patience:\n",
        "                  print(f'Fold [{fold+1}/{k_folds}] Early stopping at epoch {epoch}')\n",
        "                  break\n",
        "\n",
        "\n",
        "          # Store the best train and val accuracies for this fold\n",
        "          best_train_accuracies.append(best_train_acc)\n",
        "          best_val_accuracies.append(best_val_acc)\n",
        "          best_models.append(model)\n",
        "\n",
        "          # Append metrics for this fold\n",
        "          all_accuracies.append(fold_accuracies)\n",
        "          all_precisions.append(fold_precisions)\n",
        "          all_recalls.append(fold_recalls)\n",
        "          all_f1_scores.append(fold_f1_scores)\n",
        "\n",
        "          # Final evaluation on the test set\n",
        "          test_acc, all_test_predictions, all_test_labels = validate(model, val_loader)\n",
        "\n",
        "          print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "          # Convert predictions and labels to numpy arrays\n",
        "          all_test_predictions = np.array(all_test_predictions)\n",
        "          all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "          # Plot confusion matrix\n",
        "          plot_confusion_matrix(all_test_labels, all_test_predictions, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "\n",
        "          # Calculate True Positives (TP), False Positives (FP),\n",
        "          # True Negatives (TN), False Negatives (FN)\n",
        "          TP = np.sum((all_test_predictions == 1) & (all_test_labels == 1))\n",
        "          FP = np.sum((all_test_predictions == 1) & (all_test_labels == 0))\n",
        "          TN = np.sum((all_test_predictions == 0) & (all_test_labels == 0))\n",
        "          FN = np.sum((all_test_predictions == 0) & (all_test_labels == 1))\n",
        "\n",
        "          print(\"True Positives (TP):\", TP)\n",
        "          print(\"False Positives (FP):\", FP)\n",
        "          print(\"True Negatives (TN):\", TN)\n",
        "          print(\"False Negatives (FN):\", FN)\n",
        "\n",
        "          # Calculate accuracy, precision, recall, and F1-score\n",
        "          accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "          precision = TP / (TP + FP)\n",
        "          recall = TP / (TP + FN)\n",
        "          f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "          print(\"Accuracy:\", accuracy)\n",
        "          print(\"Precision:\", precision)\n",
        "          print(\"Recall:\", recall)\n",
        "          print(\"F1-Score:\", f1_score)\n",
        "\n",
        "          # Append metrics for this epoch\n",
        "          fold_accuracies.append(val_acc)\n",
        "          fold_precisions.append(precision)\n",
        "          fold_recalls.append(recall)\n",
        "          fold_f1_scores.append(f1_score)\n",
        "\n",
        "          all_best_models['model'].append(model)\n",
        "          all_best_models['val_ACC'].append(max(best_val_accuracies))\n",
        "          all_best_models['AUC'].append(evaluate_roc_auc(model, val_loader))\n",
        "\n",
        "      # Calculate median of best train and val accuracies\n",
        "      median_best_train_acc = np.median(best_train_accuracies)\n",
        "      median_best_val_acc = np.median(best_val_accuracies)\n",
        "      all_best_train_acc.append(median_best_train_acc)\n",
        "      all_best_val_acc.append(median_best_val_acc)\n",
        "\n",
        "      print(\"\\nMedian of Best Train Accuracies:\", median_best_train_acc)\n",
        "      print(\"Median of Best Validation Accuracies:\", median_best_val_acc)\n",
        "\n",
        "      # Compare median validation accuracies to choose the better model\n",
        "      if median_best_val_acc == max(median_best_train_acc, median_best_val_acc):\n",
        "          best_model_idx = best_val_accuracies.index(max(best_val_accuracies))\n",
        "      else:\n",
        "          best_model_idx = best_train_accuracies.index(max(best_train_accuracies))\n",
        "\n",
        "      best_model = best_models[best_model_idx]\n",
        "\n",
        "      # Calculate median of all metrics across all folds\n",
        "      median_accuracy = np.median(np.concatenate(all_accuracies))\n",
        "      median_precision = np.median(np.concatenate(all_precisions))\n",
        "      median_recall = np.median(np.concatenate(all_recalls))\n",
        "      median_f1_score = np.median(np.concatenate(all_f1_scores))\n",
        "\n",
        "      print(\"\\nMedian of All Accuracies:\", median_accuracy)\n",
        "      print(\"Median of All Precisions:\", median_precision)\n",
        "      print(\"Median of All Recalls:\", median_recall)\n",
        "      print(\"Median of All F1-Scores:\", median_f1_score)\n",
        "      print('\\n')\n",
        "\n",
        "    return all_best_models"
      ],
      "metadata": {
        "id": "yuLFZ57TJe5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def no_balanced_scatterfold(data, num_classes, hidden_channels,model_choosed):\n",
        "    all_best_train_acc = []\n",
        "    all_best_val_acc = []\n",
        "    all_auc = []\n",
        "    all_best_models = {'model':[], 'val_ACC': [], 'AUC':[]}\n",
        "\n",
        "    for iter in range(1):\n",
        "        all_data = copy.deepcopy(data)\n",
        "        print('iter:', iter)\n",
        "        print(all_data[1].x.shape[1])\n",
        "        balanced_data = [all_data[i] for i in range(len(all_data))]\n",
        "        # One-hot encode the features\n",
        "        for btd in balanced_data:\n",
        "            one_hot_encoded = [F.one_hot(btd.x[:, i].long(), num_classes[i]) for i in range(btd.x.shape[1])]\n",
        "            one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "            btd.x = one_hot_encoded_tensor\n",
        "\n",
        "        # Split the data into training (80%), validation (20%), and test (20%) sets\n",
        "        train_val_data, test_data = train_test_split(balanced_data, test_size=0.2, random_state=42)\n",
        "        train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=42) # 0.25 * 0.8 = 0.2\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "        total_features = sum(num_classes)\n",
        "        if model_choosed == 1:\n",
        "            model = GCN(total_features, hidden_channels=hidden_channels)\n",
        "        elif model_choosed == 2:\n",
        "            model = GIN(total_features, hidden_channels=hidden_channels)\n",
        "        elif model_choosed == 3:\n",
        "            model = GAT(total_features, hidden_channels=hidden_channels)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "        best_train_acc = 0.0\n",
        "        patience = 25\n",
        "        counter = 0\n",
        "\n",
        "        for epoch in range(1, 200):\n",
        "            train_acc = train(model, optimizer, train_loader)\n",
        "            val_acc, _, _ = validate(model, val_loader)\n",
        "\n",
        "            print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_train_acc = train_acc\n",
        "                counter = 0\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "            if counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch}')\n",
        "                break\n",
        "\n",
        "        test_acc, all_test_predictions, all_test_labels = validate(model, test_loader)\n",
        "\n",
        "        print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "        all_test_predictions = np.array(all_test_predictions)\n",
        "        all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plot_confusion_matrix(all_test_labels, all_test_predictions, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "\n",
        "        TP = np.sum((all_test_predictions == 1) & (all_test_labels == 1))\n",
        "        FP = np.sum((all_test_predictions == 1) & (all_test_labels == 0))\n",
        "        TN = np.sum((all_test_predictions == 0) & (all_test_labels == 0))\n",
        "        FN = np.sum((all_test_predictions == 0) & (all_test_labels == 1))\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"F1-Score:\", f1_score)\n",
        "\n",
        "        all_best_models['model'].append(model)\n",
        "        all_best_models['val_ACC'].append(best_val_acc)\n",
        "        all_best_models['AUC'].append(evaluate_roc_auc(model, val_loader))\n",
        "\n",
        "        all_best_train_acc.append(best_train_acc)\n",
        "        all_best_val_acc.append(best_val_acc)\n",
        "\n",
        "    return all_best_models"
      ],
      "metadata": {
        "id": "eLJryDstwyMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balanced_scatterfold(data, num_classes, hidden_channels,model_choosed):\n",
        "    all_best_train_acc = []\n",
        "    all_best_val_acc = []\n",
        "    all_auc = []\n",
        "    all_best_models = {'model':[], 'val_ACC': [], 'AUC':[]}\n",
        "    label_0_indices = []\n",
        "    label_1_indices = []\n",
        "    for i in range(len(data)):\n",
        "      if data[i].y == 0:\n",
        "        label_0_indices.append(i)\n",
        "      elif data[i].y == 1:\n",
        "        label_1_indices.append(i)\n",
        "\n",
        "    for iter in range(1):\n",
        "      all_data = copy.deepcopy(data)\n",
        "\n",
        "      print('iter:', iter)\n",
        "      print(all_data[1].x.shape[1])\n",
        "      min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "      random.shuffle(label_0_indices)\n",
        "      random.shuffle(label_1_indices)\n",
        "      label_0_indices = label_0_indices[:min_size_dataset]\n",
        "      label_1_indices = label_1_indices[:min_size_dataset]\n",
        "      print('size 0 data:' , len(label_0_indices))\n",
        "      print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "      balanced_indices = label_0_indices + label_1_indices\n",
        "      print('size total dataset:' , len(balanced_indices))\n",
        "\n",
        "      balanced_data = [all_data[i] for i in balanced_indices]\n",
        "      print(len(balanced_data))\n",
        "        #balanced_data = [all_data[i] for i in range(len(all_data))]\n",
        "        # One-hot encode the features\n",
        "      for btd in balanced_data:\n",
        "            one_hot_encoded = [F.one_hot(btd.x[:, i].long(), num_classes[i]) for i in range(btd.x.shape[1])]\n",
        "            one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "            btd.x = one_hot_encoded_tensor\n",
        "\n",
        "      # Split the data into training (80%), validation (20%), and test (20%) sets\n",
        "      train_val_data, test_data = train_test_split(balanced_data, test_size=0.2, random_state=42)\n",
        "      train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=42) # 0.25 * 0.8 = 0.2\n",
        "\n",
        "      train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "      val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "      test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "      total_features = sum(num_classes)\n",
        "      if model_choosed == 1:\n",
        "        model = GCN(total_features, hidden_channels=hidden_channels)\n",
        "      elif model_choosed == 2:\n",
        "        model = GIN(total_features, hidden_channels=hidden_channels)\n",
        "      elif model_choosed == 3:\n",
        "            model = GAT(total_features, hidden_channels=hidden_channels)\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "      best_val_acc = 0.0\n",
        "      best_train_acc = 0.0\n",
        "      patience = 25\n",
        "      counter = 0\n",
        "\n",
        "      for epoch in range(1, 200):\n",
        "        train_acc = train(model, optimizer, train_loader)\n",
        "        val_acc, _, _ = validate(model, val_loader)\n",
        "\n",
        "        print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          best_train_acc = train_acc\n",
        "          counter = 0\n",
        "        else:\n",
        "          counter += 1\n",
        "\n",
        "        if counter >= patience:\n",
        "          print(f'Early stopping at epoch {epoch}')\n",
        "          break\n",
        "\n",
        "      test_acc, all_test_predictions, all_test_labels = validate(model, test_loader)\n",
        "\n",
        "      print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "      all_test_predictions = np.array(all_test_predictions)\n",
        "      all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "      # Plot confusion matrix\n",
        "      plot_confusion_matrix(all_test_labels, all_test_predictions, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "\n",
        "      TP = np.sum((all_test_predictions == 1) & (all_test_labels == 1))\n",
        "      FP = np.sum((all_test_predictions == 1) & (all_test_labels == 0))\n",
        "      TN = np.sum((all_test_predictions == 0) & (all_test_labels == 0))\n",
        "      FN = np.sum((all_test_predictions == 0) & (all_test_labels == 1))\n",
        "\n",
        "      accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "      precision = TP / (TP + FP)\n",
        "      recall = TP / (TP + FN)\n",
        "      f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "      print(\"Accuracy:\", accuracy)\n",
        "      print(\"Precision:\", precision)\n",
        "      print(\"Recall:\", recall)\n",
        "      print(\"F1-Score:\", f1_score)\n",
        "\n",
        "      all_best_models['model'].append(model)\n",
        "      all_best_models['val_ACC'].append(best_val_acc)\n",
        "      all_best_models['AUC'].append(evaluate_roc_auc(model, val_loader))\n",
        "\n",
        "      all_best_train_acc.append(best_train_acc)\n",
        "      all_best_val_acc.append(best_val_acc)\n",
        "\n",
        "    return all_best_models"
      ],
      "metadata": {
        "id": "WG7aVDFFOBh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKBqFUUxKVcg"
      },
      "source": [
        "Evaluation of the models with extraction of the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxaioY-cKUgB"
      },
      "outputs": [],
      "source": [
        "def extract_metrics_and_best_model(all_best_models):\n",
        "  max_auc_index = all_best_models['AUC'].index(max(all_best_models['AUC']))\n",
        "  # Print the index and corresponding AUC value\n",
        "  print(\"Index of Max AUC:\", max_auc_index)\n",
        "  print(\"Max AUC Value:\", max(all_best_models['AUC']))\n",
        "  mean_auc = np.mean(all_best_models['AUC'])\n",
        "  std_auc = np.std(all_best_models['AUC'])\n",
        "\n",
        "  # Print the results\n",
        "  print(\"Mean AUC Value:\", mean_auc)\n",
        "  print(\"Standard Deviation AUC:\", std_auc)\n",
        "\n",
        "  best_model = all_best_models['model'][max_auc_index]\n",
        "\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Molecule with Node Importance"
      ],
      "metadata": {
        "id": "urrx3ZxRr7K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import io\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit import Chem\n",
        "from IPython.display import display, Image as IPImage\n",
        "\n",
        "def plot_graph_feature_importance(data, num_classes, best_model):\n",
        "    tp = Chem.GetPeriodicTable()\n",
        "    cp_data = copy.deepcopy(data)\n",
        "    best_model.eval()\n",
        "    elements = {}\n",
        "    for i in range(data.num_nodes):\n",
        "        first_element_int = int(data.x[i][0].item())\n",
        "        elements[i] = tp.GetElementSymbol(first_element_int)\n",
        "\n",
        "    one_hot_encoded = [F.one_hot(cp_data.x[:, j].long(), num_classes[j]) for j in range(cp_data.x.shape[1])]\n",
        "    one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "    cp_data.x = one_hot_encoded_tensor\n",
        "\n",
        "    # Forward pass to get the model output\n",
        "    output = best_model(cp_data.x.float(), cp_data.edge_index, cp_data.batch)\n",
        "\n",
        "    # Compute node importance scores\n",
        "    node_importance = best_model.gradients.norm(dim=1)\n",
        "\n",
        "    # Convert PyTorch tensor to numpy array for visualization\n",
        "    node_importance_np = node_importance.detach().numpy()\n",
        "\n",
        "    # Print node importance scores\n",
        "    #print(\"Node importance scores (raw):\", node_importance_np)\n",
        "\n",
        "    # Normalize importance scores for coloring\n",
        "    max_importance = max(node_importance_np) if len(node_importance_np) > 0 else 1\n",
        "    min_importance = min(node_importance_np) if len(node_importance_np) > 0 else 0\n",
        "    normalized_importance = (node_importance_np - min_importance) / (max_importance - min_importance + 1e-6)  # Add small epsilon to avoid division by zero\n",
        "\n",
        "    # Print normalized importance scores\n",
        "    #print(\"Node importance scores (normalized):\", normalized_importance)\n",
        "\n",
        "    # Create a NetworkX graph from edge_index\n",
        "    G = nx.Graph()\n",
        "    G.add_edges_from(cp_data.edge_index.T.numpy())\n",
        "\n",
        "    # Create a mapping from node indices to their importance scores\n",
        "    node_importance_dict = {i: importance for i, importance in enumerate(normalized_importance)}\n",
        "\n",
        "    '''\n",
        "    # Define colors based on node importance (red scale)\n",
        "    node_colors = [node_importance_dict[i] for i in range(len(G.nodes))]\n",
        "    cmap = matplotlib.colormaps['Reds']\n",
        "\n",
        "    # Determine node size based on importance (larger for higher importance)\n",
        "    node_sizes = [2000 * importance for importance in normalized_importance]\n",
        "\n",
        "    # Draw the graph with node labels and adjusted node sizes\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    pos = nx.spring_layout(G, seed=42)  # Positions for all nodes\n",
        "    nodes = nx.draw_networkx_nodes(G, pos, node_color=node_colors, cmap=cmap, node_size=node_sizes)\n",
        "    edges = nx.draw_networkx_edges(G, pos, edgelist=G.edges, alpha=0.5)\n",
        "    node_labels = nx.draw_networkx_labels(G, pos, labels=elements, font_size=10, font_color='white')\n",
        "    for _, text in node_labels.items():\n",
        "        text.set_bbox(dict(facecolor='none', edgecolor='none'))  # No box around labels\n",
        "    plt.colorbar(nodes, label='Node Importance', orientation='vertical')\n",
        "    plt.title('Graph with Node Importance')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    '''\n",
        "    return elements, node_importance_dict\n",
        "\n",
        "def visualize_molecular_graph(smiles, elements, node_importance_dict):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(\"Invalid SMILES string\")\n",
        "\n",
        "    # Create a list of atom importance scores\n",
        "    atom_importance = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        idx = atom.GetIdx()\n",
        "        atom_importance.append(node_importance_dict[idx] if idx in node_importance_dict else 0)\n",
        "\n",
        "    # Normalize importance scores for coloring\n",
        "    max_importance = max(atom_importance) if atom_importance else 1\n",
        "    min_importance = min(atom_importance) if atom_importance else 0\n",
        "    normalized_importance = [(score - min_importance) / (max_importance - min_importance + 1e-6) for score in atom_importance]\n",
        "\n",
        "    '''\n",
        "    # Print atom importance scores\n",
        "    print(\"Atom importance scores (raw):\", atom_importance)\n",
        "    print(\"Atom importance scores (normalized):\", normalized_importance)\n",
        "    '''\n",
        "    # Define the color map and normalize\n",
        "    cmap = plt.get_cmap('Reds')\n",
        "    norm = mcolors.Normalize(vmin=0, vmax=1)\n",
        "\n",
        "    # Create a dictionary of highlight colors for atoms\n",
        "    highlight_atom_colors = {}\n",
        "    for i, atom in enumerate(mol.GetAtoms()):\n",
        "        color = cmap(norm(normalized_importance[i]))\n",
        "        highlight_atom_colors[atom.GetIdx()] = (float(color[0]), float(color[1]), float(color[2]))\n",
        "\n",
        "    # Draw the molecule with highlighted atoms\n",
        "    drawer = Draw.MolDraw2DCairo(300, 300)\n",
        "    opts = drawer.drawOptions()\n",
        "    for i, atom in enumerate(mol.GetAtoms()):\n",
        "        opts.atomLabels[atom.GetIdx()] = elements[atom.GetIdx()]\n",
        "\n",
        "    drawer.DrawMolecule(mol, highlightAtoms=[atom.GetIdx() for atom in mol.GetAtoms()], highlightAtomColors=highlight_atom_colors)\n",
        "    drawer.FinishDrawing()\n",
        "\n",
        "    # Convert to PIL image\n",
        "    img_data = drawer.GetDrawingText()\n",
        "    img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "    # Display image in Colab\n",
        "    display(IPImage(img_data))\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "xdd6xVh6JtxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot confusion matrix"
      ],
      "metadata": {
        "id": "dIKx-_E-sTFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
        "    \"\"\"\n",
        "    Plots the confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (list or array): True labels.\n",
        "    y_pred (list or array): Predicted labels.\n",
        "    class_names (list): List of class names. If None, integer labels are used.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# y_true = [0, 1, 1, 0, 1, 0]\n",
        "# y_pred = [0, 1, 0, 0, 1, 1]\n",
        "# class_names = ['Class 0', 'Class 1']\n",
        "# plot_confusion_matrix(y_true, y_pred, class_names)\n"
      ],
      "metadata": {
        "id": "wOTT35pUsSJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0aDjkUbK4Aa"
      },
      "source": [
        "MAIN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#graphs-datasets/PROTEINS\n",
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
        "#qua sta anche clintox e altri vedere bene documntazione però il codice funziona anche con uun proprio dataset, però il clintox ha la y diversa dalla nostra quindi in molti casi conviene avere a che fare con db propri, dove settiamo noi la y per bene e usiamo lo script SMILEs-MOL-OGB\n",
        "data = dataset[:]\n",
        "print(data[1])"
      ],
      "metadata": {
        "id": "i8SfGdZGaZSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[1])"
      ],
      "metadata": {
        "id": "zjs-15AOE5Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/zpn_clintox.pt', 'rb') as f:\n",
        "  data = pickle.load(f)"
      ],
      "metadata": {
        "id": "mfEq25K0LRtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/clintox_dataset.csv')\n",
        "smiles_list = df['smiles'].tolist()"
      ],
      "metadata": {
        "id": "DQ3bjznPK-Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqvLH_Z_K6G1"
      },
      "outputs": [],
      "source": [
        "#dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
        "num_classes = [119, 5, 12, 12, 9, 6, 6, 2, 2]\n",
        "hidden_channels = 70\n",
        "all_best_models = balanced_scatterfold(data, num_classes, hidden_channels,3)\n",
        "best_model = extract_metrics_and_best_model(all_best_models)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_index = 16\n",
        "smiles = smiles_list[data_index]\n",
        "elements, node_importance_dict = plot_graph_feature_importance(data[data_index], num_classes, best_model)\n",
        "img = visualize_molecular_graph(smiles, elements, node_importance_dict)"
      ],
      "metadata": {
        "id": "grFW5TY3XjpJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pZBWOStOXUU8",
        "-Bs0fWiRsIlL"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}