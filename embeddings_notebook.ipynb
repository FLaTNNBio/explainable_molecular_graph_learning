{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtVle8RHNqON"
      },
      "source": [
        "# Node representation learning with Node2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tLTzxU_DNzLi",
        "outputId": "bce316e8-37f3-430d-c420-f404cc4f1a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pysmiles in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: pbr in /usr/local/lib/python3.10/dist-packages (from pysmiles) (6.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pysmiles) (3.3)\n",
            "Collecting git+https://github.com/VenkateshwaranB/stellargraph.git\n",
            "  Cloning https://github.com/VenkateshwaranB/stellargraph.git to /tmp/pip-req-build-nqnm7sc9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/VenkateshwaranB/stellargraph.git /tmp/pip-req-build-nqnm7sc9\n",
            "  Resolved https://github.com/VenkateshwaranB/stellargraph.git to commit efa1f847109a4ba490e7a5105646a20ee09a3243\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stellargraph==1.3.0b0) (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from stellargraph==1.3.0b0) (1.23.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from stellargraph==1.3.0b0) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from stellargraph==1.3.0b0) (3.3)\n",
            "Requirement already satisfied: scikit_learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from stellargraph==1.3.0b0) (1.3.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.10/dist-packages (from stellargraph==1.3.0b0) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from stellargraph==1.3.0b0) (2.1.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2->stellargraph==1.3.0b0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2->stellargraph==1.3.0b0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2->stellargraph==1.3.0b0) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2->stellargraph==1.3.0b0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2->stellargraph==1.3.0b0) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2->stellargraph==1.3.0b0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2->stellargraph==1.3.0b0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2->stellargraph==1.3.0b0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->stellargraph==1.3.0b0) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->stellargraph==1.3.0b0) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>=0.20->stellargraph==1.3.0b0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>=0.20->stellargraph==1.3.0b0) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (0.2.0)\n",
            "Collecting numpy>=1.14 (from stellargraph==1.3.0b0)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m915.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.1.0->stellargraph==1.3.0b0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->stellargraph==1.3.0b0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->stellargraph==1.3.0b0) (3.2.2)\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.1\n",
            "    Uninstalling numpy-1.23.1:\n",
            "      Successfully uninstalled numpy-1.23.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2024.3.3)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: mxnet-mkl==1.6.0 in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting numpy==1.23.1\n",
            "  Using cached numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet-mkl==1.6.0) (2.32.3)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet-mkl==1.6.0) (0.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-mkl==1.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-mkl==1.6.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-mkl==1.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-mkl==1.6.0) (2024.7.4)\n",
            "Using cached numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.12 requires numpy<2,>=1.24.4, but you have numpy 1.23.1 which is incompatible.\n",
            "albumentations 1.4.11 requires numpy>=1.24.4, but you have numpy 1.23.1 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.1 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.23.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "1d1da9563e2446a0bc9498458f9a545e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# install StellarGraph if running on Google Colab\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install pysmiles\n",
        "  !pip install git+https://github.com/VenkateshwaranB/stellargraph.git\n",
        "  !pip install rdkit\n",
        "  !pip install torch_geometric\n",
        "  !pip install datasets\n",
        "  !pip3 install mxnet-mkl==1.6.0 numpy==1.23.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wcuv1AHaNqOR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stellargraph import datasets\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Fv8jU7ilW-6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a31b3ca-2888-40c4-c4af-aa05e0d48140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ogb in /usr/local/lib/python3.10/dist-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.23.1)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.3.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (71.0.4)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2024.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a2IcVbx3jwCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a0e72f-e848-421c-a6fa-6bae012e2999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C1O3XD3xibZ"
      },
      "source": [
        "## DF with all data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JjfW3Bz-qAr-"
      },
      "outputs": [],
      "source": [
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
        "\n",
        "#qua sta anche clintox e altri vedere bene documntazione però il codice funziona anche con uun proprio dataset, però il clintox ha la y diversa dalla nostra quindi in molti casi conviene avere a che fare con db propri, dove settiamo noi la y per bene e usiamo lo script SMILEs-MOL-OGB\n",
        "all_data = dataset[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4sCu2-XWLin",
        "outputId": "a557eabe-8176-4f93-c901-844f0e6af54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Data(x=[23, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=23), Data(x=[33, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=33), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[27, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=27), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[8, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=8), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[9, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=9), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[10, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=10), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[10, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=10), Data(x=[36, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=36), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[31, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=31), Data(x=[10, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=10), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[25, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=25), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[39, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=39), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[23, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=23), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[25, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=25), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[10, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=10), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[34, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=34), Data(x=[32, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=32), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[24, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=24), Data(x=[23, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=23), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[36, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=36), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[24, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=24), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[26, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=26), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[43, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=43), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[42, 9], edge_index=[2, 84], edge_attr=[84, 3], y=[1, 1], num_nodes=42), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[26, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=26), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[37, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=37), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[32, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=32), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[9, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=9), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[14, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=14), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[2, 9], edge_index=[2, 2], edge_attr=[2, 3], y=[1, 1], num_nodes=2), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[1, 9], edge_index=[2, 0], edge_attr=[0, 3], y=[1, 1], num_nodes=1), Data(x=[2, 9], edge_index=[2, 2], edge_attr=[2, 3], y=[1, 1], num_nodes=2), Data(x=[13, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=13), Data(x=[7, 9], edge_index=[2, 12], edge_attr=[12, 3], y=[1, 1], num_nodes=7), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[12, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=12), Data(x=[13, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=13), Data(x=[12, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=12), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[26, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=26), Data(x=[20, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=20), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[8, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=8), Data(x=[6, 9], edge_index=[2, 10], edge_attr=[10, 3], y=[1, 1], num_nodes=6), Data(x=[15, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=15), Data(x=[6, 9], edge_index=[2, 10], edge_attr=[10, 3], y=[1, 1], num_nodes=6), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[7, 9], edge_index=[2, 12], edge_attr=[12, 3], y=[1, 1], num_nodes=7), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[6, 9], edge_index=[2, 10], edge_attr=[10, 3], y=[1, 1], num_nodes=6), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[13, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=13), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[8, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=8), Data(x=[12, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=12), Data(x=[13, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=13), Data(x=[13, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=13), Data(x=[12, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=12), Data(x=[12, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=12), Data(x=[14, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=14), Data(x=[8, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=8), Data(x=[9, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=9), Data(x=[7, 9], edge_index=[2, 12], edge_attr=[12, 3], y=[1, 1], num_nodes=7), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[40, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=40), Data(x=[9, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=9), Data(x=[13, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=13), Data(x=[20, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=20), Data(x=[27, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=27), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[7, 9], edge_index=[2, 12], edge_attr=[12, 3], y=[1, 1], num_nodes=7), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[7, 9], edge_index=[2, 12], edge_attr=[12, 3], y=[1, 1], num_nodes=7), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[12, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=12), Data(x=[19, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=19), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[8, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=8), Data(x=[14, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=14), Data(x=[18, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=18), Data(x=[20, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=20), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[8, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=8), Data(x=[13, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=13), Data(x=[6, 9], edge_index=[2, 10], edge_attr=[10, 3], y=[1, 1], num_nodes=6), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[9, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=9), Data(x=[15, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=15), Data(x=[14, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=14), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[39, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=39), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[14, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=14), Data(x=[9, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=9), Data(x=[16, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=16), Data(x=[9, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=9), Data(x=[15, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=15), Data(x=[18, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=18), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[19, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=19), Data(x=[15, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=15), Data(x=[20, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=20), Data(x=[46, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=46), Data(x=[50, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=50), Data(x=[23, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=23), Data(x=[17, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=17), Data(x=[19, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=19), Data(x=[40, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=40), Data(x=[15, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=15), Data(x=[16, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=16), Data(x=[3, 9], edge_index=[2, 4], edge_attr=[4, 3], y=[1, 1], num_nodes=3), Data(x=[19, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=19), Data(x=[24, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=24), Data(x=[15, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=15), Data(x=[2, 9], edge_index=[2, 2], edge_attr=[2, 3], y=[1, 1], num_nodes=2), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[3, 9], edge_index=[2, 4], edge_attr=[4, 3], y=[1, 1], num_nodes=3), Data(x=[3, 9], edge_index=[2, 4], edge_attr=[4, 3], y=[1, 1], num_nodes=3), Data(x=[3, 9], edge_index=[2, 4], edge_attr=[4, 3], y=[1, 1], num_nodes=3), Data(x=[9, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=9), Data(x=[29, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=29), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[8, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=8), Data(x=[11, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=11), Data(x=[10, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=10), Data(x=[35, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=35), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[2, 9], edge_index=[2, 2], edge_attr=[2, 3], y=[1, 1], num_nodes=2), Data(x=[3, 9], edge_index=[2, 4], edge_attr=[4, 3], y=[1, 1], num_nodes=3), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[4, 9], edge_index=[2, 6], edge_attr=[6, 3], y=[1, 1], num_nodes=4), Data(x=[3, 9], edge_index=[2, 4], edge_attr=[4, 3], y=[1, 1], num_nodes=3), Data(x=[2, 9], edge_index=[2, 2], edge_attr=[2, 3], y=[1, 1], num_nodes=2), Data(x=[5, 9], edge_index=[2, 8], edge_attr=[8, 3], y=[1, 1], num_nodes=5), Data(x=[3, 9], edge_index=[2, 4], edge_attr=[4, 3], y=[1, 1], num_nodes=3), Data(x=[35, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=35), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[35, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=35), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[36, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=36), Data(x=[36, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=36), Data(x=[35, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=35), Data(x=[36, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=36), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[35, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=35), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[26, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=26), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[24, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=24), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[26, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=26), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[8, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=8), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[23, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=23), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[39, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=39), Data(x=[39, 9], edge_index=[2, 84], edge_attr=[84, 3], y=[1, 1], num_nodes=39), Data(x=[40, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=40), Data(x=[38, 9], edge_index=[2, 84], edge_attr=[84, 3], y=[1, 1], num_nodes=38), Data(x=[39, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=39), Data(x=[36, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=36), Data(x=[51, 9], edge_index=[2, 110], edge_attr=[110, 3], y=[1, 1], num_nodes=51), Data(x=[32, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=32), Data(x=[31, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=31), Data(x=[38, 9], edge_index=[2, 84], edge_attr=[84, 3], y=[1, 1], num_nodes=38), Data(x=[31, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=31), Data(x=[30, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=30), Data(x=[35, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=35), Data(x=[31, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=31), Data(x=[9, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=9), Data(x=[9, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=9), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[10, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=10), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=22), Data(x=[38, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=38), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[26, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=26), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[41, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=41), Data(x=[20, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=20), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[7, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=7), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[10, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=10), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[26, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=26), Data(x=[24, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=24), Data(x=[24, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=24), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[8, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=8), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[37, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=37), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[22, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=22), Data(x=[23, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=23), Data(x=[21, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=22), Data(x=[24, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=24), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[42, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=42), Data(x=[13, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=13), Data(x=[13, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=13), Data(x=[11, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=11), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[35, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=35), Data(x=[34, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=34), Data(x=[34, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=34), Data(x=[34, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=34), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[18, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=18), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[38, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=38), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[13, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=13), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[35, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=35), Data(x=[34, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=34), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[65, 9], edge_index=[2, 136], edge_attr=[136, 3], y=[1, 1], num_nodes=65), Data(x=[68, 9], edge_index=[2, 142], edge_attr=[142, 3], y=[1, 1], num_nodes=68), Data(x=[68, 9], edge_index=[2, 142], edge_attr=[142, 3], y=[1, 1], num_nodes=68), Data(x=[73, 9], edge_index=[2, 152], edge_attr=[152, 3], y=[1, 1], num_nodes=73), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[11, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=11), Data(x=[10, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=10), Data(x=[11, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=11), Data(x=[10, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=10), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[40, 9], edge_index=[2, 84], edge_attr=[84, 3], y=[1, 1], num_nodes=40), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[24, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=24), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[38, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=38), Data(x=[41, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=41), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[27, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=27), Data(x=[25, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=25), Data(x=[25, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=25), Data(x=[27, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=27), Data(x=[27, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=27), Data(x=[44, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=44), Data(x=[51, 9], edge_index=[2, 106], edge_attr=[106, 3], y=[1, 1], num_nodes=51), Data(x=[52, 9], edge_index=[2, 108], edge_attr=[108, 3], y=[1, 1], num_nodes=52), Data(x=[55, 9], edge_index=[2, 114], edge_attr=[114, 3], y=[1, 1], num_nodes=55), Data(x=[31, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=31), Data(x=[30, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=30), Data(x=[48, 9], edge_index=[2, 104], edge_attr=[104, 3], y=[1, 1], num_nodes=48), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[34, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=34), Data(x=[34, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=34), Data(x=[31, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=31), Data(x=[41, 9], edge_index=[2, 92], edge_attr=[92, 3], y=[1, 1], num_nodes=41), Data(x=[40, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=40), Data(x=[43, 9], edge_index=[2, 96], edge_attr=[96, 3], y=[1, 1], num_nodes=43), Data(x=[91, 9], edge_index=[2, 192], edge_attr=[192, 3], y=[1, 1], num_nodes=91), Data(x=[91, 9], edge_index=[2, 192], edge_attr=[192, 3], y=[1, 1], num_nodes=91), Data(x=[87, 9], edge_index=[2, 184], edge_attr=[184, 3], y=[1, 1], num_nodes=87), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[20, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=20), Data(x=[19, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=19), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[101, 9], edge_index=[2, 212], edge_attr=[212, 3], y=[1, 1], num_nodes=101), Data(x=[102, 9], edge_index=[2, 214], edge_attr=[214, 3], y=[1, 1], num_nodes=102), Data(x=[112, 9], edge_index=[2, 234], edge_attr=[234, 3], y=[1, 1], num_nodes=112), Data(x=[55, 9], edge_index=[2, 124], edge_attr=[124, 3], y=[1, 1], num_nodes=55), Data(x=[54, 9], edge_index=[2, 122], edge_attr=[122, 3], y=[1, 1], num_nodes=54), Data(x=[57, 9], edge_index=[2, 128], edge_attr=[128, 3], y=[1, 1], num_nodes=57), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[29, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=29), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[27, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=27), Data(x=[74, 9], edge_index=[2, 154], edge_attr=[154, 3], y=[1, 1], num_nodes=74), Data(x=[75, 9], edge_index=[2, 156], edge_attr=[156, 3], y=[1, 1], num_nodes=75), Data(x=[73, 9], edge_index=[2, 152], edge_attr=[152, 3], y=[1, 1], num_nodes=73), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[35, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=35), Data(x=[35, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=35), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[11, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=11), Data(x=[13, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=13), Data(x=[13, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=13), Data(x=[9, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=9), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[9, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=9), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[13, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=13), Data(x=[10, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=10), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[32, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=32), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[40, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=40), Data(x=[40, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=40), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[42, 9], edge_index=[2, 94], edge_attr=[94, 3], y=[1, 1], num_nodes=42), Data(x=[44, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=44), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[33, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=33), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[36, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=36), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[37, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=37), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[25, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=25), Data(x=[30, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=30), Data(x=[39, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=39), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[69, 9], edge_index=[2, 142], edge_attr=[142, 3], y=[1, 1], num_nodes=69), Data(x=[67, 9], edge_index=[2, 138], edge_attr=[138, 3], y=[1, 1], num_nodes=67), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[8, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=8), Data(x=[60, 9], edge_index=[2, 136], edge_attr=[136, 3], y=[1, 1], num_nodes=60), Data(x=[65, 9], edge_index=[2, 144], edge_attr=[144, 3], y=[1, 1], num_nodes=65), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[17, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=17), Data(x=[16, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=16), Data(x=[58, 9], edge_index=[2, 126], edge_attr=[126, 3], y=[1, 1], num_nodes=58), Data(x=[60, 9], edge_index=[2, 130], edge_attr=[130, 3], y=[1, 1], num_nodes=60), Data(x=[37, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=37), Data(x=[42, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=42), Data(x=[39, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=39), Data(x=[39, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=39), Data(x=[33, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=33), Data(x=[13, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=13), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[10, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=10), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[35, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=35), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[29, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=29), Data(x=[29, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=29), Data(x=[36, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=36), Data(x=[36, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=36), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[24, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=24), Data(x=[35, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=35), Data(x=[39, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=39), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[36, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=36), Data(x=[29, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=29), Data(x=[32, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=32), Data(x=[35, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=35), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[29, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=29), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[48, 9], edge_index=[2, 108], edge_attr=[108, 3], y=[1, 1], num_nodes=48), Data(x=[45, 9], edge_index=[2, 102], edge_attr=[102, 3], y=[1, 1], num_nodes=45), Data(x=[67, 9], edge_index=[2, 144], edge_attr=[144, 3], y=[1, 1], num_nodes=67), Data(x=[67, 9], edge_index=[2, 144], edge_attr=[144, 3], y=[1, 1], num_nodes=67), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[101, 9], edge_index=[2, 220], edge_attr=[220, 3], y=[1, 1], num_nodes=101), Data(x=[121, 9], edge_index=[2, 260], edge_attr=[260, 3], y=[1, 1], num_nodes=121), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[31, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=31), Data(x=[31, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=31), Data(x=[37, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=37), Data(x=[37, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=37), Data(x=[20, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=20), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[42, 9], edge_index=[2, 96], edge_attr=[96, 3], y=[1, 1], num_nodes=42), Data(x=[42, 9], edge_index=[2, 96], edge_attr=[96, 3], y=[1, 1], num_nodes=42), Data(x=[37, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=37), Data(x=[35, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=35), Data(x=[57, 9], edge_index=[2, 120], edge_attr=[120, 3], y=[1, 1], num_nodes=57), Data(x=[56, 9], edge_index=[2, 118], edge_attr=[118, 3], y=[1, 1], num_nodes=56), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[5, 9], edge_index=[2, 10], edge_attr=[10, 3], y=[1, 1], num_nodes=5), Data(x=[35, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=35), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[6, 9], edge_index=[2, 12], edge_attr=[12, 3], y=[1, 1], num_nodes=6), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[31, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=31), Data(x=[28, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=28), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[12, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=12), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[10, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=10), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[17, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=17), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[17, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=17), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[33, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=33), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[25, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=25), Data(x=[26, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=26), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[30, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=30), Data(x=[40, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=40), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[8, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=8), Data(x=[6, 9], edge_index=[2, 12], edge_attr=[12, 3], y=[1, 1], num_nodes=6), Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=33), Data(x=[25, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=25), Data(x=[5, 9], edge_index=[2, 10], edge_attr=[10, 3], y=[1, 1], num_nodes=5), Data(x=[8, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=8), Data(x=[20, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=20), Data(x=[21, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=21), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[9, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=9), Data(x=[18, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=18), Data(x=[42, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=42), Data(x=[42, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=42), Data(x=[48, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=48), Data(x=[47, 9], edge_index=[2, 96], edge_attr=[96, 3], y=[1, 1], num_nodes=47), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[9, 9], edge_index=[2, 18], edge_attr=[18, 3], y=[1, 1], num_nodes=9), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[78, 9], edge_index=[2, 158], edge_attr=[158, 3], y=[1, 1], num_nodes=78), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[5, 9], edge_index=[2, 12], edge_attr=[12, 3], y=[1, 1], num_nodes=5), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[46, 9], edge_index=[2, 102], edge_attr=[102, 3], y=[1, 1], num_nodes=46), Data(x=[31, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=31), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=33), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[30, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=30), Data(x=[46, 9], edge_index=[2, 106], edge_attr=[106, 3], y=[1, 1], num_nodes=46), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[29, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=29), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[91, 9], edge_index=[2, 190], edge_attr=[190, 3], y=[1, 1], num_nodes=91), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[34, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=34), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[38, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=38), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[7, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=7), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[29, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=29), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[36, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=36), Data(x=[36, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=36), Data(x=[36, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=36), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[40, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=40), Data(x=[67, 9], edge_index=[2, 136], edge_attr=[136, 3], y=[1, 1], num_nodes=67), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[15, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=15), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[42, 9], edge_index=[2, 94], edge_attr=[94, 3], y=[1, 1], num_nodes=42), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[43, 9], edge_index=[2, 94], edge_attr=[94, 3], y=[1, 1], num_nodes=43), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[96, 9], edge_index=[2, 206], edge_attr=[206, 3], y=[1, 1], num_nodes=96), Data(x=[36, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=36), Data(x=[44, 9], edge_index=[2, 96], edge_attr=[96, 3], y=[1, 1], num_nodes=44), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[48, 9], edge_index=[2, 100], edge_attr=[100, 3], y=[1, 1], num_nodes=48), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[36, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=36), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[24, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=24), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[42, 9], edge_index=[2, 92], edge_attr=[92, 3], y=[1, 1], num_nodes=42), Data(x=[82, 9], edge_index=[2, 176], edge_attr=[176, 3], y=[1, 1], num_nodes=82), Data(x=[89, 9], edge_index=[2, 190], edge_attr=[190, 3], y=[1, 1], num_nodes=89), Data(x=[46, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=46), Data(x=[37, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=37), Data(x=[115, 9], edge_index=[2, 236], edge_attr=[236, 3], y=[1, 1], num_nodes=115), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[27, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=27), Data(x=[27, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=27), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[35, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=35), Data(x=[39, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=39), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[41, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=41), Data(x=[11, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=11), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=17), Data(x=[25, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=25), Data(x=[19, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=19), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[42, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=42), Data(x=[26, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=26), Data(x=[49, 9], edge_index=[2, 106], edge_attr=[106, 3], y=[1, 1], num_nodes=49), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[57, 9], edge_index=[2, 130], edge_attr=[130, 3], y=[1, 1], num_nodes=57), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[57, 9], edge_index=[2, 130], edge_attr=[130, 3], y=[1, 1], num_nodes=57), Data(x=[43, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=43), Data(x=[43, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=43), Data(x=[34, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=34), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[72, 9], edge_index=[2, 150], edge_attr=[150, 3], y=[1, 1], num_nodes=72), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[10, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=10), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[39, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=39), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[27, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=27), Data(x=[49, 9], edge_index=[2, 110], edge_attr=[110, 3], y=[1, 1], num_nodes=49), Data(x=[85, 9], edge_index=[2, 172], edge_attr=[172, 3], y=[1, 1], num_nodes=85), Data(x=[81, 9], edge_index=[2, 162], edge_attr=[162, 3], y=[1, 1], num_nodes=81), Data(x=[100, 9], edge_index=[2, 206], edge_attr=[206, 3], y=[1, 1], num_nodes=100), Data(x=[43, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=43), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[33, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=33), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[36, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=36), Data(x=[53, 9], edge_index=[2, 116], edge_attr=[116, 3], y=[1, 1], num_nodes=53), Data(x=[85, 9], edge_index=[2, 170], edge_attr=[170, 3], y=[1, 1], num_nodes=85), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[62, 9], edge_index=[2, 136], edge_attr=[136, 3], y=[1, 1], num_nodes=62), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[73, 9], edge_index=[2, 160], edge_attr=[160, 3], y=[1, 1], num_nodes=73), Data(x=[52, 9], edge_index=[2, 108], edge_attr=[108, 3], y=[1, 1], num_nodes=52), Data(x=[56, 9], edge_index=[2, 124], edge_attr=[124, 3], y=[1, 1], num_nodes=56), Data(x=[51, 9], edge_index=[2, 114], edge_attr=[114, 3], y=[1, 1], num_nodes=51), Data(x=[31, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=31), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[35, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=35), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[20, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=20), Data(x=[57, 9], edge_index=[2, 124], edge_attr=[124, 3], y=[1, 1], num_nodes=57), Data(x=[17, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=17), Data(x=[41, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=41), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[46, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=46), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[24, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=24), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[37, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=37), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[43, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=43), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[90, 9], edge_index=[2, 192], edge_attr=[192, 3], y=[1, 1], num_nodes=90), Data(x=[25, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=25), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[90, 9], edge_index=[2, 194], edge_attr=[194, 3], y=[1, 1], num_nodes=90), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[42, 9], edge_index=[2, 92], edge_attr=[92, 3], y=[1, 1], num_nodes=42), Data(x=[53, 9], edge_index=[2, 116], edge_attr=[116, 3], y=[1, 1], num_nodes=53), Data(x=[87, 9], edge_index=[2, 192], edge_attr=[192, 3], y=[1, 1], num_nodes=87), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[62, 9], edge_index=[2, 136], edge_attr=[136, 3], y=[1, 1], num_nodes=62), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[13, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=13), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[96, 9], edge_index=[2, 202], edge_attr=[202, 3], y=[1, 1], num_nodes=96), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[40, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=40), Data(x=[44, 9], edge_index=[2, 94], edge_attr=[94, 3], y=[1, 1], num_nodes=44), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[58, 9], edge_index=[2, 126], edge_attr=[126, 3], y=[1, 1], num_nodes=58), Data(x=[76, 9], edge_index=[2, 166], edge_attr=[166, 3], y=[1, 1], num_nodes=76), Data(x=[39, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=39), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[61, 9], edge_index=[2, 132], edge_attr=[132, 3], y=[1, 1], num_nodes=61), Data(x=[63, 9], edge_index=[2, 136], edge_attr=[136, 3], y=[1, 1], num_nodes=63), Data(x=[59, 9], edge_index=[2, 126], edge_attr=[126, 3], y=[1, 1], num_nodes=59), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[30, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=30), Data(x=[24, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=24), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[40, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=40), Data(x=[42, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=42), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[35, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=35), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[38, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=38), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[32, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=32), Data(x=[24, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=24), Data(x=[12, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=12), Data(x=[38, 9], edge_index=[2, 84], edge_attr=[84, 3], y=[1, 1], num_nodes=38), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[32, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=32), Data(x=[37, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=37), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[29, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=29), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[36, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=36), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[43, 9], edge_index=[2, 96], edge_attr=[96, 3], y=[1, 1], num_nodes=43), Data(x=[38, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=38), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[13, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=13), Data(x=[32, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=32), Data(x=[29, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=29), Data(x=[23, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=23), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[62, 9], edge_index=[2, 126], edge_attr=[126, 3], y=[1, 1], num_nodes=62), Data(x=[43, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=43), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[29, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=29), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[71, 9], edge_index=[2, 150], edge_attr=[150, 3], y=[1, 1], num_nodes=71), Data(x=[31, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=31), Data(x=[35, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=35), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[54, 9], edge_index=[2, 112], edge_attr=[112, 3], y=[1, 1], num_nodes=54), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[18, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=18), Data(x=[38, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=38), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[96, 9], edge_index=[2, 206], edge_attr=[206, 3], y=[1, 1], num_nodes=96), Data(x=[43, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=43), Data(x=[85, 9], edge_index=[2, 180], edge_attr=[180, 3], y=[1, 1], num_nodes=85), Data(x=[95, 9], edge_index=[2, 204], edge_attr=[204, 3], y=[1, 1], num_nodes=95), Data(x=[52, 9], edge_index=[2, 110], edge_attr=[110, 3], y=[1, 1], num_nodes=52), Data(x=[50, 9], edge_index=[2, 106], edge_attr=[106, 3], y=[1, 1], num_nodes=50), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[33, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=33), Data(x=[41, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=41), Data(x=[33, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=33), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[36, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=36), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=33), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[41, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=41), Data(x=[37, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=37), Data(x=[45, 9], edge_index=[2, 98], edge_attr=[98, 3], y=[1, 1], num_nodes=45), Data(x=[49, 9], edge_index=[2, 106], edge_attr=[106, 3], y=[1, 1], num_nodes=49), Data(x=[39, 9], edge_index=[2, 84], edge_attr=[84, 3], y=[1, 1], num_nodes=39), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[35, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=35), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[51, 9], edge_index=[2, 106], edge_attr=[106, 3], y=[1, 1], num_nodes=51), Data(x=[37, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=37), Data(x=[36, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=36), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[35, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=35), Data(x=[26, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=26), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[18, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=18), Data(x=[20, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=20), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[12, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=12), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[20, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=20), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=22), Data(x=[21, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[20, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=20), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[32, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=32), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[74, 9], edge_index=[2, 158], edge_attr=[158, 3], y=[1, 1], num_nodes=74), Data(x=[74, 9], edge_index=[2, 158], edge_attr=[158, 3], y=[1, 1], num_nodes=74), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[26, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=26), Data(x=[38, 9], edge_index=[2, 86], edge_attr=[86, 3], y=[1, 1], num_nodes=38), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[31, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=31), Data(x=[36, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=36), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[40, 9], edge_index=[2, 84], edge_attr=[84, 3], y=[1, 1], num_nodes=40), Data(x=[65, 9], edge_index=[2, 134], edge_attr=[134, 3], y=[1, 1], num_nodes=65), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[35, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=35), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[37, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=37), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[117, 9], edge_index=[2, 248], edge_attr=[248, 3], y=[1, 1], num_nodes=117), Data(x=[35, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=35), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[94, 9], edge_index=[2, 196], edge_attr=[196, 3], y=[1, 1], num_nodes=94), Data(x=[77, 9], edge_index=[2, 164], edge_attr=[164, 3], y=[1, 1], num_nodes=77), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[18, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=18), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[35, 9], edge_index=[2, 78], edge_attr=[78, 3], y=[1, 1], num_nodes=35), Data(x=[30, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=30), Data(x=[27, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=27), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[24, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=24), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[25, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=25), Data(x=[22, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=22), Data(x=[30, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=30), Data(x=[24, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=24), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[27, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=27), Data(x=[34, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=34), Data(x=[13, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=13), Data(x=[35, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=35), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[36, 9], edge_index=[2, 80], edge_attr=[80, 3], y=[1, 1], num_nodes=36), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[52, 9], edge_index=[2, 120], edge_attr=[120, 3], y=[1, 1], num_nodes=52), Data(x=[57, 9], edge_index=[2, 120], edge_attr=[120, 3], y=[1, 1], num_nodes=57), Data(x=[47, 9], edge_index=[2, 100], edge_attr=[100, 3], y=[1, 1], num_nodes=47), Data(x=[66, 9], edge_index=[2, 148], edge_attr=[148, 3], y=[1, 1], num_nodes=66), Data(x=[44, 9], edge_index=[2, 94], edge_attr=[94, 3], y=[1, 1], num_nodes=44), Data(x=[65, 9], edge_index=[2, 132], edge_attr=[132, 3], y=[1, 1], num_nodes=65), Data(x=[79, 9], edge_index=[2, 164], edge_attr=[164, 3], y=[1, 1], num_nodes=79), Data(x=[33, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=33), Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=19), Data(x=[38, 9], edge_index=[2, 88], edge_attr=[88, 3], y=[1, 1], num_nodes=38), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[136, 9], edge_index=[2, 286], edge_attr=[286, 3], y=[1, 1], num_nodes=136), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[43, 9], edge_index=[2, 100], edge_attr=[100, 3], y=[1, 1], num_nodes=43), Data(x=[43, 9], edge_index=[2, 100], edge_attr=[100, 3], y=[1, 1], num_nodes=43), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[21, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=21), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[16, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=16), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[11, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=11), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[16, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[17, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=17), Data(x=[8, 9], edge_index=[2, 16], edge_attr=[16, 3], y=[1, 1], num_nodes=8), Data(x=[14, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=14), Data(x=[12, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=12), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[16, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=16), Data(x=[15, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=15), Data(x=[18, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=18), Data(x=[19, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=19), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[92, 9], edge_index=[2, 196], edge_attr=[196, 3], y=[1, 1], num_nodes=92), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[18, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], num_nodes=18), Data(x=[20, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=20), Data(x=[12, 9], edge_index=[2, 26], edge_attr=[26, 3], y=[1, 1], num_nodes=12), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[28, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=28), Data(x=[35, 9], edge_index=[2, 82], edge_attr=[82, 3], y=[1, 1], num_nodes=35), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[24, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=24), Data(x=[15, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=15), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[31, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=31), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[34, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=34), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[26, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=26), Data(x=[20, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=20), Data(x=[30, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=30), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[13, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=13), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[18, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=18), Data(x=[30, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=30), Data(x=[19, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=19), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[23, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=23), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[25, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=25), Data(x=[29, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=29), Data(x=[32, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=32), Data(x=[14, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=14), Data(x=[27, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=27), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[28, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=28), Data(x=[42, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=42), Data(x=[22, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=22), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[11, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=11), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=33), Data(x=[26, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=26), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[34, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=34), Data(x=[11, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=11), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[34, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=34), Data(x=[29, 9], edge_index=[2, 64], edge_attr=[64, 3], y=[1, 1], num_nodes=29), Data(x=[24, 9], edge_index=[2, 52], edge_attr=[52, 3], y=[1, 1], num_nodes=24), Data(x=[36, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=36), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[34, 9], edge_index=[2, 76], edge_attr=[76, 3], y=[1, 1], num_nodes=34), Data(x=[26, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=26), Data(x=[32, 9], edge_index=[2, 68], edge_attr=[68, 3], y=[1, 1], num_nodes=32), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[26, 9], edge_index=[2, 62], edge_attr=[62, 3], y=[1, 1], num_nodes=26), Data(x=[13, 9], edge_index=[2, 20], edge_attr=[20, 3], y=[1, 1], num_nodes=13), Data(x=[28, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=28), Data(x=[22, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=22), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[23, 9], edge_index=[2, 50], edge_attr=[50, 3], y=[1, 1], num_nodes=23), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[21, 9], edge_index=[2, 44], edge_attr=[44, 3], y=[1, 1], num_nodes=21), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22), Data(x=[16, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=17), Data(x=[16, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=16), Data(x=[17, 9], edge_index=[2, 36], edge_attr=[36, 3], y=[1, 1], num_nodes=17), Data(x=[25, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=25), Data(x=[30, 9], edge_index=[2, 66], edge_attr=[66, 3], y=[1, 1], num_nodes=30), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[18, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=18), Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=24), Data(x=[27, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=27), Data(x=[10, 9], edge_index=[2, 22], edge_attr=[22, 3], y=[1, 1], num_nodes=10), Data(x=[27, 9], edge_index=[2, 58], edge_attr=[58, 3], y=[1, 1], num_nodes=27), Data(x=[122, 9], edge_index=[2, 264], edge_attr=[264, 3], y=[1, 1], num_nodes=122), Data(x=[28, 9], edge_index=[2, 60], edge_attr=[60, 3], y=[1, 1], num_nodes=28), Data(x=[44, 9], edge_index=[2, 90], edge_attr=[90, 3], y=[1, 1], num_nodes=44), Data(x=[34, 9], edge_index=[2, 70], edge_attr=[70, 3], y=[1, 1], num_nodes=34), Data(x=[26, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=26), Data(x=[15, 9], edge_index=[2, 32], edge_attr=[32, 3], y=[1, 1], num_nodes=15), Data(x=[17, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 1], num_nodes=17), Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], y=[1, 1], num_nodes=16), Data(x=[7, 9], edge_index=[2, 14], edge_attr=[14, 3], y=[1, 1], num_nodes=7), Data(x=[35, 9], edge_index=[2, 72], edge_attr=[72, 3], y=[1, 1], num_nodes=35), Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], num_nodes=14), Data(x=[23, 9], edge_index=[2, 54], edge_attr=[54, 3], y=[1, 1], num_nodes=23), Data(x=[36, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=36), Data(x=[20, 9], edge_index=[2, 42], edge_attr=[42, 3], y=[1, 1], num_nodes=20), Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=21), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], num_nodes=23), Data(x=[12, 9], edge_index=[2, 24], edge_attr=[24, 3], y=[1, 1], num_nodes=12), Data(x=[35, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], num_nodes=35), Data(x=[13, 9], edge_index=[2, 28], edge_attr=[28, 3], y=[1, 1], num_nodes=13), Data(x=[27, 9], edge_index=[2, 56], edge_attr=[56, 3], y=[1, 1], num_nodes=27), Data(x=[22, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], num_nodes=22)]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import torch_geometric\n",
        "# Load Data object from file\n",
        "with open('/content/drive/MyDrive/clintox.pt', 'rb') as f:\n",
        "    all_data = pickle.load(f)\n",
        "\n",
        "# Now loaded_data contains the Data object\n",
        "print(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nzQS4IfKzcC9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import stellargraph as sg\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "from stellargraph.data import BiasedRandomWalk\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, features=node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, attributes=edge_attributes)\n",
        "\n",
        "    return G, y.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZBWOStOXUU8"
      },
      "source": [
        "#Node2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxkjURhnXcIv"
      },
      "source": [
        "Construction of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "7I_OdnXOCqE8",
        "outputId": "3facc80a-4827-45a5-a393-755f826ad793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0\n",
            "size 0 data: 1443\n",
            "size 1 data: 1443\n",
            "size total dataset: 2886\n",
            "2886\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-541343bf41e6>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mrw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBiasedRandomWalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     walks = rw.run(\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# root nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# maximum length of a random walk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stellargraph/data/explorer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, nodes, n, length, p, q, seed, weighted)\u001b[0m\n\u001b[1;32m    485\u001b[0m                     \u001b[0;31m# appropriate transition probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                         neighbours, weights = self.graph.neighbor_arrays(\n\u001b[0m\u001b[1;32m    488\u001b[0m                             \u001b[0mcurrent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_edge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ilocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stellargraph/core/graph.py\u001b[0m in \u001b[0;36mneighbor_arrays\u001b[0;34m(self, node, include_edge_weight, edge_types, use_ilocs)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_ilocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_ilocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0mother_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         return self._transform_edges(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import copy\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "label_0_indices = []\n",
        "label_1_indices = []\n",
        "dfs = []\n",
        "\n",
        "for i in range(len(all_data)):\n",
        "  if all_data[i].y == 0:\n",
        "    label_0_indices.append(i)\n",
        "  elif all_data[i].y == 1:\n",
        "    label_1_indices.append(i)\n",
        "\n",
        "for iter in range(5):\n",
        "  print('iter:', iter)\n",
        "\n",
        "  min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "  random.shuffle(label_0_indices)\n",
        "  random.shuffle(label_1_indices)\n",
        "  label_0_indices = label_0_indices[:min_size_dataset]\n",
        "  label_1_indices = label_1_indices[:min_size_dataset]\n",
        "  print('size 0 data:' , len(label_0_indices))\n",
        "  print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "  balanced_indices = label_0_indices + label_1_indices\n",
        "  print('size total dataset:' , len(balanced_indices))\n",
        "\n",
        "  balanced_data = [all_data[i] for i in balanced_indices]\n",
        "  print(len(balanced_data))\n",
        "\n",
        "  df = pd.DataFrame(columns = ['emb','label'])\n",
        "\n",
        "  for dtb in balanced_data:\n",
        "    graph,y = create_networkx_graph(dtb.edge_index, dtb.edge_attr, dtb.x, dtb.y, dtb.num_nodes)\n",
        "        # Convert node features to DataFrame\n",
        "    node_features_dict = {node: graph.nodes[node]['features'] for node in graph.nodes}\n",
        "    node_df = pd.DataFrame.from_dict(node_features_dict, orient='index')\n",
        "\n",
        "        # Convert edge attributes to DataFrame\n",
        "    edge_features_dict = {(src, dst): data['attributes'] for src, dst, data in graph.edges(data=True)}\n",
        "    edge_df = pd.DataFrame.from_dict(edge_features_dict, orient='index')\n",
        "\n",
        "        # Create 'source', 'target' columns in the edge DataFrame\n",
        "    edge_df['source'] = [edge[0] for edge in edge_df.index]\n",
        "    edge_df['target'] = [edge[1] for edge in edge_df.index]\n",
        "\n",
        "        # Create a StellarGraph from the NetworkX graph and DataFrames\n",
        "    Gs = sg.StellarGraph(nodes=node_df, edges=edge_df)\n",
        "\n",
        "    rw = BiasedRandomWalk(Gs)\n",
        "\n",
        "    walks = rw.run(\n",
        "        nodes=list(Gs.nodes()),  # root nodes\n",
        "        length=100,  # maximum length of a random walk\n",
        "        n=10,  # number of random walks per root node\n",
        "        p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
        "        q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
        "        weighted=True,\n",
        "        seed = 42\n",
        "    )\n",
        "\n",
        "    str_walks = [[str(n) for n in walk] for walk in walks]\n",
        "    model = Word2Vec(str_walks, window=5, min_count=0, sg=1, workers=2)\n",
        "\n",
        "        # Retrieve node embeddings and corresponding subjects\n",
        "    node_ids = model.wv.index_to_key  # list of node IDs\n",
        "    node_embeddings = (\n",
        "        model.wv.vectors\n",
        "    )  # numpy.ndarray of size number of nodes times embeddings dimensionality\n",
        "\n",
        "    df.loc[len(df)] = [node_embeddings, y]\n",
        "  #df.to_pickle('/content/drive/MyDrive/emb_bbbp_node2vec_data_' + str(iter + 1) + '.pkl')\n",
        "  #print(df)\n",
        "  dfs.append(df)\n",
        "  #se va tutto bene poi questo break si toglie e si fa per tuti i kfold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Udl-HSNsLnu"
      },
      "source": [
        "Creation of the Model for classification on the Embedding data given from node2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMg83xsGuhn7"
      },
      "outputs": [],
      "source": [
        "# Define a function to create and compile your model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def create_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(222, 100)),\n",
        "    layers.Dropout(0.3),  # Adding dropout for regularization\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),  # Adding dropout for regularization\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.3),  # Adding dropout for regularization\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVeC_w4UsjDq"
      },
      "source": [
        "5 k-fold on 5 datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvjMtzYbuJxl",
        "outputId": "d608da4b-9b3b-47a4-db8b-69aa2436fda1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6723 - accuracy: 0.5319 - val_loss: 0.6956 - val_accuracy: 0.5440\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6715 - accuracy: 0.5324 - val_loss: 0.6985 - val_accuracy: 0.5444\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6711 - accuracy: 0.5329 - val_loss: 0.6993 - val_accuracy: 0.5438\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6707 - accuracy: 0.5331 - val_loss: 0.6974 - val_accuracy: 0.5437\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6702 - accuracy: 0.5333 - val_loss: 0.6968 - val_accuracy: 0.5435\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6699 - accuracy: 0.5334 - val_loss: 0.6967 - val_accuracy: 0.5442\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6698 - accuracy: 0.5337 - val_loss: 0.6988 - val_accuracy: 0.5440\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6694 - accuracy: 0.5340 - val_loss: 0.6997 - val_accuracy: 0.5430\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6692 - accuracy: 0.5341 - val_loss: 0.6985 - val_accuracy: 0.5436\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6687 - accuracy: 0.5345 - val_loss: 0.7002 - val_accuracy: 0.5433\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6686 - accuracy: 0.5346 - val_loss: 0.6997 - val_accuracy: 0.5432\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6683 - accuracy: 0.5350 - val_loss: 0.7013 - val_accuracy: 0.5439\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6684 - accuracy: 0.5346 - val_loss: 0.7037 - val_accuracy: 0.5433\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6682 - accuracy: 0.5350 - val_loss: 0.6996 - val_accuracy: 0.5429\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6674 - accuracy: 0.5357 - val_loss: 0.7038 - val_accuracy: 0.5438\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6672 - accuracy: 0.5354 - val_loss: 0.7017 - val_accuracy: 0.5429\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 3s 44ms/step - loss: 0.6670 - accuracy: 0.5357 - val_loss: 0.7079 - val_accuracy: 0.5433\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6670 - accuracy: 0.5357 - val_loss: 0.7037 - val_accuracy: 0.5426\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6666 - accuracy: 0.5372 - val_loss: 0.7105 - val_accuracy: 0.4859\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6684 - accuracy: 0.5193 - val_loss: 0.7016 - val_accuracy: 0.5437\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6666 - accuracy: 0.5361 - val_loss: 0.7085 - val_accuracy: 0.5436\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6671 - accuracy: 0.5299 - val_loss: 0.7062 - val_accuracy: 0.4871\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6662 - accuracy: 0.5324 - val_loss: 0.7066 - val_accuracy: 0.5435\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6659 - accuracy: 0.5365 - val_loss: 0.7081 - val_accuracy: 0.5438\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6656 - accuracy: 0.5368 - val_loss: 0.7038 - val_accuracy: 0.5438\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6656 - accuracy: 0.5366 - val_loss: 0.7054 - val_accuracy: 0.5428\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6653 - accuracy: 0.5367 - val_loss: 0.7076 - val_accuracy: 0.5434\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6656 - accuracy: 0.5368 - val_loss: 0.7088 - val_accuracy: 0.5432\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 3s 44ms/step - loss: 0.6652 - accuracy: 0.5370 - val_loss: 0.7110 - val_accuracy: 0.5435\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6647 - accuracy: 0.5374 - val_loss: 0.7076 - val_accuracy: 0.5429\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6647 - accuracy: 0.5375 - val_loss: 0.7095 - val_accuracy: 0.5434\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6647 - accuracy: 0.5373 - val_loss: 0.7102 - val_accuracy: 0.5439\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 3s 44ms/step - loss: 0.6646 - accuracy: 0.5376 - val_loss: 0.7071 - val_accuracy: 0.5432\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6651 - accuracy: 0.5373 - val_loss: 0.7090 - val_accuracy: 0.5428\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6642 - accuracy: 0.5379 - val_loss: 0.7102 - val_accuracy: 0.5440\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6641 - accuracy: 0.5379 - val_loss: 0.7100 - val_accuracy: 0.5435\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6638 - accuracy: 0.5382 - val_loss: 0.7115 - val_accuracy: 0.5442\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6636 - accuracy: 0.5384 - val_loss: 0.7138 - val_accuracy: 0.5436\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6633 - accuracy: 0.5383 - val_loss: 0.7108 - val_accuracy: 0.5431\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6634 - accuracy: 0.5381 - val_loss: 0.7142 - val_accuracy: 0.5435\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6632 - accuracy: 0.5384 - val_loss: 0.7138 - val_accuracy: 0.5435\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6628 - accuracy: 0.5384 - val_loss: 0.7158 - val_accuracy: 0.5432\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6628 - accuracy: 0.5383 - val_loss: 0.7163 - val_accuracy: 0.5435\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6629 - accuracy: 0.5387 - val_loss: 0.7151 - val_accuracy: 0.5431\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6628 - accuracy: 0.5388 - val_loss: 0.7128 - val_accuracy: 0.5433\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6627 - accuracy: 0.5385 - val_loss: 0.7147 - val_accuracy: 0.5425\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6627 - accuracy: 0.5388 - val_loss: 0.7134 - val_accuracy: 0.5431\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6623 - accuracy: 0.5390 - val_loss: 0.7148 - val_accuracy: 0.5427\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 76ms/step - loss: 0.6626 - accuracy: 0.5391 - val_loss: 0.7150 - val_accuracy: 0.5427\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6620 - accuracy: 0.5393 - val_loss: 0.7189 - val_accuracy: 0.5431\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6619 - accuracy: 0.5391 - val_loss: 0.7156 - val_accuracy: 0.5430\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6621 - accuracy: 0.5393 - val_loss: 0.7124 - val_accuracy: 0.5424\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6622 - accuracy: 0.5391 - val_loss: 0.7143 - val_accuracy: 0.5425\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6616 - accuracy: 0.5396 - val_loss: 0.7140 - val_accuracy: 0.5425\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 3s 44ms/step - loss: 0.6619 - accuracy: 0.5394 - val_loss: 0.7164 - val_accuracy: 0.5427\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6614 - accuracy: 0.5398 - val_loss: 0.7153 - val_accuracy: 0.5430\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6612 - accuracy: 0.5399 - val_loss: 0.7156 - val_accuracy: 0.5427\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6616 - accuracy: 0.5397 - val_loss: 0.7156 - val_accuracy: 0.5430\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.6614 - accuracy: 0.5397 - val_loss: 0.7175 - val_accuracy: 0.5427\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6613 - accuracy: 0.5399 - val_loss: 0.7154 - val_accuracy: 0.5428\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6617 - accuracy: 0.5407 - val_loss: 0.7164 - val_accuracy: 0.5438\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6608 - accuracy: 0.5400 - val_loss: 0.7175 - val_accuracy: 0.5431\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6614 - accuracy: 0.5340 - val_loss: 0.7157 - val_accuracy: 0.5429\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6608 - accuracy: 0.5398 - val_loss: 0.7178 - val_accuracy: 0.5429\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6608 - accuracy: 0.5399 - val_loss: 0.7194 - val_accuracy: 0.5438\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6605 - accuracy: 0.5403 - val_loss: 0.7185 - val_accuracy: 0.5432\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6602 - accuracy: 0.5405 - val_loss: 0.7164 - val_accuracy: 0.5428\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6608 - accuracy: 0.5401 - val_loss: 0.7176 - val_accuracy: 0.5437\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6601 - accuracy: 0.5404 - val_loss: 0.7206 - val_accuracy: 0.5427\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6600 - accuracy: 0.5404 - val_loss: 0.7200 - val_accuracy: 0.5433\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6603 - accuracy: 0.5403 - val_loss: 0.7185 - val_accuracy: 0.5431\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6600 - accuracy: 0.5405 - val_loss: 0.7169 - val_accuracy: 0.5430\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6602 - accuracy: 0.5404 - val_loss: 0.7193 - val_accuracy: 0.5432\n",
            "19/19 [==============================] - 1s 13ms/step - loss: 0.7199 - accuracy: 0.5429\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 5s 55ms/step - loss: 0.6907 - accuracy: 0.4969 - val_loss: 0.6910 - val_accuracy: 0.5287\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6871 - accuracy: 0.5204 - val_loss: 0.6900 - val_accuracy: 0.5326\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6856 - accuracy: 0.5229 - val_loss: 0.6922 - val_accuracy: 0.5326\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6846 - accuracy: 0.5237 - val_loss: 0.6922 - val_accuracy: 0.5330\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 7s 98ms/step - loss: 0.6833 - accuracy: 0.5246 - val_loss: 0.6929 - val_accuracy: 0.5334\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6825 - accuracy: 0.5255 - val_loss: 0.6908 - val_accuracy: 0.5347\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6816 - accuracy: 0.5264 - val_loss: 0.6920 - val_accuracy: 0.5343\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6809 - accuracy: 0.5266 - val_loss: 0.6904 - val_accuracy: 0.5348\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6801 - accuracy: 0.5274 - val_loss: 0.6906 - val_accuracy: 0.5335\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6797 - accuracy: 0.5280 - val_loss: 0.6918 - val_accuracy: 0.5351\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6789 - accuracy: 0.5285 - val_loss: 0.6924 - val_accuracy: 0.5351\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6785 - accuracy: 0.5286 - val_loss: 0.6943 - val_accuracy: 0.5348\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6778 - accuracy: 0.5292 - val_loss: 0.6934 - val_accuracy: 0.5350\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6772 - accuracy: 0.5298 - val_loss: 0.6935 - val_accuracy: 0.5351\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6769 - accuracy: 0.5299 - val_loss: 0.6935 - val_accuracy: 0.5338\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6767 - accuracy: 0.5303 - val_loss: 0.6971 - val_accuracy: 0.5344\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6758 - accuracy: 0.5306 - val_loss: 0.6954 - val_accuracy: 0.5347\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6754 - accuracy: 0.5311 - val_loss: 0.6974 - val_accuracy: 0.5345\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6752 - accuracy: 0.5316 - val_loss: 0.6975 - val_accuracy: 0.5339\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6747 - accuracy: 0.5315 - val_loss: 0.6972 - val_accuracy: 0.5341\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6743 - accuracy: 0.5318 - val_loss: 0.6969 - val_accuracy: 0.5328\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6738 - accuracy: 0.5324 - val_loss: 0.6989 - val_accuracy: 0.5340\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6732 - accuracy: 0.5327 - val_loss: 0.7000 - val_accuracy: 0.5340\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6728 - accuracy: 0.5331 - val_loss: 0.7055 - val_accuracy: 0.5350\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6727 - accuracy: 0.5332 - val_loss: 0.7006 - val_accuracy: 0.5346\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6723 - accuracy: 0.5333 - val_loss: 0.7030 - val_accuracy: 0.5344\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6721 - accuracy: 0.5336 - val_loss: 0.7004 - val_accuracy: 0.5338\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6714 - accuracy: 0.5339 - val_loss: 0.7038 - val_accuracy: 0.5349\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6712 - accuracy: 0.5345 - val_loss: 0.7040 - val_accuracy: 0.5343\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6710 - accuracy: 0.5343 - val_loss: 0.7107 - val_accuracy: 0.5345\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6707 - accuracy: 0.5348 - val_loss: 0.7064 - val_accuracy: 0.5347\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6706 - accuracy: 0.5344 - val_loss: 0.7056 - val_accuracy: 0.5345\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6700 - accuracy: 0.5355 - val_loss: 0.7054 - val_accuracy: 0.5339\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6701 - accuracy: 0.5352 - val_loss: 0.7085 - val_accuracy: 0.5340\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6693 - accuracy: 0.5357 - val_loss: 0.7112 - val_accuracy: 0.5341\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6695 - accuracy: 0.5356 - val_loss: 0.7056 - val_accuracy: 0.5337\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6691 - accuracy: 0.5359 - val_loss: 0.7123 - val_accuracy: 0.5341\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6686 - accuracy: 0.5363 - val_loss: 0.7098 - val_accuracy: 0.5335\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6687 - accuracy: 0.5360 - val_loss: 0.7091 - val_accuracy: 0.5334\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6686 - accuracy: 0.5362 - val_loss: 0.7074 - val_accuracy: 0.5331\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6680 - accuracy: 0.5366 - val_loss: 0.7133 - val_accuracy: 0.5339\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6675 - accuracy: 0.5369 - val_loss: 0.7195 - val_accuracy: 0.5342\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6679 - accuracy: 0.5366 - val_loss: 0.7119 - val_accuracy: 0.5335\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6676 - accuracy: 0.5373 - val_loss: 0.7116 - val_accuracy: 0.5338\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6673 - accuracy: 0.5308 - val_loss: 0.7123 - val_accuracy: 0.5333\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6672 - accuracy: 0.5373 - val_loss: 0.7146 - val_accuracy: 0.5333\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6665 - accuracy: 0.5379 - val_loss: 0.7162 - val_accuracy: 0.5333\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6676 - accuracy: 0.5373 - val_loss: 0.7169 - val_accuracy: 0.5341\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6670 - accuracy: 0.5374 - val_loss: 0.7151 - val_accuracy: 0.5339\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6659 - accuracy: 0.5380 - val_loss: 0.7176 - val_accuracy: 0.5339\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6663 - accuracy: 0.5377 - val_loss: 0.7137 - val_accuracy: 0.5339\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6659 - accuracy: 0.5383 - val_loss: 0.7235 - val_accuracy: 0.5339\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6654 - accuracy: 0.5383 - val_loss: 0.7157 - val_accuracy: 0.5334\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6650 - accuracy: 0.5390 - val_loss: 0.7227 - val_accuracy: 0.5339\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6657 - accuracy: 0.5386 - val_loss: 0.7181 - val_accuracy: 0.5337\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6653 - accuracy: 0.5387 - val_loss: 0.7148 - val_accuracy: 0.5336\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6647 - accuracy: 0.5391 - val_loss: 0.7190 - val_accuracy: 0.5339\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6648 - accuracy: 0.5389 - val_loss: 0.7160 - val_accuracy: 0.5331\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6642 - accuracy: 0.5395 - val_loss: 0.7173 - val_accuracy: 0.5332\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6645 - accuracy: 0.5386 - val_loss: 0.7212 - val_accuracy: 0.5338\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6644 - accuracy: 0.5394 - val_loss: 0.7243 - val_accuracy: 0.5337\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6641 - accuracy: 0.5393 - val_loss: 0.7193 - val_accuracy: 0.5331\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6646 - accuracy: 0.5395 - val_loss: 0.7235 - val_accuracy: 0.5331\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6637 - accuracy: 0.5398 - val_loss: 0.7237 - val_accuracy: 0.5333\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6639 - accuracy: 0.5396 - val_loss: 0.7202 - val_accuracy: 0.5332\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6639 - accuracy: 0.5397 - val_loss: 0.7189 - val_accuracy: 0.5336\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6635 - accuracy: 0.5400 - val_loss: 0.7251 - val_accuracy: 0.5339\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6636 - accuracy: 0.5398 - val_loss: 0.7261 - val_accuracy: 0.5341\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6635 - accuracy: 0.5398 - val_loss: 0.7218 - val_accuracy: 0.5328\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6631 - accuracy: 0.5401 - val_loss: 0.7235 - val_accuracy: 0.5331\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6630 - accuracy: 0.5402 - val_loss: 0.7239 - val_accuracy: 0.5338\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6631 - accuracy: 0.5402 - val_loss: 0.7243 - val_accuracy: 0.5332\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6626 - accuracy: 0.5404 - val_loss: 0.7275 - val_accuracy: 0.5339\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6624 - accuracy: 0.5406 - val_loss: 0.7276 - val_accuracy: 0.5335\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6630 - accuracy: 0.5412 - val_loss: 0.7232 - val_accuracy: 0.5329\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6630 - accuracy: 0.5384 - val_loss: 0.7276 - val_accuracy: 0.5339\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6625 - accuracy: 0.5405 - val_loss: 0.7294 - val_accuracy: 0.5337\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6627 - accuracy: 0.5406 - val_loss: 0.7287 - val_accuracy: 0.5337\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6625 - accuracy: 0.5375 - val_loss: 0.7289 - val_accuracy: 0.5340\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6622 - accuracy: 0.5410 - val_loss: 0.7274 - val_accuracy: 0.5334\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6617 - accuracy: 0.5412 - val_loss: 0.7264 - val_accuracy: 0.5337\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6617 - accuracy: 0.5412 - val_loss: 0.7292 - val_accuracy: 0.5329\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6616 - accuracy: 0.5413 - val_loss: 0.7283 - val_accuracy: 0.5329\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6616 - accuracy: 0.5412 - val_loss: 0.7323 - val_accuracy: 0.5338\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6614 - accuracy: 0.5415 - val_loss: 0.7312 - val_accuracy: 0.5334\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6616 - accuracy: 0.5408 - val_loss: 0.7272 - val_accuracy: 0.5327\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6617 - accuracy: 0.5412 - val_loss: 0.7341 - val_accuracy: 0.5340\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6613 - accuracy: 0.5419 - val_loss: 0.7304 - val_accuracy: 0.5328\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6616 - accuracy: 0.5392 - val_loss: 0.7289 - val_accuracy: 0.5333\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6608 - accuracy: 0.5418 - val_loss: 0.7257 - val_accuracy: 0.5327\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6613 - accuracy: 0.5416 - val_loss: 0.7292 - val_accuracy: 0.5330\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6609 - accuracy: 0.5418 - val_loss: 0.7306 - val_accuracy: 0.5334\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6608 - accuracy: 0.5418 - val_loss: 0.7279 - val_accuracy: 0.5326\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6610 - accuracy: 0.5417 - val_loss: 0.7280 - val_accuracy: 0.5328\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6607 - accuracy: 0.5419 - val_loss: 0.7270 - val_accuracy: 0.5331\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6607 - accuracy: 0.5417 - val_loss: 0.7339 - val_accuracy: 0.5337\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6606 - accuracy: 0.5421 - val_loss: 0.7318 - val_accuracy: 0.5334\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6609 - accuracy: 0.5419 - val_loss: 0.7334 - val_accuracy: 0.5335\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6604 - accuracy: 0.5421 - val_loss: 0.7300 - val_accuracy: 0.5322\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6601 - accuracy: 0.5425 - val_loss: 0.7314 - val_accuracy: 0.5328\n",
            "19/19 [==============================] - 1s 13ms/step - loss: 0.7323 - accuracy: 0.5327\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 5s 50ms/step - loss: 0.6906 - accuracy: 0.5214 - val_loss: 0.6892 - val_accuracy: 0.5009\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6874 - accuracy: 0.5292 - val_loss: 0.6878 - val_accuracy: 0.5006\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6865 - accuracy: 0.5310 - val_loss: 0.6859 - val_accuracy: 0.5024\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6851 - accuracy: 0.5321 - val_loss: 0.6854 - val_accuracy: 0.5024\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6843 - accuracy: 0.5328 - val_loss: 0.6853 - val_accuracy: 0.5024\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6830 - accuracy: 0.5340 - val_loss: 0.6868 - val_accuracy: 0.5007\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6822 - accuracy: 0.5352 - val_loss: 0.6856 - val_accuracy: 0.5027\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6815 - accuracy: 0.5355 - val_loss: 0.6853 - val_accuracy: 0.5028\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6808 - accuracy: 0.5357 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6802 - accuracy: 0.5367 - val_loss: 0.6862 - val_accuracy: 0.5010\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6791 - accuracy: 0.5374 - val_loss: 0.6874 - val_accuracy: 0.4985\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6788 - accuracy: 0.5379 - val_loss: 0.6873 - val_accuracy: 0.4994\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6780 - accuracy: 0.5385 - val_loss: 0.6870 - val_accuracy: 0.5017\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6773 - accuracy: 0.5390 - val_loss: 0.6884 - val_accuracy: 0.4984\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6766 - accuracy: 0.5394 - val_loss: 0.6885 - val_accuracy: 0.4987\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6764 - accuracy: 0.5397 - val_loss: 0.6896 - val_accuracy: 0.4990\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6756 - accuracy: 0.5401 - val_loss: 0.6893 - val_accuracy: 0.4981\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6751 - accuracy: 0.5403 - val_loss: 0.6908 - val_accuracy: 0.4965\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6748 - accuracy: 0.5409 - val_loss: 0.6909 - val_accuracy: 0.4989\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6742 - accuracy: 0.5409 - val_loss: 0.6908 - val_accuracy: 0.4996\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6739 - accuracy: 0.5416 - val_loss: 0.6913 - val_accuracy: 0.4974\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6734 - accuracy: 0.5418 - val_loss: 0.6913 - val_accuracy: 0.4984\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6729 - accuracy: 0.5423 - val_loss: 0.6954 - val_accuracy: 0.4997\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6733 - accuracy: 0.5419 - val_loss: 0.6916 - val_accuracy: 0.4989\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6722 - accuracy: 0.5424 - val_loss: 0.6936 - val_accuracy: 0.4986\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6718 - accuracy: 0.5429 - val_loss: 0.6940 - val_accuracy: 0.4958\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6716 - accuracy: 0.5430 - val_loss: 0.6922 - val_accuracy: 0.4979\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6714 - accuracy: 0.5431 - val_loss: 0.6941 - val_accuracy: 0.4971\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6709 - accuracy: 0.5435 - val_loss: 0.6948 - val_accuracy: 0.4985\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6709 - accuracy: 0.5434 - val_loss: 0.6947 - val_accuracy: 0.4974\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6702 - accuracy: 0.5440 - val_loss: 0.6942 - val_accuracy: 0.4981\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6697 - accuracy: 0.5443 - val_loss: 0.6939 - val_accuracy: 0.4979\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6699 - accuracy: 0.5442 - val_loss: 0.6945 - val_accuracy: 0.4968\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6698 - accuracy: 0.5441 - val_loss: 0.6981 - val_accuracy: 0.4954\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6696 - accuracy: 0.5445 - val_loss: 0.6958 - val_accuracy: 0.4992\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6689 - accuracy: 0.5448 - val_loss: 0.6951 - val_accuracy: 0.4983\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6688 - accuracy: 0.5451 - val_loss: 0.6962 - val_accuracy: 0.4989\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6688 - accuracy: 0.5450 - val_loss: 0.6961 - val_accuracy: 0.4983\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6682 - accuracy: 0.5452 - val_loss: 0.6966 - val_accuracy: 0.4989\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6678 - accuracy: 0.5458 - val_loss: 0.6977 - val_accuracy: 0.4969\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6675 - accuracy: 0.5457 - val_loss: 0.6983 - val_accuracy: 0.4976\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6674 - accuracy: 0.5459 - val_loss: 0.6986 - val_accuracy: 0.4975\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6674 - accuracy: 0.5461 - val_loss: 0.6975 - val_accuracy: 0.4969\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6673 - accuracy: 0.5428 - val_loss: 0.7006 - val_accuracy: 0.4975\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6670 - accuracy: 0.5464 - val_loss: 0.6994 - val_accuracy: 0.4979\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6672 - accuracy: 0.5466 - val_loss: 0.6989 - val_accuracy: 0.4967\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6669 - accuracy: 0.5464 - val_loss: 0.6995 - val_accuracy: 0.4973\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 9s 123ms/step - loss: 0.6662 - accuracy: 0.5469 - val_loss: 0.6989 - val_accuracy: 0.4974\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6660 - accuracy: 0.5469 - val_loss: 0.7010 - val_accuracy: 0.4988\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6656 - accuracy: 0.5473 - val_loss: 0.7001 - val_accuracy: 0.4976\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6655 - accuracy: 0.5474 - val_loss: 0.6998 - val_accuracy: 0.4986\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6655 - accuracy: 0.5474 - val_loss: 0.6998 - val_accuracy: 0.4978\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6651 - accuracy: 0.5475 - val_loss: 0.7012 - val_accuracy: 0.4988\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6650 - accuracy: 0.5474 - val_loss: 0.7012 - val_accuracy: 0.4968\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6650 - accuracy: 0.5477 - val_loss: 0.7019 - val_accuracy: 0.4985\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6647 - accuracy: 0.5478 - val_loss: 0.7025 - val_accuracy: 0.4984\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 3s 45ms/step - loss: 0.6645 - accuracy: 0.5480 - val_loss: 0.7029 - val_accuracy: 0.4973\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6643 - accuracy: 0.5480 - val_loss: 0.7035 - val_accuracy: 0.4991\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6642 - accuracy: 0.5481 - val_loss: 0.7020 - val_accuracy: 0.4985\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6644 - accuracy: 0.5480 - val_loss: 0.7013 - val_accuracy: 0.4980\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6637 - accuracy: 0.5483 - val_loss: 0.7015 - val_accuracy: 0.4977\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6640 - accuracy: 0.5485 - val_loss: 0.7022 - val_accuracy: 0.4980\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6633 - accuracy: 0.5489 - val_loss: 0.7039 - val_accuracy: 0.4974\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6634 - accuracy: 0.5485 - val_loss: 0.7030 - val_accuracy: 0.4971\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6632 - accuracy: 0.5489 - val_loss: 0.7051 - val_accuracy: 0.4988\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6633 - accuracy: 0.5487 - val_loss: 0.7045 - val_accuracy: 0.4978\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6628 - accuracy: 0.5489 - val_loss: 0.7054 - val_accuracy: 0.4976\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6628 - accuracy: 0.5492 - val_loss: 0.7049 - val_accuracy: 0.4989\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6627 - accuracy: 0.5491 - val_loss: 0.7058 - val_accuracy: 0.4988\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6626 - accuracy: 0.5490 - val_loss: 0.7050 - val_accuracy: 0.4976\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6624 - accuracy: 0.5493 - val_loss: 0.7073 - val_accuracy: 0.4973\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6621 - accuracy: 0.5498 - val_loss: 0.7066 - val_accuracy: 0.4973\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6622 - accuracy: 0.5495 - val_loss: 0.7073 - val_accuracy: 0.4994\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6625 - accuracy: 0.5493 - val_loss: 0.7050 - val_accuracy: 0.4965\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6623 - accuracy: 0.5496 - val_loss: 0.7046 - val_accuracy: 0.4982\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6617 - accuracy: 0.5495 - val_loss: 0.7077 - val_accuracy: 0.4990\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6618 - accuracy: 0.5498 - val_loss: 0.7062 - val_accuracy: 0.4979\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6617 - accuracy: 0.5501 - val_loss: 0.7058 - val_accuracy: 0.4982\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6614 - accuracy: 0.5498 - val_loss: 0.7079 - val_accuracy: 0.4975\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6611 - accuracy: 0.5501 - val_loss: 0.7069 - val_accuracy: 0.4973\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6615 - accuracy: 0.5498 - val_loss: 0.7061 - val_accuracy: 0.4972\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6614 - accuracy: 0.5502 - val_loss: 0.7068 - val_accuracy: 0.4978\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6609 - accuracy: 0.5504 - val_loss: 0.7067 - val_accuracy: 0.4987\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6613 - accuracy: 0.5505 - val_loss: 0.7063 - val_accuracy: 0.4993\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6614 - accuracy: 0.5505 - val_loss: 0.7056 - val_accuracy: 0.4960\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6611 - accuracy: 0.5503 - val_loss: 0.7061 - val_accuracy: 0.4978\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6606 - accuracy: 0.5507 - val_loss: 0.7093 - val_accuracy: 0.4990\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6606 - accuracy: 0.5504 - val_loss: 0.7089 - val_accuracy: 0.4983\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6609 - accuracy: 0.5505 - val_loss: 0.7080 - val_accuracy: 0.4990\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6608 - accuracy: 0.5504 - val_loss: 0.7079 - val_accuracy: 0.4983\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6605 - accuracy: 0.5508 - val_loss: 0.7086 - val_accuracy: 0.4973\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6605 - accuracy: 0.5507 - val_loss: 0.7099 - val_accuracy: 0.4965\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6604 - accuracy: 0.5507 - val_loss: 0.7091 - val_accuracy: 0.4982\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6599 - accuracy: 0.5512 - val_loss: 0.7085 - val_accuracy: 0.4976\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6602 - accuracy: 0.5507 - val_loss: 0.7084 - val_accuracy: 0.4985\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6601 - accuracy: 0.5509 - val_loss: 0.7101 - val_accuracy: 0.4987\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6603 - accuracy: 0.5506 - val_loss: 0.7089 - val_accuracy: 0.4976\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6599 - accuracy: 0.5509 - val_loss: 0.7086 - val_accuracy: 0.4978\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6602 - accuracy: 0.5508 - val_loss: 0.7094 - val_accuracy: 0.4978\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6598 - accuracy: 0.5509 - val_loss: 0.7099 - val_accuracy: 0.4983\n",
            "19/19 [==============================] - 1s 14ms/step - loss: 0.7142 - accuracy: 0.4957\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 81ms/step - loss: 0.6909 - accuracy: 0.5043 - val_loss: 0.6885 - val_accuracy: 0.5304\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 3s 46ms/step - loss: 0.6881 - accuracy: 0.5214 - val_loss: 0.6865 - val_accuracy: 0.5305\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6869 - accuracy: 0.5227 - val_loss: 0.6856 - val_accuracy: 0.5320\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6856 - accuracy: 0.5238 - val_loss: 0.6846 - val_accuracy: 0.5335\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6847 - accuracy: 0.5246 - val_loss: 0.6847 - val_accuracy: 0.5345\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6842 - accuracy: 0.5250 - val_loss: 0.6845 - val_accuracy: 0.5341\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6829 - accuracy: 0.5265 - val_loss: 0.6839 - val_accuracy: 0.5337\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6819 - accuracy: 0.5268 - val_loss: 0.6841 - val_accuracy: 0.5341\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6812 - accuracy: 0.5276 - val_loss: 0.6845 - val_accuracy: 0.5340\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6804 - accuracy: 0.5284 - val_loss: 0.6845 - val_accuracy: 0.5336\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6797 - accuracy: 0.5289 - val_loss: 0.6845 - val_accuracy: 0.5342\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6792 - accuracy: 0.5293 - val_loss: 0.6846 - val_accuracy: 0.5345\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6785 - accuracy: 0.5299 - val_loss: 0.6850 - val_accuracy: 0.5343\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6780 - accuracy: 0.5300 - val_loss: 0.6853 - val_accuracy: 0.5340\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6776 - accuracy: 0.5303 - val_loss: 0.6848 - val_accuracy: 0.5345\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6768 - accuracy: 0.5310 - val_loss: 0.6858 - val_accuracy: 0.5334\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6765 - accuracy: 0.5313 - val_loss: 0.6860 - val_accuracy: 0.5339\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6765 - accuracy: 0.5319 - val_loss: 0.6861 - val_accuracy: 0.5332\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6758 - accuracy: 0.5321 - val_loss: 0.6868 - val_accuracy: 0.5341\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6753 - accuracy: 0.5321 - val_loss: 0.6859 - val_accuracy: 0.5337\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6748 - accuracy: 0.5326 - val_loss: 0.6878 - val_accuracy: 0.5334\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6743 - accuracy: 0.5329 - val_loss: 0.6863 - val_accuracy: 0.5341\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6743 - accuracy: 0.5330 - val_loss: 0.6861 - val_accuracy: 0.5342\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6737 - accuracy: 0.5335 - val_loss: 0.6879 - val_accuracy: 0.5334\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6730 - accuracy: 0.5342 - val_loss: 0.6872 - val_accuracy: 0.5331\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6732 - accuracy: 0.5340 - val_loss: 0.6877 - val_accuracy: 0.5334\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6722 - accuracy: 0.5345 - val_loss: 0.6891 - val_accuracy: 0.5328\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6732 - accuracy: 0.5344 - val_loss: 0.6890 - val_accuracy: 0.5333\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6721 - accuracy: 0.5346 - val_loss: 0.6878 - val_accuracy: 0.5335\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6714 - accuracy: 0.5352 - val_loss: 0.6891 - val_accuracy: 0.5335\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6710 - accuracy: 0.5356 - val_loss: 0.6882 - val_accuracy: 0.5325\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6705 - accuracy: 0.5356 - val_loss: 0.6896 - val_accuracy: 0.5335\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6705 - accuracy: 0.5358 - val_loss: 0.6888 - val_accuracy: 0.5324\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6702 - accuracy: 0.5363 - val_loss: 0.6898 - val_accuracy: 0.5327\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6700 - accuracy: 0.5364 - val_loss: 0.6881 - val_accuracy: 0.5331\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6695 - accuracy: 0.5365 - val_loss: 0.6898 - val_accuracy: 0.5333\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6695 - accuracy: 0.5367 - val_loss: 0.6908 - val_accuracy: 0.5333\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6692 - accuracy: 0.5369 - val_loss: 0.6894 - val_accuracy: 0.5338\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6685 - accuracy: 0.5374 - val_loss: 0.6917 - val_accuracy: 0.5334\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6684 - accuracy: 0.5375 - val_loss: 0.6898 - val_accuracy: 0.5334\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6680 - accuracy: 0.5377 - val_loss: 0.6920 - val_accuracy: 0.5331\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6685 - accuracy: 0.5376 - val_loss: 0.6916 - val_accuracy: 0.5330\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6677 - accuracy: 0.5378 - val_loss: 0.6926 - val_accuracy: 0.5321\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6672 - accuracy: 0.5382 - val_loss: 0.6923 - val_accuracy: 0.5322\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6674 - accuracy: 0.5381 - val_loss: 0.6932 - val_accuracy: 0.5335\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6671 - accuracy: 0.5384 - val_loss: 0.6913 - val_accuracy: 0.5330\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6670 - accuracy: 0.5388 - val_loss: 0.6940 - val_accuracy: 0.4949\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6667 - accuracy: 0.5335 - val_loss: 0.6923 - val_accuracy: 0.5338\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6667 - accuracy: 0.5383 - val_loss: 0.6922 - val_accuracy: 0.5336\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6664 - accuracy: 0.5386 - val_loss: 0.6932 - val_accuracy: 0.5326\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6660 - accuracy: 0.5389 - val_loss: 0.6931 - val_accuracy: 0.5329\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6656 - accuracy: 0.5394 - val_loss: 0.6935 - val_accuracy: 0.5330\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6657 - accuracy: 0.5391 - val_loss: 0.6932 - val_accuracy: 0.5331\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6657 - accuracy: 0.5394 - val_loss: 0.6948 - val_accuracy: 0.5329\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6653 - accuracy: 0.5396 - val_loss: 0.6933 - val_accuracy: 0.5334\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6650 - accuracy: 0.5396 - val_loss: 0.6966 - val_accuracy: 0.5332\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6649 - accuracy: 0.5397 - val_loss: 0.6955 - val_accuracy: 0.5326\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6645 - accuracy: 0.5399 - val_loss: 0.6942 - val_accuracy: 0.5330\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6646 - accuracy: 0.5401 - val_loss: 0.6950 - val_accuracy: 0.5332\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6644 - accuracy: 0.5400 - val_loss: 0.6948 - val_accuracy: 0.5325\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6642 - accuracy: 0.5402 - val_loss: 0.6971 - val_accuracy: 0.5324\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6647 - accuracy: 0.5401 - val_loss: 0.6963 - val_accuracy: 0.5331\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6647 - accuracy: 0.5404 - val_loss: 0.6961 - val_accuracy: 0.5334\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6639 - accuracy: 0.5405 - val_loss: 0.6949 - val_accuracy: 0.5330\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6637 - accuracy: 0.5405 - val_loss: 0.6972 - val_accuracy: 0.5332\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6640 - accuracy: 0.5404 - val_loss: 0.6962 - val_accuracy: 0.5328\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6637 - accuracy: 0.5410 - val_loss: 0.6973 - val_accuracy: 0.5323\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6634 - accuracy: 0.5407 - val_loss: 0.6983 - val_accuracy: 0.5321\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6636 - accuracy: 0.5336 - val_loss: 0.6966 - val_accuracy: 0.5330\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6631 - accuracy: 0.5411 - val_loss: 0.6959 - val_accuracy: 0.5329\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6628 - accuracy: 0.5411 - val_loss: 0.6981 - val_accuracy: 0.5333\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6632 - accuracy: 0.5409 - val_loss: 0.6974 - val_accuracy: 0.5338\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6629 - accuracy: 0.5410 - val_loss: 0.6970 - val_accuracy: 0.5331\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6627 - accuracy: 0.5414 - val_loss: 0.6959 - val_accuracy: 0.5326\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 61ms/step - loss: 0.6628 - accuracy: 0.5414 - val_loss: 0.6984 - val_accuracy: 0.5328\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6624 - accuracy: 0.5399 - val_loss: 0.6989 - val_accuracy: 0.5337\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6622 - accuracy: 0.5416 - val_loss: 0.6963 - val_accuracy: 0.5334\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6621 - accuracy: 0.5418 - val_loss: 0.6985 - val_accuracy: 0.5330\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6623 - accuracy: 0.5419 - val_loss: 0.6988 - val_accuracy: 0.5325\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6620 - accuracy: 0.5417 - val_loss: 0.6987 - val_accuracy: 0.5332\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6621 - accuracy: 0.5417 - val_loss: 0.6999 - val_accuracy: 0.5330\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6618 - accuracy: 0.5421 - val_loss: 0.7021 - val_accuracy: 0.5326\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6614 - accuracy: 0.5423 - val_loss: 0.7008 - val_accuracy: 0.5335\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6625 - accuracy: 0.5418 - val_loss: 0.6988 - val_accuracy: 0.5330\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6614 - accuracy: 0.5421 - val_loss: 0.6983 - val_accuracy: 0.5333\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 8s 107ms/step - loss: 0.6613 - accuracy: 0.5421 - val_loss: 0.7000 - val_accuracy: 0.5329\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6614 - accuracy: 0.5421 - val_loss: 0.7004 - val_accuracy: 0.5331\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6613 - accuracy: 0.5422 - val_loss: 0.6977 - val_accuracy: 0.5334\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6610 - accuracy: 0.5425 - val_loss: 0.6999 - val_accuracy: 0.5329\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6607 - accuracy: 0.5425 - val_loss: 0.7009 - val_accuracy: 0.5326\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6609 - accuracy: 0.5427 - val_loss: 0.6998 - val_accuracy: 0.5327\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6609 - accuracy: 0.5393 - val_loss: 0.6996 - val_accuracy: 0.5330\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6611 - accuracy: 0.5424 - val_loss: 0.6997 - val_accuracy: 0.5329\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6609 - accuracy: 0.5427 - val_loss: 0.6997 - val_accuracy: 0.5329\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6603 - accuracy: 0.5430 - val_loss: 0.7008 - val_accuracy: 0.5326\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6609 - accuracy: 0.5424 - val_loss: 0.6991 - val_accuracy: 0.5332\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6608 - accuracy: 0.5426 - val_loss: 0.7000 - val_accuracy: 0.5329\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6607 - accuracy: 0.5427 - val_loss: 0.7011 - val_accuracy: 0.5332\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6601 - accuracy: 0.5432 - val_loss: 0.7022 - val_accuracy: 0.5321\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6600 - accuracy: 0.5432 - val_loss: 0.7012 - val_accuracy: 0.5331\n",
            "19/19 [==============================] - 1s 14ms/step - loss: 0.7037 - accuracy: 0.5321\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 5s 53ms/step - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6875 - val_accuracy: 0.5099\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6878 - accuracy: 0.5259 - val_loss: 0.6862 - val_accuracy: 0.5117\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6864 - accuracy: 0.5273 - val_loss: 0.6858 - val_accuracy: 0.5130\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6852 - accuracy: 0.5292 - val_loss: 0.6856 - val_accuracy: 0.5125\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6841 - accuracy: 0.5299 - val_loss: 0.6854 - val_accuracy: 0.5138\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6831 - accuracy: 0.5306 - val_loss: 0.6866 - val_accuracy: 0.5144\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6825 - accuracy: 0.5321 - val_loss: 0.6857 - val_accuracy: 0.5142\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6815 - accuracy: 0.5327 - val_loss: 0.6858 - val_accuracy: 0.5141\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6808 - accuracy: 0.5334 - val_loss: 0.6855 - val_accuracy: 0.5147\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6805 - accuracy: 0.5334 - val_loss: 0.6863 - val_accuracy: 0.5127\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6793 - accuracy: 0.5348 - val_loss: 0.6864 - val_accuracy: 0.5128\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6788 - accuracy: 0.5350 - val_loss: 0.6858 - val_accuracy: 0.5130\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6781 - accuracy: 0.5356 - val_loss: 0.6869 - val_accuracy: 0.5116\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6782 - accuracy: 0.5356 - val_loss: 0.6862 - val_accuracy: 0.5129\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6774 - accuracy: 0.5362 - val_loss: 0.6875 - val_accuracy: 0.5111\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6770 - accuracy: 0.5365 - val_loss: 0.6871 - val_accuracy: 0.5114\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6763 - accuracy: 0.5367 - val_loss: 0.6867 - val_accuracy: 0.5124\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6756 - accuracy: 0.5374 - val_loss: 0.6880 - val_accuracy: 0.5120\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 3s 48ms/step - loss: 0.6755 - accuracy: 0.5374 - val_loss: 0.6875 - val_accuracy: 0.5121\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6751 - accuracy: 0.5376 - val_loss: 0.6878 - val_accuracy: 0.5126\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6748 - accuracy: 0.5378 - val_loss: 0.6878 - val_accuracy: 0.5125\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6739 - accuracy: 0.5385 - val_loss: 0.6876 - val_accuracy: 0.5124\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6742 - accuracy: 0.5383 - val_loss: 0.6872 - val_accuracy: 0.5116\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6735 - accuracy: 0.5390 - val_loss: 0.6884 - val_accuracy: 0.5110\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6729 - accuracy: 0.5395 - val_loss: 0.6889 - val_accuracy: 0.5121\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6732 - accuracy: 0.5387 - val_loss: 0.6892 - val_accuracy: 0.5098\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 3s 47ms/step - loss: 0.6724 - accuracy: 0.5397 - val_loss: 0.6899 - val_accuracy: 0.5127\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6724 - accuracy: 0.5398 - val_loss: 0.6926 - val_accuracy: 0.5136\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6718 - accuracy: 0.5396 - val_loss: 0.6880 - val_accuracy: 0.5115\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6714 - accuracy: 0.5403 - val_loss: 0.6906 - val_accuracy: 0.5131\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6715 - accuracy: 0.5402 - val_loss: 0.6893 - val_accuracy: 0.5126\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6706 - accuracy: 0.5407 - val_loss: 0.6915 - val_accuracy: 0.5108\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6706 - accuracy: 0.5410 - val_loss: 0.6900 - val_accuracy: 0.5116\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6702 - accuracy: 0.5413 - val_loss: 0.6914 - val_accuracy: 0.5129\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6700 - accuracy: 0.5412 - val_loss: 0.6908 - val_accuracy: 0.5119\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6694 - accuracy: 0.5417 - val_loss: 0.6911 - val_accuracy: 0.5118\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6693 - accuracy: 0.5421 - val_loss: 0.6917 - val_accuracy: 0.5127\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6691 - accuracy: 0.5420 - val_loss: 0.6932 - val_accuracy: 0.5110\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6693 - accuracy: 0.5417 - val_loss: 0.6911 - val_accuracy: 0.5116\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6688 - accuracy: 0.5421 - val_loss: 0.6905 - val_accuracy: 0.5127\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6683 - accuracy: 0.5425 - val_loss: 0.6916 - val_accuracy: 0.5123\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6680 - accuracy: 0.5429 - val_loss: 0.6926 - val_accuracy: 0.5123\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6677 - accuracy: 0.5431 - val_loss: 0.6919 - val_accuracy: 0.5114\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6677 - accuracy: 0.5429 - val_loss: 0.6936 - val_accuracy: 0.5127\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6670 - accuracy: 0.5436 - val_loss: 0.6932 - val_accuracy: 0.5118\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6671 - accuracy: 0.5435 - val_loss: 0.6934 - val_accuracy: 0.5117\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6671 - accuracy: 0.5434 - val_loss: 0.6936 - val_accuracy: 0.5120\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6665 - accuracy: 0.5438 - val_loss: 0.6938 - val_accuracy: 0.5121\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6665 - accuracy: 0.5441 - val_loss: 0.6960 - val_accuracy: 0.5125\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6669 - accuracy: 0.5439 - val_loss: 0.6941 - val_accuracy: 0.5128\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6667 - accuracy: 0.5438 - val_loss: 0.6934 - val_accuracy: 0.5116\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6657 - accuracy: 0.5443 - val_loss: 0.6944 - val_accuracy: 0.5122\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6654 - accuracy: 0.5446 - val_loss: 0.6948 - val_accuracy: 0.5122\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6652 - accuracy: 0.5448 - val_loss: 0.6946 - val_accuracy: 0.5124\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6654 - accuracy: 0.5447 - val_loss: 0.6944 - val_accuracy: 0.5124\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6650 - accuracy: 0.5450 - val_loss: 0.6961 - val_accuracy: 0.5112\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6647 - accuracy: 0.5451 - val_loss: 0.6962 - val_accuracy: 0.5127\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6649 - accuracy: 0.5453 - val_loss: 0.6975 - val_accuracy: 0.5128\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6650 - accuracy: 0.5449 - val_loss: 0.6944 - val_accuracy: 0.5126\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6645 - accuracy: 0.5453 - val_loss: 0.6956 - val_accuracy: 0.5125\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6644 - accuracy: 0.5453 - val_loss: 0.6959 - val_accuracy: 0.5120\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6638 - accuracy: 0.5456 - val_loss: 0.6975 - val_accuracy: 0.5117\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6644 - accuracy: 0.5453 - val_loss: 0.6961 - val_accuracy: 0.5131\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6642 - accuracy: 0.5456 - val_loss: 0.6968 - val_accuracy: 0.5126\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6634 - accuracy: 0.5461 - val_loss: 0.6970 - val_accuracy: 0.5119\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6637 - accuracy: 0.5459 - val_loss: 0.6976 - val_accuracy: 0.5114\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6634 - accuracy: 0.5462 - val_loss: 0.6981 - val_accuracy: 0.5125\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6637 - accuracy: 0.5462 - val_loss: 0.6966 - val_accuracy: 0.5117\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6631 - accuracy: 0.5463 - val_loss: 0.6987 - val_accuracy: 0.5124\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6631 - accuracy: 0.5462 - val_loss: 0.6976 - val_accuracy: 0.5119\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6628 - accuracy: 0.5466 - val_loss: 0.6971 - val_accuracy: 0.5122\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6628 - accuracy: 0.5464 - val_loss: 0.6985 - val_accuracy: 0.5119\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6625 - accuracy: 0.5465 - val_loss: 0.6986 - val_accuracy: 0.5119\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6625 - accuracy: 0.5467 - val_loss: 0.6994 - val_accuracy: 0.5126\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6621 - accuracy: 0.5469 - val_loss: 0.6985 - val_accuracy: 0.5116\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6619 - accuracy: 0.5470 - val_loss: 0.6985 - val_accuracy: 0.5119\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6623 - accuracy: 0.5434 - val_loss: 0.7003 - val_accuracy: 0.5115\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6620 - accuracy: 0.5471 - val_loss: 0.6992 - val_accuracy: 0.5115\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6618 - accuracy: 0.5470 - val_loss: 0.6991 - val_accuracy: 0.5118\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6617 - accuracy: 0.5473 - val_loss: 0.6991 - val_accuracy: 0.5112\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6618 - accuracy: 0.5470 - val_loss: 0.6994 - val_accuracy: 0.5120\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6617 - accuracy: 0.5472 - val_loss: 0.6987 - val_accuracy: 0.5115\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6616 - accuracy: 0.5473 - val_loss: 0.7007 - val_accuracy: 0.5121\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6619 - accuracy: 0.5471 - val_loss: 0.6967 - val_accuracy: 0.5117\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6613 - accuracy: 0.5469 - val_loss: 0.6996 - val_accuracy: 0.5121\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6612 - accuracy: 0.5477 - val_loss: 0.7006 - val_accuracy: 0.5118\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6613 - accuracy: 0.5472 - val_loss: 0.7011 - val_accuracy: 0.5123\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6608 - accuracy: 0.5477 - val_loss: 0.7010 - val_accuracy: 0.5117\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6609 - accuracy: 0.5476 - val_loss: 0.7002 - val_accuracy: 0.5124\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6610 - accuracy: 0.5476 - val_loss: 0.7012 - val_accuracy: 0.5118\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6609 - accuracy: 0.5479 - val_loss: 0.7002 - val_accuracy: 0.5118\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 4s 48ms/step - loss: 0.6609 - accuracy: 0.5479 - val_loss: 0.7010 - val_accuracy: 0.5118\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6607 - accuracy: 0.5481 - val_loss: 0.7013 - val_accuracy: 0.5123\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6605 - accuracy: 0.5481 - val_loss: 0.7019 - val_accuracy: 0.5122\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6606 - accuracy: 0.5480 - val_loss: 0.7024 - val_accuracy: 0.5120\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6604 - accuracy: 0.5479 - val_loss: 0.7015 - val_accuracy: 0.5119\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6601 - accuracy: 0.5484 - val_loss: 0.7032 - val_accuracy: 0.5123\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6603 - accuracy: 0.5479 - val_loss: 0.7026 - val_accuracy: 0.5114\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6602 - accuracy: 0.5483 - val_loss: 0.7021 - val_accuracy: 0.5120\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6604 - accuracy: 0.5481 - val_loss: 0.7021 - val_accuracy: 0.5121\n",
            "19/19 [==============================] - 1s 15ms/step - loss: 0.7021 - accuracy: 0.5120\n",
            "Best accuracy for dataset 0: 0.5428648591041565\n",
            "2308\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 5s 53ms/step - loss: 0.6903 - accuracy: 0.5022 - val_loss: 0.6885 - val_accuracy: 0.5385\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6878 - accuracy: 0.5182 - val_loss: 0.6870 - val_accuracy: 0.5424\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6866 - accuracy: 0.5197 - val_loss: 0.6865 - val_accuracy: 0.5428\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6851 - accuracy: 0.5211 - val_loss: 0.6858 - val_accuracy: 0.5435\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6841 - accuracy: 0.5227 - val_loss: 0.6854 - val_accuracy: 0.5438\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6834 - accuracy: 0.5229 - val_loss: 0.6851 - val_accuracy: 0.5445\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6826 - accuracy: 0.5239 - val_loss: 0.6849 - val_accuracy: 0.5447\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6812 - accuracy: 0.5251 - val_loss: 0.6845 - val_accuracy: 0.5446\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6807 - accuracy: 0.5256 - val_loss: 0.6849 - val_accuracy: 0.5443\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6802 - accuracy: 0.5262 - val_loss: 0.6848 - val_accuracy: 0.5445\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6795 - accuracy: 0.5267 - val_loss: 0.6844 - val_accuracy: 0.5447\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6791 - accuracy: 0.5267 - val_loss: 0.6847 - val_accuracy: 0.5444\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6784 - accuracy: 0.5270 - val_loss: 0.6849 - val_accuracy: 0.5452\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6779 - accuracy: 0.5278 - val_loss: 0.6850 - val_accuracy: 0.5440\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6774 - accuracy: 0.5280 - val_loss: 0.6855 - val_accuracy: 0.5448\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6771 - accuracy: 0.5286 - val_loss: 0.6856 - val_accuracy: 0.5446\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6762 - accuracy: 0.5290 - val_loss: 0.6863 - val_accuracy: 0.5447\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6756 - accuracy: 0.5297 - val_loss: 0.6865 - val_accuracy: 0.5437\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6756 - accuracy: 0.5294 - val_loss: 0.6857 - val_accuracy: 0.5438\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6746 - accuracy: 0.5306 - val_loss: 0.6862 - val_accuracy: 0.5445\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6746 - accuracy: 0.5302 - val_loss: 0.6865 - val_accuracy: 0.5433\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6744 - accuracy: 0.5307 - val_loss: 0.6870 - val_accuracy: 0.5433\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6734 - accuracy: 0.5310 - val_loss: 0.6886 - val_accuracy: 0.5436\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6736 - accuracy: 0.5311 - val_loss: 0.6884 - val_accuracy: 0.5422\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6729 - accuracy: 0.5315 - val_loss: 0.6881 - val_accuracy: 0.5438\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6726 - accuracy: 0.5317 - val_loss: 0.6874 - val_accuracy: 0.5421\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6723 - accuracy: 0.5319 - val_loss: 0.6885 - val_accuracy: 0.5422\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6716 - accuracy: 0.5327 - val_loss: 0.6895 - val_accuracy: 0.5431\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6714 - accuracy: 0.5326 - val_loss: 0.6888 - val_accuracy: 0.5431\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6709 - accuracy: 0.5329 - val_loss: 0.6885 - val_accuracy: 0.5421\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6706 - accuracy: 0.5332 - val_loss: 0.6893 - val_accuracy: 0.5424\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 5s 76ms/step - loss: 0.6697 - accuracy: 0.5339 - val_loss: 0.6907 - val_accuracy: 0.5430\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6698 - accuracy: 0.5339 - val_loss: 0.6899 - val_accuracy: 0.5423\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6697 - accuracy: 0.5338 - val_loss: 0.6898 - val_accuracy: 0.5427\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6690 - accuracy: 0.5344 - val_loss: 0.6909 - val_accuracy: 0.5424\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6691 - accuracy: 0.5346 - val_loss: 0.6920 - val_accuracy: 0.5430\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6691 - accuracy: 0.5346 - val_loss: 0.6912 - val_accuracy: 0.5425\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6681 - accuracy: 0.5353 - val_loss: 0.6945 - val_accuracy: 0.5431\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6685 - accuracy: 0.5347 - val_loss: 0.6929 - val_accuracy: 0.5436\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6684 - accuracy: 0.5352 - val_loss: 0.6918 - val_accuracy: 0.5427\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6673 - accuracy: 0.5356 - val_loss: 0.6927 - val_accuracy: 0.5419\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6673 - accuracy: 0.5356 - val_loss: 0.6924 - val_accuracy: 0.5427\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6671 - accuracy: 0.5359 - val_loss: 0.6926 - val_accuracy: 0.5415\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6668 - accuracy: 0.5361 - val_loss: 0.6941 - val_accuracy: 0.5427\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6669 - accuracy: 0.5357 - val_loss: 0.6929 - val_accuracy: 0.5426\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6672 - accuracy: 0.5359 - val_loss: 0.6932 - val_accuracy: 0.5420\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6664 - accuracy: 0.5365 - val_loss: 0.6942 - val_accuracy: 0.5418\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6658 - accuracy: 0.5368 - val_loss: 0.6947 - val_accuracy: 0.5422\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6659 - accuracy: 0.5366 - val_loss: 0.6952 - val_accuracy: 0.5423\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6658 - accuracy: 0.5368 - val_loss: 0.6943 - val_accuracy: 0.5431\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6652 - accuracy: 0.5373 - val_loss: 0.6964 - val_accuracy: 0.5421\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6656 - accuracy: 0.5369 - val_loss: 0.6963 - val_accuracy: 0.5417\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6652 - accuracy: 0.5375 - val_loss: 0.6974 - val_accuracy: 0.5424\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6650 - accuracy: 0.5374 - val_loss: 0.6944 - val_accuracy: 0.5414\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6649 - accuracy: 0.5375 - val_loss: 0.6960 - val_accuracy: 0.5417\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6652 - accuracy: 0.5375 - val_loss: 0.6945 - val_accuracy: 0.5414\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6648 - accuracy: 0.5367 - val_loss: 0.6947 - val_accuracy: 0.5417\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6645 - accuracy: 0.5380 - val_loss: 0.6969 - val_accuracy: 0.5428\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6644 - accuracy: 0.5379 - val_loss: 0.6954 - val_accuracy: 0.5421\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6642 - accuracy: 0.5381 - val_loss: 0.6965 - val_accuracy: 0.5420\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6640 - accuracy: 0.5379 - val_loss: 0.6964 - val_accuracy: 0.5425\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6645 - accuracy: 0.5377 - val_loss: 0.6977 - val_accuracy: 0.5423\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6636 - accuracy: 0.5384 - val_loss: 0.6974 - val_accuracy: 0.5419\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6631 - accuracy: 0.5387 - val_loss: 0.6966 - val_accuracy: 0.5418\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6636 - accuracy: 0.5388 - val_loss: 0.6972 - val_accuracy: 0.5421\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6631 - accuracy: 0.5387 - val_loss: 0.6973 - val_accuracy: 0.5414\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6634 - accuracy: 0.5387 - val_loss: 0.7001 - val_accuracy: 0.5419\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6634 - accuracy: 0.5386 - val_loss: 0.7002 - val_accuracy: 0.5417\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6631 - accuracy: 0.5387 - val_loss: 0.6986 - val_accuracy: 0.5416\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6627 - accuracy: 0.5391 - val_loss: 0.6981 - val_accuracy: 0.5417\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6625 - accuracy: 0.5394 - val_loss: 0.6992 - val_accuracy: 0.5419\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6623 - accuracy: 0.5393 - val_loss: 0.6999 - val_accuracy: 0.5416\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6625 - accuracy: 0.5394 - val_loss: 0.7006 - val_accuracy: 0.5419\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6625 - accuracy: 0.5393 - val_loss: 0.7008 - val_accuracy: 0.5419\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6616 - accuracy: 0.5396 - val_loss: 0.7000 - val_accuracy: 0.5418\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6633 - accuracy: 0.5392 - val_loss: 0.6962 - val_accuracy: 0.5415\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6620 - accuracy: 0.5399 - val_loss: 0.7003 - val_accuracy: 0.5416\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6617 - accuracy: 0.5395 - val_loss: 0.7007 - val_accuracy: 0.5415\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6618 - accuracy: 0.5396 - val_loss: 0.7018 - val_accuracy: 0.5418\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6619 - accuracy: 0.5397 - val_loss: 0.7035 - val_accuracy: 0.5425\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6620 - accuracy: 0.5395 - val_loss: 0.7017 - val_accuracy: 0.5420\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6618 - accuracy: 0.5399 - val_loss: 0.7001 - val_accuracy: 0.5415\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6613 - accuracy: 0.5400 - val_loss: 0.7048 - val_accuracy: 0.5424\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6613 - accuracy: 0.5401 - val_loss: 0.7022 - val_accuracy: 0.5414\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6608 - accuracy: 0.5403 - val_loss: 0.7010 - val_accuracy: 0.5410\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6608 - accuracy: 0.5404 - val_loss: 0.7006 - val_accuracy: 0.5419\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6609 - accuracy: 0.5404 - val_loss: 0.7024 - val_accuracy: 0.5420\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6606 - accuracy: 0.5404 - val_loss: 0.7038 - val_accuracy: 0.5422\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6606 - accuracy: 0.5405 - val_loss: 0.7016 - val_accuracy: 0.5412\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6607 - accuracy: 0.5404 - val_loss: 0.7009 - val_accuracy: 0.5416\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6607 - accuracy: 0.5404 - val_loss: 0.7038 - val_accuracy: 0.5422\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6606 - accuracy: 0.5404 - val_loss: 0.7020 - val_accuracy: 0.5420\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6608 - accuracy: 0.5405 - val_loss: 0.7023 - val_accuracy: 0.5423\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6599 - accuracy: 0.5396 - val_loss: 0.7033 - val_accuracy: 0.5417\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6611 - accuracy: 0.5347 - val_loss: 0.7019 - val_accuracy: 0.5420\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6602 - accuracy: 0.5407 - val_loss: 0.7019 - val_accuracy: 0.5417\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6601 - accuracy: 0.5411 - val_loss: 0.7023 - val_accuracy: 0.5417\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6603 - accuracy: 0.5409 - val_loss: 0.7072 - val_accuracy: 0.5417\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6599 - accuracy: 0.5381 - val_loss: 0.7039 - val_accuracy: 0.5421\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6598 - accuracy: 0.5413 - val_loss: 0.7026 - val_accuracy: 0.5416\n",
            "19/19 [==============================] - 1s 14ms/step - loss: 0.7063 - accuracy: 0.5401\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 8s 57ms/step - loss: 0.6908 - accuracy: 0.5153 - val_loss: 0.6877 - val_accuracy: 0.5343\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 8s 108ms/step - loss: 0.6882 - accuracy: 0.5190 - val_loss: 0.6860 - val_accuracy: 0.5363\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6867 - accuracy: 0.5210 - val_loss: 0.6861 - val_accuracy: 0.5386\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6856 - accuracy: 0.5216 - val_loss: 0.6850 - val_accuracy: 0.5389\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6847 - accuracy: 0.5230 - val_loss: 0.6851 - val_accuracy: 0.5396\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6837 - accuracy: 0.5235 - val_loss: 0.6842 - val_accuracy: 0.5395\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6828 - accuracy: 0.5249 - val_loss: 0.6845 - val_accuracy: 0.5390\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6821 - accuracy: 0.5256 - val_loss: 0.6853 - val_accuracy: 0.5393\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6820 - accuracy: 0.5258 - val_loss: 0.6851 - val_accuracy: 0.5391\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6812 - accuracy: 0.5259 - val_loss: 0.6850 - val_accuracy: 0.5394\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6802 - accuracy: 0.5269 - val_loss: 0.6852 - val_accuracy: 0.5397\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6795 - accuracy: 0.5280 - val_loss: 0.6847 - val_accuracy: 0.5384\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6792 - accuracy: 0.5281 - val_loss: 0.6847 - val_accuracy: 0.5392\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6784 - accuracy: 0.5288 - val_loss: 0.6855 - val_accuracy: 0.5394\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6780 - accuracy: 0.5292 - val_loss: 0.6859 - val_accuracy: 0.5393\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6774 - accuracy: 0.5293 - val_loss: 0.6856 - val_accuracy: 0.5392\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6772 - accuracy: 0.5294 - val_loss: 0.6860 - val_accuracy: 0.5389\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6762 - accuracy: 0.5302 - val_loss: 0.6861 - val_accuracy: 0.5395\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6762 - accuracy: 0.5304 - val_loss: 0.6869 - val_accuracy: 0.5391\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6757 - accuracy: 0.5310 - val_loss: 0.6864 - val_accuracy: 0.5385\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6749 - accuracy: 0.5316 - val_loss: 0.6878 - val_accuracy: 0.5391\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6747 - accuracy: 0.5315 - val_loss: 0.6869 - val_accuracy: 0.5384\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6742 - accuracy: 0.5318 - val_loss: 0.6870 - val_accuracy: 0.5390\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6734 - accuracy: 0.5326 - val_loss: 0.6893 - val_accuracy: 0.5389\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6735 - accuracy: 0.5322 - val_loss: 0.6896 - val_accuracy: 0.5390\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6731 - accuracy: 0.5328 - val_loss: 0.6883 - val_accuracy: 0.5372\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6725 - accuracy: 0.5335 - val_loss: 0.6879 - val_accuracy: 0.5373\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6720 - accuracy: 0.5334 - val_loss: 0.6913 - val_accuracy: 0.5386\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6721 - accuracy: 0.5336 - val_loss: 0.6897 - val_accuracy: 0.5385\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6719 - accuracy: 0.5338 - val_loss: 0.6892 - val_accuracy: 0.5381\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6711 - accuracy: 0.5344 - val_loss: 0.6903 - val_accuracy: 0.5376\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6707 - accuracy: 0.5346 - val_loss: 0.6914 - val_accuracy: 0.5393\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6708 - accuracy: 0.5343 - val_loss: 0.6903 - val_accuracy: 0.5375\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6701 - accuracy: 0.5351 - val_loss: 0.6906 - val_accuracy: 0.5383\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6703 - accuracy: 0.5348 - val_loss: 0.6904 - val_accuracy: 0.5388\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6695 - accuracy: 0.5352 - val_loss: 0.6923 - val_accuracy: 0.5386\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6694 - accuracy: 0.5356 - val_loss: 0.6913 - val_accuracy: 0.5378\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6693 - accuracy: 0.5355 - val_loss: 0.6905 - val_accuracy: 0.5387\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6691 - accuracy: 0.5358 - val_loss: 0.6912 - val_accuracy: 0.5368\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6687 - accuracy: 0.5361 - val_loss: 0.6914 - val_accuracy: 0.5384\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6680 - accuracy: 0.5364 - val_loss: 0.6914 - val_accuracy: 0.5374\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6675 - accuracy: 0.5368 - val_loss: 0.6929 - val_accuracy: 0.5377\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6681 - accuracy: 0.5367 - val_loss: 0.6924 - val_accuracy: 0.5382\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6681 - accuracy: 0.5369 - val_loss: 0.6925 - val_accuracy: 0.5385\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6673 - accuracy: 0.5373 - val_loss: 0.6929 - val_accuracy: 0.5378\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6675 - accuracy: 0.5369 - val_loss: 0.6927 - val_accuracy: 0.5382\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6675 - accuracy: 0.5371 - val_loss: 0.6938 - val_accuracy: 0.5377\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6671 - accuracy: 0.5373 - val_loss: 0.6955 - val_accuracy: 0.5386\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6669 - accuracy: 0.5373 - val_loss: 0.6931 - val_accuracy: 0.5374\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6664 - accuracy: 0.5374 - val_loss: 0.6937 - val_accuracy: 0.5376\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6661 - accuracy: 0.5378 - val_loss: 0.6950 - val_accuracy: 0.5375\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6657 - accuracy: 0.5381 - val_loss: 0.6972 - val_accuracy: 0.5385\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6662 - accuracy: 0.5379 - val_loss: 0.6961 - val_accuracy: 0.5378\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6657 - accuracy: 0.5380 - val_loss: 0.6954 - val_accuracy: 0.5366\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6652 - accuracy: 0.5384 - val_loss: 0.6966 - val_accuracy: 0.5377\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6657 - accuracy: 0.5384 - val_loss: 0.6974 - val_accuracy: 0.5379\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6655 - accuracy: 0.5383 - val_loss: 0.6964 - val_accuracy: 0.5371\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6652 - accuracy: 0.5384 - val_loss: 0.6967 - val_accuracy: 0.5378\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6646 - accuracy: 0.5391 - val_loss: 0.6969 - val_accuracy: 0.5374\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6645 - accuracy: 0.5389 - val_loss: 0.6963 - val_accuracy: 0.5377\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6641 - accuracy: 0.5394 - val_loss: 0.6965 - val_accuracy: 0.5379\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6646 - accuracy: 0.5389 - val_loss: 0.6970 - val_accuracy: 0.5379\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6641 - accuracy: 0.5395 - val_loss: 0.6974 - val_accuracy: 0.5371\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6642 - accuracy: 0.5390 - val_loss: 0.6960 - val_accuracy: 0.5377\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6638 - accuracy: 0.5396 - val_loss: 0.6980 - val_accuracy: 0.5380\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6642 - accuracy: 0.5394 - val_loss: 0.6964 - val_accuracy: 0.5375\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6634 - accuracy: 0.5397 - val_loss: 0.6978 - val_accuracy: 0.5369\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6636 - accuracy: 0.5396 - val_loss: 0.6977 - val_accuracy: 0.5373\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6636 - accuracy: 0.5397 - val_loss: 0.6984 - val_accuracy: 0.5380\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6634 - accuracy: 0.5396 - val_loss: 0.6971 - val_accuracy: 0.5374\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6634 - accuracy: 0.5396 - val_loss: 0.6975 - val_accuracy: 0.5377\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6630 - accuracy: 0.5400 - val_loss: 0.6974 - val_accuracy: 0.5368\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6627 - accuracy: 0.5404 - val_loss: 0.6999 - val_accuracy: 0.5363\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6634 - accuracy: 0.5401 - val_loss: 0.6996 - val_accuracy: 0.5375\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6632 - accuracy: 0.5301 - val_loss: 0.7001 - val_accuracy: 0.5383\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6626 - accuracy: 0.5403 - val_loss: 0.6985 - val_accuracy: 0.5375\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6626 - accuracy: 0.5404 - val_loss: 0.6985 - val_accuracy: 0.5375\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6622 - accuracy: 0.5404 - val_loss: 0.6997 - val_accuracy: 0.5378\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6620 - accuracy: 0.5407 - val_loss: 0.7008 - val_accuracy: 0.5381\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6617 - accuracy: 0.5408 - val_loss: 0.7013 - val_accuracy: 0.5375\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6620 - accuracy: 0.5410 - val_loss: 0.7013 - val_accuracy: 0.5362\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6618 - accuracy: 0.5410 - val_loss: 0.6999 - val_accuracy: 0.5382\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6617 - accuracy: 0.5410 - val_loss: 0.7020 - val_accuracy: 0.5372\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6622 - accuracy: 0.5408 - val_loss: 0.7008 - val_accuracy: 0.5371\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6615 - accuracy: 0.5411 - val_loss: 0.7015 - val_accuracy: 0.5373\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6615 - accuracy: 0.5411 - val_loss: 0.6994 - val_accuracy: 0.5368\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6616 - accuracy: 0.5413 - val_loss: 0.7010 - val_accuracy: 0.5375\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6616 - accuracy: 0.5411 - val_loss: 0.6999 - val_accuracy: 0.5375\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6613 - accuracy: 0.5411 - val_loss: 0.7004 - val_accuracy: 0.5371\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6613 - accuracy: 0.5414 - val_loss: 0.7009 - val_accuracy: 0.5378\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6612 - accuracy: 0.5412 - val_loss: 0.7004 - val_accuracy: 0.5368\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6616 - accuracy: 0.5412 - val_loss: 0.7005 - val_accuracy: 0.5380\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6612 - accuracy: 0.5414 - val_loss: 0.7018 - val_accuracy: 0.5376\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6609 - accuracy: 0.5416 - val_loss: 0.7024 - val_accuracy: 0.5373\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6610 - accuracy: 0.5414 - val_loss: 0.7013 - val_accuracy: 0.5374\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6605 - accuracy: 0.5416 - val_loss: 0.7018 - val_accuracy: 0.5370\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6611 - accuracy: 0.5414 - val_loss: 0.7014 - val_accuracy: 0.5365\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6610 - accuracy: 0.5415 - val_loss: 0.7028 - val_accuracy: 0.5373\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6606 - accuracy: 0.5418 - val_loss: 0.7014 - val_accuracy: 0.5377\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6609 - accuracy: 0.5418 - val_loss: 0.7033 - val_accuracy: 0.5377\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 0.7050 - accuracy: 0.5371\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 76ms/step - loss: 0.6900 - accuracy: 0.5194 - val_loss: 0.6891 - val_accuracy: 0.4965\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6876 - accuracy: 0.5305 - val_loss: 0.6886 - val_accuracy: 0.4975\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6858 - accuracy: 0.5313 - val_loss: 0.6881 - val_accuracy: 0.4974\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6842 - accuracy: 0.5333 - val_loss: 0.6886 - val_accuracy: 0.4973\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6834 - accuracy: 0.5345 - val_loss: 0.6886 - val_accuracy: 0.4978\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6823 - accuracy: 0.5351 - val_loss: 0.6881 - val_accuracy: 0.4991\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6816 - accuracy: 0.5359 - val_loss: 0.6889 - val_accuracy: 0.4980\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6807 - accuracy: 0.5366 - val_loss: 0.6881 - val_accuracy: 0.4989\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6800 - accuracy: 0.5376 - val_loss: 0.6887 - val_accuracy: 0.5002\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6795 - accuracy: 0.5377 - val_loss: 0.6885 - val_accuracy: 0.4983\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6786 - accuracy: 0.5386 - val_loss: 0.6892 - val_accuracy: 0.4987\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6780 - accuracy: 0.5387 - val_loss: 0.6894 - val_accuracy: 0.4968\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6776 - accuracy: 0.5396 - val_loss: 0.6923 - val_accuracy: 0.4972\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6774 - accuracy: 0.5398 - val_loss: 0.6891 - val_accuracy: 0.4990\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6763 - accuracy: 0.5401 - val_loss: 0.6917 - val_accuracy: 0.4988\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6758 - accuracy: 0.5407 - val_loss: 0.6912 - val_accuracy: 0.4975\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6752 - accuracy: 0.5410 - val_loss: 0.6905 - val_accuracy: 0.4970\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6750 - accuracy: 0.5411 - val_loss: 0.6922 - val_accuracy: 0.4996\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6745 - accuracy: 0.5413 - val_loss: 0.6910 - val_accuracy: 0.4980\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6739 - accuracy: 0.5417 - val_loss: 0.6914 - val_accuracy: 0.4977\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6734 - accuracy: 0.5423 - val_loss: 0.6925 - val_accuracy: 0.4983\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6731 - accuracy: 0.5425 - val_loss: 0.6929 - val_accuracy: 0.4976\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6728 - accuracy: 0.5426 - val_loss: 0.6925 - val_accuracy: 0.4981\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 4s 49ms/step - loss: 0.6728 - accuracy: 0.5423 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6720 - accuracy: 0.5431 - val_loss: 0.6933 - val_accuracy: 0.4975\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6715 - accuracy: 0.5432 - val_loss: 0.6935 - val_accuracy: 0.4979\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6712 - accuracy: 0.5435 - val_loss: 0.6949 - val_accuracy: 0.4986\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 8s 105ms/step - loss: 0.6711 - accuracy: 0.5434 - val_loss: 0.6941 - val_accuracy: 0.4972\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6706 - accuracy: 0.5440 - val_loss: 0.6975 - val_accuracy: 0.4992\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6708 - accuracy: 0.5439 - val_loss: 0.6949 - val_accuracy: 0.4975\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6704 - accuracy: 0.5442 - val_loss: 0.6957 - val_accuracy: 0.4976\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 5s 76ms/step - loss: 0.6703 - accuracy: 0.5442 - val_loss: 0.6952 - val_accuracy: 0.4976\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6692 - accuracy: 0.5448 - val_loss: 0.6968 - val_accuracy: 0.4967\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6693 - accuracy: 0.5450 - val_loss: 0.6958 - val_accuracy: 0.4969\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6685 - accuracy: 0.5452 - val_loss: 0.6976 - val_accuracy: 0.4975\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6686 - accuracy: 0.5453 - val_loss: 0.6981 - val_accuracy: 0.4975\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6685 - accuracy: 0.5455 - val_loss: 0.6999 - val_accuracy: 0.4981\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6682 - accuracy: 0.5459 - val_loss: 0.6990 - val_accuracy: 0.4974\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6680 - accuracy: 0.5458 - val_loss: 0.7009 - val_accuracy: 0.4977\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6676 - accuracy: 0.5461 - val_loss: 0.6987 - val_accuracy: 0.4974\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6675 - accuracy: 0.5459 - val_loss: 0.6984 - val_accuracy: 0.4969\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6673 - accuracy: 0.5462 - val_loss: 0.6994 - val_accuracy: 0.4986\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6669 - accuracy: 0.5464 - val_loss: 0.7017 - val_accuracy: 0.4985\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6668 - accuracy: 0.5468 - val_loss: 0.7012 - val_accuracy: 0.4978\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6667 - accuracy: 0.5466 - val_loss: 0.7024 - val_accuracy: 0.4975\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6670 - accuracy: 0.5464 - val_loss: 0.7008 - val_accuracy: 0.4983\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6662 - accuracy: 0.5470 - val_loss: 0.7008 - val_accuracy: 0.4972\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6655 - accuracy: 0.5474 - val_loss: 0.7041 - val_accuracy: 0.4983\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6660 - accuracy: 0.5471 - val_loss: 0.7026 - val_accuracy: 0.4978\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6654 - accuracy: 0.5476 - val_loss: 0.7052 - val_accuracy: 0.4986\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6659 - accuracy: 0.5474 - val_loss: 0.7025 - val_accuracy: 0.4980\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6653 - accuracy: 0.5476 - val_loss: 0.7056 - val_accuracy: 0.4966\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6656 - accuracy: 0.5474 - val_loss: 0.7031 - val_accuracy: 0.4976\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6650 - accuracy: 0.5481 - val_loss: 0.7060 - val_accuracy: 0.4974\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6644 - accuracy: 0.5482 - val_loss: 0.7056 - val_accuracy: 0.4973\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6646 - accuracy: 0.5479 - val_loss: 0.7084 - val_accuracy: 0.4982\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6647 - accuracy: 0.5480 - val_loss: 0.7038 - val_accuracy: 0.4977\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6640 - accuracy: 0.5483 - val_loss: 0.7076 - val_accuracy: 0.4986\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6644 - accuracy: 0.5484 - val_loss: 0.7052 - val_accuracy: 0.4979\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6642 - accuracy: 0.5485 - val_loss: 0.7062 - val_accuracy: 0.4983\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6637 - accuracy: 0.5486 - val_loss: 0.7051 - val_accuracy: 0.4985\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6637 - accuracy: 0.5489 - val_loss: 0.7062 - val_accuracy: 0.4981\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6636 - accuracy: 0.5487 - val_loss: 0.7101 - val_accuracy: 0.4996\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6638 - accuracy: 0.5451 - val_loss: 0.7069 - val_accuracy: 0.4966\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6634 - accuracy: 0.5491 - val_loss: 0.7063 - val_accuracy: 0.4979\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6632 - accuracy: 0.5490 - val_loss: 0.7100 - val_accuracy: 0.4984\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6631 - accuracy: 0.5494 - val_loss: 0.7066 - val_accuracy: 0.4970\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6631 - accuracy: 0.5496 - val_loss: 0.7079 - val_accuracy: 0.4988\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6630 - accuracy: 0.5492 - val_loss: 0.7067 - val_accuracy: 0.4975\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6625 - accuracy: 0.5498 - val_loss: 0.7086 - val_accuracy: 0.4979\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6629 - accuracy: 0.5495 - val_loss: 0.7076 - val_accuracy: 0.4977\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6621 - accuracy: 0.5497 - val_loss: 0.7093 - val_accuracy: 0.4977\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6624 - accuracy: 0.5497 - val_loss: 0.7097 - val_accuracy: 0.4981\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6621 - accuracy: 0.5498 - val_loss: 0.7115 - val_accuracy: 0.4980\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6626 - accuracy: 0.5495 - val_loss: 0.7084 - val_accuracy: 0.4974\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6622 - accuracy: 0.5500 - val_loss: 0.7092 - val_accuracy: 0.4981\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6619 - accuracy: 0.5501 - val_loss: 0.7104 - val_accuracy: 0.4979\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6619 - accuracy: 0.5501 - val_loss: 0.7099 - val_accuracy: 0.4978\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6621 - accuracy: 0.5498 - val_loss: 0.7084 - val_accuracy: 0.4979\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6616 - accuracy: 0.5501 - val_loss: 0.7095 - val_accuracy: 0.4979\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6610 - accuracy: 0.5507 - val_loss: 0.7127 - val_accuracy: 0.4985\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 4s 50ms/step - loss: 0.6617 - accuracy: 0.5506 - val_loss: 0.7132 - val_accuracy: 0.4990\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6616 - accuracy: 0.5506 - val_loss: 0.7128 - val_accuracy: 0.4982\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6612 - accuracy: 0.5506 - val_loss: 0.7122 - val_accuracy: 0.4977\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6612 - accuracy: 0.5507 - val_loss: 0.7101 - val_accuracy: 0.4977\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6610 - accuracy: 0.5507 - val_loss: 0.7106 - val_accuracy: 0.4979\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6608 - accuracy: 0.5507 - val_loss: 0.7126 - val_accuracy: 0.4984\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6614 - accuracy: 0.5505 - val_loss: 0.7124 - val_accuracy: 0.4985\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6605 - accuracy: 0.5509 - val_loss: 0.7131 - val_accuracy: 0.4990\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6605 - accuracy: 0.5509 - val_loss: 0.7123 - val_accuracy: 0.4986\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6603 - accuracy: 0.5513 - val_loss: 0.7100 - val_accuracy: 0.4974\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6602 - accuracy: 0.5512 - val_loss: 0.7131 - val_accuracy: 0.4987\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6605 - accuracy: 0.5511 - val_loss: 0.7118 - val_accuracy: 0.4975\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6606 - accuracy: 0.5510 - val_loss: 0.7115 - val_accuracy: 0.4983\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6599 - accuracy: 0.5516 - val_loss: 0.7120 - val_accuracy: 0.4980\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6603 - accuracy: 0.5513 - val_loss: 0.7112 - val_accuracy: 0.4986\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 4s 52ms/step - loss: 0.6599 - accuracy: 0.5515 - val_loss: 0.7129 - val_accuracy: 0.4980\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6600 - accuracy: 0.5516 - val_loss: 0.7161 - val_accuracy: 0.4974\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6603 - accuracy: 0.5514 - val_loss: 0.7162 - val_accuracy: 0.4984\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 4s 53ms/step - loss: 0.6597 - accuracy: 0.5515 - val_loss: 0.7144 - val_accuracy: 0.4979\n",
            "19/19 [==============================] - 1s 15ms/step - loss: 0.7201 - accuracy: 0.4960\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 5s 57ms/step - loss: 0.6903 - accuracy: 0.5021 - val_loss: 0.6866 - val_accuracy: 0.5352\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 7s 91ms/step - loss: 0.6879 - accuracy: 0.5200 - val_loss: 0.6858 - val_accuracy: 0.5385\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 4s 51ms/step - loss: 0.6869 - accuracy: 0.5217 - val_loss: 0.6847 - val_accuracy: 0.5387\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6860 - accuracy: 0.5215 - val_loss: 0.6844 - val_accuracy: 0.5390\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6847 - accuracy: 0.5231 - val_loss: 0.6843 - val_accuracy: 0.5394\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6839 - accuracy: 0.5242 - val_loss: 0.6843 - val_accuracy: 0.5393\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6831 - accuracy: 0.5249 - val_loss: 0.6840 - val_accuracy: 0.5387\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6824 - accuracy: 0.5256 - val_loss: 0.6834 - val_accuracy: 0.5396\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6817 - accuracy: 0.5260 - val_loss: 0.6840 - val_accuracy: 0.5390\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 4s 54ms/step - loss: 0.6808 - accuracy: 0.5266 - val_loss: 0.6857 - val_accuracy: 0.5357\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6802 - accuracy: 0.5271 - val_loss: 0.6843 - val_accuracy: 0.5382\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6795 - accuracy: 0.5278 - val_loss: 0.6853 - val_accuracy: 0.5392\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6792 - accuracy: 0.5282 - val_loss: 0.6850 - val_accuracy: 0.5379\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6783 - accuracy: 0.5285 - val_loss: 0.6851 - val_accuracy: 0.5385\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6780 - accuracy: 0.5291 - val_loss: 0.6851 - val_accuracy: 0.5378\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6777 - accuracy: 0.5292 - val_loss: 0.6868 - val_accuracy: 0.5393\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6772 - accuracy: 0.5297 - val_loss: 0.6862 - val_accuracy: 0.5394\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6764 - accuracy: 0.5305 - val_loss: 0.6855 - val_accuracy: 0.5386\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6758 - accuracy: 0.5308 - val_loss: 0.6857 - val_accuracy: 0.5389\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6754 - accuracy: 0.5309 - val_loss: 0.6861 - val_accuracy: 0.5383\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6749 - accuracy: 0.5316 - val_loss: 0.6867 - val_accuracy: 0.5376\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6745 - accuracy: 0.5321 - val_loss: 0.6879 - val_accuracy: 0.5356\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6744 - accuracy: 0.5318 - val_loss: 0.6872 - val_accuracy: 0.5388\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6738 - accuracy: 0.5325 - val_loss: 0.6874 - val_accuracy: 0.5373\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6733 - accuracy: 0.5327 - val_loss: 0.6871 - val_accuracy: 0.5385\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6735 - accuracy: 0.5324 - val_loss: 0.6868 - val_accuracy: 0.5391\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6726 - accuracy: 0.5332 - val_loss: 0.6877 - val_accuracy: 0.5382\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6721 - accuracy: 0.5336 - val_loss: 0.6885 - val_accuracy: 0.5373\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6720 - accuracy: 0.5337 - val_loss: 0.6880 - val_accuracy: 0.5377\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6715 - accuracy: 0.5343 - val_loss: 0.6901 - val_accuracy: 0.5360\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6712 - accuracy: 0.5340 - val_loss: 0.6893 - val_accuracy: 0.5390\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6710 - accuracy: 0.5347 - val_loss: 0.6886 - val_accuracy: 0.5380\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6707 - accuracy: 0.5347 - val_loss: 0.6886 - val_accuracy: 0.5381\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6702 - accuracy: 0.5351 - val_loss: 0.6895 - val_accuracy: 0.5395\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6699 - accuracy: 0.5354 - val_loss: 0.6904 - val_accuracy: 0.5386\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6698 - accuracy: 0.5352 - val_loss: 0.6896 - val_accuracy: 0.5383\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6691 - accuracy: 0.5289 - val_loss: 0.6914 - val_accuracy: 0.5369\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6692 - accuracy: 0.5284 - val_loss: 0.6908 - val_accuracy: 0.5380\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6692 - accuracy: 0.5358 - val_loss: 0.6919 - val_accuracy: 0.5388\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6687 - accuracy: 0.5360 - val_loss: 0.6904 - val_accuracy: 0.5386\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6686 - accuracy: 0.5349 - val_loss: 0.6930 - val_accuracy: 0.5381\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6685 - accuracy: 0.5332 - val_loss: 0.6912 - val_accuracy: 0.5376\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6677 - accuracy: 0.5366 - val_loss: 0.6928 - val_accuracy: 0.5381\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6678 - accuracy: 0.5367 - val_loss: 0.6943 - val_accuracy: 0.5376\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6681 - accuracy: 0.5338 - val_loss: 0.6928 - val_accuracy: 0.5376\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6672 - accuracy: 0.5349 - val_loss: 0.6937 - val_accuracy: 0.5374\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6671 - accuracy: 0.5374 - val_loss: 0.6939 - val_accuracy: 0.5377\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6668 - accuracy: 0.5375 - val_loss: 0.6938 - val_accuracy: 0.5380\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6663 - accuracy: 0.5380 - val_loss: 0.6945 - val_accuracy: 0.5378\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6663 - accuracy: 0.5379 - val_loss: 0.6943 - val_accuracy: 0.5379\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6665 - accuracy: 0.5277 - val_loss: 0.6952 - val_accuracy: 0.5370\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6666 - accuracy: 0.5378 - val_loss: 0.6960 - val_accuracy: 0.5380\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6661 - accuracy: 0.5381 - val_loss: 0.6951 - val_accuracy: 0.5369\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6662 - accuracy: 0.5382 - val_loss: 0.6935 - val_accuracy: 0.5371\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 4s 55ms/step - loss: 0.6657 - accuracy: 0.5382 - val_loss: 0.6952 - val_accuracy: 0.5370\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6652 - accuracy: 0.5388 - val_loss: 0.6951 - val_accuracy: 0.5373\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6649 - accuracy: 0.5390 - val_loss: 0.6975 - val_accuracy: 0.5372\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6653 - accuracy: 0.5385 - val_loss: 0.6959 - val_accuracy: 0.5376\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6651 - accuracy: 0.5385 - val_loss: 0.6967 - val_accuracy: 0.5384\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6648 - accuracy: 0.5389 - val_loss: 0.6956 - val_accuracy: 0.5372\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6643 - accuracy: 0.5392 - val_loss: 0.6977 - val_accuracy: 0.5375\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6648 - accuracy: 0.5386 - val_loss: 0.6972 - val_accuracy: 0.5373\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6648 - accuracy: 0.5393 - val_loss: 0.6961 - val_accuracy: 0.5380\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6643 - accuracy: 0.5392 - val_loss: 0.6984 - val_accuracy: 0.5377\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6642 - accuracy: 0.5392 - val_loss: 0.6978 - val_accuracy: 0.5376\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6640 - accuracy: 0.5394 - val_loss: 0.6998 - val_accuracy: 0.5377\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6637 - accuracy: 0.5396 - val_loss: 0.6977 - val_accuracy: 0.5375\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6639 - accuracy: 0.5395 - val_loss: 0.6984 - val_accuracy: 0.5370\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6635 - accuracy: 0.5398 - val_loss: 0.6990 - val_accuracy: 0.5371\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6637 - accuracy: 0.5398 - val_loss: 0.6976 - val_accuracy: 0.5368\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6637 - accuracy: 0.5396 - val_loss: 0.6983 - val_accuracy: 0.5376\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6630 - accuracy: 0.5403 - val_loss: 0.6983 - val_accuracy: 0.5371\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6633 - accuracy: 0.5400 - val_loss: 0.6993 - val_accuracy: 0.5370\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6628 - accuracy: 0.5403 - val_loss: 0.6984 - val_accuracy: 0.5374\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6629 - accuracy: 0.5404 - val_loss: 0.6998 - val_accuracy: 0.5362\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6627 - accuracy: 0.5404 - val_loss: 0.7006 - val_accuracy: 0.5371\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6622 - accuracy: 0.5408 - val_loss: 0.7005 - val_accuracy: 0.5365\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6627 - accuracy: 0.5405 - val_loss: 0.7010 - val_accuracy: 0.5362\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6624 - accuracy: 0.5405 - val_loss: 0.6997 - val_accuracy: 0.5363\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6626 - accuracy: 0.5405 - val_loss: 0.7015 - val_accuracy: 0.5375\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6621 - accuracy: 0.5407 - val_loss: 0.7016 - val_accuracy: 0.5366\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6619 - accuracy: 0.5409 - val_loss: 0.7016 - val_accuracy: 0.5367\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6625 - accuracy: 0.5407 - val_loss: 0.6995 - val_accuracy: 0.5364\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6622 - accuracy: 0.5407 - val_loss: 0.7011 - val_accuracy: 0.5373\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6615 - accuracy: 0.5413 - val_loss: 0.7010 - val_accuracy: 0.5369\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6616 - accuracy: 0.5410 - val_loss: 0.7015 - val_accuracy: 0.5368\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6621 - accuracy: 0.5404 - val_loss: 0.7023 - val_accuracy: 0.5366\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6619 - accuracy: 0.5410 - val_loss: 0.7034 - val_accuracy: 0.5360\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6623 - accuracy: 0.5406 - val_loss: 0.7023 - val_accuracy: 0.5368\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6613 - accuracy: 0.5410 - val_loss: 0.7038 - val_accuracy: 0.5370\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6611 - accuracy: 0.5413 - val_loss: 0.7047 - val_accuracy: 0.5373\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6616 - accuracy: 0.5413 - val_loss: 0.7026 - val_accuracy: 0.5368\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6617 - accuracy: 0.5405 - val_loss: 0.7030 - val_accuracy: 0.5368\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6612 - accuracy: 0.5412 - val_loss: 0.7036 - val_accuracy: 0.5369\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6612 - accuracy: 0.5418 - val_loss: 0.7035 - val_accuracy: 0.5371\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6612 - accuracy: 0.5415 - val_loss: 0.7033 - val_accuracy: 0.5365\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6611 - accuracy: 0.5416 - val_loss: 0.7035 - val_accuracy: 0.5369\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6610 - accuracy: 0.5415 - val_loss: 0.7042 - val_accuracy: 0.5373\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6608 - accuracy: 0.5411 - val_loss: 0.7049 - val_accuracy: 0.5362\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6611 - accuracy: 0.5331 - val_loss: 0.7044 - val_accuracy: 0.5376\n",
            "19/19 [==============================] - 1s 25ms/step - loss: 0.7067 - accuracy: 0.5369\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 6s 63ms/step - loss: 0.6905 - accuracy: 0.5185 - val_loss: 0.6894 - val_accuracy: 0.5084\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6874 - accuracy: 0.5265 - val_loss: 0.6890 - val_accuracy: 0.5090\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6856 - accuracy: 0.5291 - val_loss: 0.6885 - val_accuracy: 0.5097\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6848 - accuracy: 0.5302 - val_loss: 0.6883 - val_accuracy: 0.5091\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6840 - accuracy: 0.5305 - val_loss: 0.6882 - val_accuracy: 0.5097\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6830 - accuracy: 0.5323 - val_loss: 0.6880 - val_accuracy: 0.5100\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6816 - accuracy: 0.5334 - val_loss: 0.6895 - val_accuracy: 0.5103\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6813 - accuracy: 0.5336 - val_loss: 0.6885 - val_accuracy: 0.5092\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6801 - accuracy: 0.5345 - val_loss: 0.6896 - val_accuracy: 0.5097\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6795 - accuracy: 0.5343 - val_loss: 0.6895 - val_accuracy: 0.5100\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6788 - accuracy: 0.5355 - val_loss: 0.6909 - val_accuracy: 0.5100\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6784 - accuracy: 0.5355 - val_loss: 0.6899 - val_accuracy: 0.5097\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6782 - accuracy: 0.5357 - val_loss: 0.6917 - val_accuracy: 0.5100\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6774 - accuracy: 0.5362 - val_loss: 0.6930 - val_accuracy: 0.5098\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6767 - accuracy: 0.5367 - val_loss: 0.6933 - val_accuracy: 0.5103\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6760 - accuracy: 0.5375 - val_loss: 0.6934 - val_accuracy: 0.5099\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6757 - accuracy: 0.5375 - val_loss: 0.6950 - val_accuracy: 0.5100\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6752 - accuracy: 0.5379 - val_loss: 0.6980 - val_accuracy: 0.5093\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6752 - accuracy: 0.5382 - val_loss: 0.6935 - val_accuracy: 0.5101\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6743 - accuracy: 0.5387 - val_loss: 0.6948 - val_accuracy: 0.5098\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6739 - accuracy: 0.5389 - val_loss: 0.6970 - val_accuracy: 0.5103\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6736 - accuracy: 0.5390 - val_loss: 0.6957 - val_accuracy: 0.5100\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6731 - accuracy: 0.5395 - val_loss: 0.7005 - val_accuracy: 0.5095\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6729 - accuracy: 0.5396 - val_loss: 0.6979 - val_accuracy: 0.5091\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6724 - accuracy: 0.5399 - val_loss: 0.6997 - val_accuracy: 0.5092\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6716 - accuracy: 0.5404 - val_loss: 0.7001 - val_accuracy: 0.5093\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6717 - accuracy: 0.5404 - val_loss: 0.6996 - val_accuracy: 0.5096\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6711 - accuracy: 0.5407 - val_loss: 0.7020 - val_accuracy: 0.5096\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6711 - accuracy: 0.5407 - val_loss: 0.7030 - val_accuracy: 0.5096\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6708 - accuracy: 0.5413 - val_loss: 0.7033 - val_accuracy: 0.5090\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6706 - accuracy: 0.5412 - val_loss: 0.7027 - val_accuracy: 0.5092\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6700 - accuracy: 0.5417 - val_loss: 0.7023 - val_accuracy: 0.5094\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6695 - accuracy: 0.5417 - val_loss: 0.7077 - val_accuracy: 0.5089\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6695 - accuracy: 0.5417 - val_loss: 0.7056 - val_accuracy: 0.5089\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6696 - accuracy: 0.5420 - val_loss: 0.7037 - val_accuracy: 0.5092\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6694 - accuracy: 0.5420 - val_loss: 0.7052 - val_accuracy: 0.5095\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6689 - accuracy: 0.5424 - val_loss: 0.7046 - val_accuracy: 0.5095\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6683 - accuracy: 0.5429 - val_loss: 0.7082 - val_accuracy: 0.5093\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6685 - accuracy: 0.5427 - val_loss: 0.7076 - val_accuracy: 0.5093\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6679 - accuracy: 0.5432 - val_loss: 0.7080 - val_accuracy: 0.5090\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6677 - accuracy: 0.5431 - val_loss: 0.7091 - val_accuracy: 0.5092\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6673 - accuracy: 0.5434 - val_loss: 0.7086 - val_accuracy: 0.5090\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6673 - accuracy: 0.5432 - val_loss: 0.7096 - val_accuracy: 0.5087\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6673 - accuracy: 0.5438 - val_loss: 0.7138 - val_accuracy: 0.5093\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6670 - accuracy: 0.5439 - val_loss: 0.7104 - val_accuracy: 0.5090\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6665 - accuracy: 0.5443 - val_loss: 0.7124 - val_accuracy: 0.5094\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6664 - accuracy: 0.5439 - val_loss: 0.7133 - val_accuracy: 0.5089\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6661 - accuracy: 0.5444 - val_loss: 0.7128 - val_accuracy: 0.5088\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6663 - accuracy: 0.5444 - val_loss: 0.7111 - val_accuracy: 0.5084\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6656 - accuracy: 0.5448 - val_loss: 0.7142 - val_accuracy: 0.5090\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6658 - accuracy: 0.5447 - val_loss: 0.7134 - val_accuracy: 0.5093\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6654 - accuracy: 0.5449 - val_loss: 0.7159 - val_accuracy: 0.5089\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6648 - accuracy: 0.5454 - val_loss: 0.7158 - val_accuracy: 0.5089\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6650 - accuracy: 0.5451 - val_loss: 0.7137 - val_accuracy: 0.5088\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6647 - accuracy: 0.5452 - val_loss: 0.7147 - val_accuracy: 0.5086\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6645 - accuracy: 0.5455 - val_loss: 0.7156 - val_accuracy: 0.5085\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6643 - accuracy: 0.5456 - val_loss: 0.7176 - val_accuracy: 0.5086\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6643 - accuracy: 0.5458 - val_loss: 0.7179 - val_accuracy: 0.5083\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6640 - accuracy: 0.5459 - val_loss: 0.7174 - val_accuracy: 0.5081\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6640 - accuracy: 0.5461 - val_loss: 0.7169 - val_accuracy: 0.5083\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6634 - accuracy: 0.5462 - val_loss: 0.7204 - val_accuracy: 0.5081\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6635 - accuracy: 0.5463 - val_loss: 0.7182 - val_accuracy: 0.5085\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6633 - accuracy: 0.5465 - val_loss: 0.7205 - val_accuracy: 0.5081\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6635 - accuracy: 0.5462 - val_loss: 0.7244 - val_accuracy: 0.5084\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6634 - accuracy: 0.5464 - val_loss: 0.7218 - val_accuracy: 0.5085\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6631 - accuracy: 0.5465 - val_loss: 0.7175 - val_accuracy: 0.5081\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6628 - accuracy: 0.5468 - val_loss: 0.7232 - val_accuracy: 0.5085\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6631 - accuracy: 0.5467 - val_loss: 0.7208 - val_accuracy: 0.5083\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6638 - accuracy: 0.5463 - val_loss: 0.7193 - val_accuracy: 0.5084\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6627 - accuracy: 0.5471 - val_loss: 0.7253 - val_accuracy: 0.5086\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6630 - accuracy: 0.5384 - val_loss: 0.7202 - val_accuracy: 0.5085\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6626 - accuracy: 0.5470 - val_loss: 0.7258 - val_accuracy: 0.5088\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6625 - accuracy: 0.5470 - val_loss: 0.7196 - val_accuracy: 0.5083\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6624 - accuracy: 0.5469 - val_loss: 0.7249 - val_accuracy: 0.5082\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6617 - accuracy: 0.5473 - val_loss: 0.7204 - val_accuracy: 0.5081\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6618 - accuracy: 0.5472 - val_loss: 0.7271 - val_accuracy: 0.5079\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6621 - accuracy: 0.5472 - val_loss: 0.7209 - val_accuracy: 0.5083\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6617 - accuracy: 0.5474 - val_loss: 0.7251 - val_accuracy: 0.5087\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6611 - accuracy: 0.5476 - val_loss: 0.7261 - val_accuracy: 0.5087\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6612 - accuracy: 0.5477 - val_loss: 0.7229 - val_accuracy: 0.5084\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6608 - accuracy: 0.5479 - val_loss: 0.7265 - val_accuracy: 0.5087\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6612 - accuracy: 0.5478 - val_loss: 0.7251 - val_accuracy: 0.5082\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6609 - accuracy: 0.5480 - val_loss: 0.7212 - val_accuracy: 0.5086\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6609 - accuracy: 0.5479 - val_loss: 0.7221 - val_accuracy: 0.5084\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6609 - accuracy: 0.5479 - val_loss: 0.7251 - val_accuracy: 0.5083\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6607 - accuracy: 0.5482 - val_loss: 0.7284 - val_accuracy: 0.5084\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6607 - accuracy: 0.5481 - val_loss: 0.7242 - val_accuracy: 0.5085\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6608 - accuracy: 0.5478 - val_loss: 0.7252 - val_accuracy: 0.5085\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6604 - accuracy: 0.5483 - val_loss: 0.7307 - val_accuracy: 0.5087\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6602 - accuracy: 0.5482 - val_loss: 0.7275 - val_accuracy: 0.5085\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6600 - accuracy: 0.5484 - val_loss: 0.7264 - val_accuracy: 0.5082\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6598 - accuracy: 0.5485 - val_loss: 0.7251 - val_accuracy: 0.5087\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6598 - accuracy: 0.5487 - val_loss: 0.7286 - val_accuracy: 0.5086\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6602 - accuracy: 0.5492 - val_loss: 0.7256 - val_accuracy: 0.5084\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6604 - accuracy: 0.5420 - val_loss: 0.7304 - val_accuracy: 0.5085\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6596 - accuracy: 0.5487 - val_loss: 0.7285 - val_accuracy: 0.5083\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6596 - accuracy: 0.5488 - val_loss: 0.7276 - val_accuracy: 0.5086\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6597 - accuracy: 0.5487 - val_loss: 0.7268 - val_accuracy: 0.5088\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6596 - accuracy: 0.5487 - val_loss: 0.7298 - val_accuracy: 0.5080\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6598 - accuracy: 0.5487 - val_loss: 0.7304 - val_accuracy: 0.5092\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 0.7279 - accuracy: 0.5091\n",
            "Best accuracy for dataset 1: 0.5400651693344116\n",
            "2308\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 71ms/step - loss: 0.6912 - accuracy: 0.4946 - val_loss: 0.6877 - val_accuracy: 0.5371\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6886 - accuracy: 0.5106 - val_loss: 0.6870 - val_accuracy: 0.5435\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6870 - accuracy: 0.5194 - val_loss: 0.6851 - val_accuracy: 0.5429\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6859 - accuracy: 0.5201 - val_loss: 0.6846 - val_accuracy: 0.5437\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6847 - accuracy: 0.5215 - val_loss: 0.6845 - val_accuracy: 0.5436\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6842 - accuracy: 0.5224 - val_loss: 0.6853 - val_accuracy: 0.5424\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6832 - accuracy: 0.5228 - val_loss: 0.6846 - val_accuracy: 0.5453\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6829 - accuracy: 0.5240 - val_loss: 0.6847 - val_accuracy: 0.5439\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6815 - accuracy: 0.5246 - val_loss: 0.6849 - val_accuracy: 0.5441\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6811 - accuracy: 0.5247 - val_loss: 0.6843 - val_accuracy: 0.5453\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6799 - accuracy: 0.5261 - val_loss: 0.6849 - val_accuracy: 0.5447\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6794 - accuracy: 0.5264 - val_loss: 0.6848 - val_accuracy: 0.5448\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6788 - accuracy: 0.5269 - val_loss: 0.6848 - val_accuracy: 0.5449\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6784 - accuracy: 0.5272 - val_loss: 0.6858 - val_accuracy: 0.5444\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6775 - accuracy: 0.5276 - val_loss: 0.6876 - val_accuracy: 0.5441\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6774 - accuracy: 0.5284 - val_loss: 0.6862 - val_accuracy: 0.5453\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6765 - accuracy: 0.5291 - val_loss: 0.6867 - val_accuracy: 0.5446\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6759 - accuracy: 0.5295 - val_loss: 0.6861 - val_accuracy: 0.5450\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6757 - accuracy: 0.5295 - val_loss: 0.6855 - val_accuracy: 0.5442\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6753 - accuracy: 0.5297 - val_loss: 0.6870 - val_accuracy: 0.5447\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6751 - accuracy: 0.5300 - val_loss: 0.6867 - val_accuracy: 0.5447\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6747 - accuracy: 0.5301 - val_loss: 0.6866 - val_accuracy: 0.5447\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6740 - accuracy: 0.5310 - val_loss: 0.6862 - val_accuracy: 0.5447\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6735 - accuracy: 0.5311 - val_loss: 0.6863 - val_accuracy: 0.5445\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6730 - accuracy: 0.5314 - val_loss: 0.6870 - val_accuracy: 0.5447\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6724 - accuracy: 0.5316 - val_loss: 0.6872 - val_accuracy: 0.5447\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6722 - accuracy: 0.5319 - val_loss: 0.6879 - val_accuracy: 0.5451\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6718 - accuracy: 0.5324 - val_loss: 0.6881 - val_accuracy: 0.5445\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6712 - accuracy: 0.5329 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6709 - accuracy: 0.5327 - val_loss: 0.6895 - val_accuracy: 0.5448\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6709 - accuracy: 0.5286 - val_loss: 0.6888 - val_accuracy: 0.5447\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6703 - accuracy: 0.5335 - val_loss: 0.6890 - val_accuracy: 0.5445\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6705 - accuracy: 0.5329 - val_loss: 0.6896 - val_accuracy: 0.5449\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6706 - accuracy: 0.5336 - val_loss: 0.6904 - val_accuracy: 0.5450\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6699 - accuracy: 0.5337 - val_loss: 0.6889 - val_accuracy: 0.5458\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6694 - accuracy: 0.5341 - val_loss: 0.6889 - val_accuracy: 0.5459\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6688 - accuracy: 0.5344 - val_loss: 0.6893 - val_accuracy: 0.5450\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6689 - accuracy: 0.5344 - val_loss: 0.6890 - val_accuracy: 0.5453\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6683 - accuracy: 0.5348 - val_loss: 0.6893 - val_accuracy: 0.5455\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6684 - accuracy: 0.5347 - val_loss: 0.6891 - val_accuracy: 0.5451\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6678 - accuracy: 0.5338 - val_loss: 0.6899 - val_accuracy: 0.5451\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6676 - accuracy: 0.5355 - val_loss: 0.6909 - val_accuracy: 0.5451\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6681 - accuracy: 0.5350 - val_loss: 0.6904 - val_accuracy: 0.5448\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6674 - accuracy: 0.5356 - val_loss: 0.6931 - val_accuracy: 0.5449\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6670 - accuracy: 0.5359 - val_loss: 0.6902 - val_accuracy: 0.5449\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6664 - accuracy: 0.5361 - val_loss: 0.6913 - val_accuracy: 0.5447\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6661 - accuracy: 0.5366 - val_loss: 0.6927 - val_accuracy: 0.5448\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6666 - accuracy: 0.5361 - val_loss: 0.6923 - val_accuracy: 0.5451\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6661 - accuracy: 0.5365 - val_loss: 0.6923 - val_accuracy: 0.5451\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6659 - accuracy: 0.5367 - val_loss: 0.6931 - val_accuracy: 0.5454\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6657 - accuracy: 0.5369 - val_loss: 0.6918 - val_accuracy: 0.5454\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6654 - accuracy: 0.5371 - val_loss: 0.6930 - val_accuracy: 0.5457\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6654 - accuracy: 0.5371 - val_loss: 0.6940 - val_accuracy: 0.5451\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6653 - accuracy: 0.5332 - val_loss: 0.6927 - val_accuracy: 0.5453\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6652 - accuracy: 0.5374 - val_loss: 0.6919 - val_accuracy: 0.5451\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6650 - accuracy: 0.5372 - val_loss: 0.6932 - val_accuracy: 0.5456\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6646 - accuracy: 0.5376 - val_loss: 0.6934 - val_accuracy: 0.5448\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6644 - accuracy: 0.5374 - val_loss: 0.6935 - val_accuracy: 0.5453\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6643 - accuracy: 0.5378 - val_loss: 0.6928 - val_accuracy: 0.5452\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6638 - accuracy: 0.5378 - val_loss: 0.6935 - val_accuracy: 0.5454\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6640 - accuracy: 0.5383 - val_loss: 0.6933 - val_accuracy: 0.5444\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6644 - accuracy: 0.5375 - val_loss: 0.6963 - val_accuracy: 0.5445\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6640 - accuracy: 0.5378 - val_loss: 0.6922 - val_accuracy: 0.5445\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6635 - accuracy: 0.5382 - val_loss: 0.6943 - val_accuracy: 0.5451\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6642 - accuracy: 0.5373 - val_loss: 0.6940 - val_accuracy: 0.5452\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6633 - accuracy: 0.5381 - val_loss: 0.6947 - val_accuracy: 0.5450\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6642 - accuracy: 0.5381 - val_loss: 0.6930 - val_accuracy: 0.5443\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6629 - accuracy: 0.5385 - val_loss: 0.6961 - val_accuracy: 0.5448\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6629 - accuracy: 0.5387 - val_loss: 0.6961 - val_accuracy: 0.5450\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6630 - accuracy: 0.5385 - val_loss: 0.6935 - val_accuracy: 0.5453\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6626 - accuracy: 0.5391 - val_loss: 0.6963 - val_accuracy: 0.5444\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6625 - accuracy: 0.5391 - val_loss: 0.6954 - val_accuracy: 0.5447\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6623 - accuracy: 0.5382 - val_loss: 0.6959 - val_accuracy: 0.5453\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6623 - accuracy: 0.5392 - val_loss: 0.6967 - val_accuracy: 0.5448\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6623 - accuracy: 0.5394 - val_loss: 0.6957 - val_accuracy: 0.5444\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6624 - accuracy: 0.5393 - val_loss: 0.6967 - val_accuracy: 0.5438\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6626 - accuracy: 0.5388 - val_loss: 0.6967 - val_accuracy: 0.5439\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6621 - accuracy: 0.5391 - val_loss: 0.6953 - val_accuracy: 0.5445\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6623 - accuracy: 0.5389 - val_loss: 0.6982 - val_accuracy: 0.5438\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6620 - accuracy: 0.5392 - val_loss: 0.6971 - val_accuracy: 0.5445\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6615 - accuracy: 0.5399 - val_loss: 0.6968 - val_accuracy: 0.5437\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6617 - accuracy: 0.5396 - val_loss: 0.6978 - val_accuracy: 0.5445\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6615 - accuracy: 0.5398 - val_loss: 0.6990 - val_accuracy: 0.5440\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 5s 61ms/step - loss: 0.6614 - accuracy: 0.5397 - val_loss: 0.6973 - val_accuracy: 0.5438\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6614 - accuracy: 0.5397 - val_loss: 0.6980 - val_accuracy: 0.5441\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6612 - accuracy: 0.5369 - val_loss: 0.6991 - val_accuracy: 0.5448\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6611 - accuracy: 0.5399 - val_loss: 0.6997 - val_accuracy: 0.5444\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6610 - accuracy: 0.5400 - val_loss: 0.7004 - val_accuracy: 0.5444\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6612 - accuracy: 0.5398 - val_loss: 0.6992 - val_accuracy: 0.5441\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6611 - accuracy: 0.5398 - val_loss: 0.6976 - val_accuracy: 0.5445\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6608 - accuracy: 0.5403 - val_loss: 0.6990 - val_accuracy: 0.5443\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6606 - accuracy: 0.5402 - val_loss: 0.6997 - val_accuracy: 0.5435\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6607 - accuracy: 0.5405 - val_loss: 0.6996 - val_accuracy: 0.5441\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6604 - accuracy: 0.5404 - val_loss: 0.7001 - val_accuracy: 0.5440\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6610 - accuracy: 0.5403 - val_loss: 0.7001 - val_accuracy: 0.5436\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6604 - accuracy: 0.5405 - val_loss: 0.6994 - val_accuracy: 0.5441\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6603 - accuracy: 0.5406 - val_loss: 0.6997 - val_accuracy: 0.5439\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6601 - accuracy: 0.5408 - val_loss: 0.7009 - val_accuracy: 0.5438\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6602 - accuracy: 0.5406 - val_loss: 0.7014 - val_accuracy: 0.5439\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6602 - accuracy: 0.5380 - val_loss: 0.6996 - val_accuracy: 0.5442\n",
            "19/19 [==============================] - 1s 16ms/step - loss: 0.6999 - accuracy: 0.5439\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 78ms/step - loss: 0.6901 - accuracy: 0.5081 - val_loss: 0.6885 - val_accuracy: 0.5335\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6878 - accuracy: 0.5208 - val_loss: 0.6875 - val_accuracy: 0.5350\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6867 - accuracy: 0.5224 - val_loss: 0.6873 - val_accuracy: 0.5370\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6858 - accuracy: 0.5233 - val_loss: 0.6863 - val_accuracy: 0.5369\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6846 - accuracy: 0.5243 - val_loss: 0.6854 - val_accuracy: 0.5374\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6843 - accuracy: 0.5248 - val_loss: 0.6852 - val_accuracy: 0.5365\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6832 - accuracy: 0.5251 - val_loss: 0.6851 - val_accuracy: 0.5375\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6828 - accuracy: 0.5256 - val_loss: 0.6852 - val_accuracy: 0.5370\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6818 - accuracy: 0.5266 - val_loss: 0.6851 - val_accuracy: 0.5381\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6812 - accuracy: 0.5269 - val_loss: 0.6854 - val_accuracy: 0.5374\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6805 - accuracy: 0.5275 - val_loss: 0.6853 - val_accuracy: 0.5386\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6797 - accuracy: 0.5284 - val_loss: 0.6856 - val_accuracy: 0.5380\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6794 - accuracy: 0.5286 - val_loss: 0.6854 - val_accuracy: 0.5389\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6789 - accuracy: 0.5286 - val_loss: 0.6859 - val_accuracy: 0.5377\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6785 - accuracy: 0.5290 - val_loss: 0.6858 - val_accuracy: 0.5393\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6784 - accuracy: 0.5295 - val_loss: 0.6871 - val_accuracy: 0.5386\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6776 - accuracy: 0.5299 - val_loss: 0.6863 - val_accuracy: 0.5380\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6767 - accuracy: 0.5307 - val_loss: 0.6873 - val_accuracy: 0.5381\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6765 - accuracy: 0.5302 - val_loss: 0.6870 - val_accuracy: 0.5383\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 4s 56ms/step - loss: 0.6759 - accuracy: 0.5307 - val_loss: 0.6879 - val_accuracy: 0.5377\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6754 - accuracy: 0.5314 - val_loss: 0.6885 - val_accuracy: 0.5382\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6753 - accuracy: 0.5315 - val_loss: 0.6884 - val_accuracy: 0.5379\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6747 - accuracy: 0.5319 - val_loss: 0.6910 - val_accuracy: 0.5375\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6740 - accuracy: 0.5326 - val_loss: 0.6880 - val_accuracy: 0.5386\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6740 - accuracy: 0.5325 - val_loss: 0.6899 - val_accuracy: 0.5382\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6734 - accuracy: 0.5326 - val_loss: 0.6887 - val_accuracy: 0.5382\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6733 - accuracy: 0.5329 - val_loss: 0.6885 - val_accuracy: 0.5379\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6729 - accuracy: 0.5332 - val_loss: 0.6891 - val_accuracy: 0.5381\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6724 - accuracy: 0.5335 - val_loss: 0.6903 - val_accuracy: 0.5379\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6722 - accuracy: 0.5337 - val_loss: 0.6911 - val_accuracy: 0.5383\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6714 - accuracy: 0.5343 - val_loss: 0.6891 - val_accuracy: 0.5377\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6717 - accuracy: 0.5342 - val_loss: 0.6902 - val_accuracy: 0.5384\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6715 - accuracy: 0.5343 - val_loss: 0.6916 - val_accuracy: 0.5382\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6710 - accuracy: 0.5345 - val_loss: 0.6932 - val_accuracy: 0.5379\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6705 - accuracy: 0.5350 - val_loss: 0.6915 - val_accuracy: 0.5383\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6703 - accuracy: 0.5352 - val_loss: 0.6933 - val_accuracy: 0.5384\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6701 - accuracy: 0.5352 - val_loss: 0.6929 - val_accuracy: 0.5379\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6695 - accuracy: 0.5357 - val_loss: 0.6931 - val_accuracy: 0.5377\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6695 - accuracy: 0.5355 - val_loss: 0.6911 - val_accuracy: 0.5376\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6695 - accuracy: 0.5270 - val_loss: 0.6962 - val_accuracy: 0.5375\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6688 - accuracy: 0.5359 - val_loss: 0.6942 - val_accuracy: 0.5385\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6688 - accuracy: 0.5361 - val_loss: 0.6929 - val_accuracy: 0.5376\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6688 - accuracy: 0.5361 - val_loss: 0.6957 - val_accuracy: 0.5381\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6682 - accuracy: 0.5367 - val_loss: 0.6944 - val_accuracy: 0.5377\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6681 - accuracy: 0.5364 - val_loss: 0.6954 - val_accuracy: 0.5379\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6678 - accuracy: 0.5368 - val_loss: 0.6944 - val_accuracy: 0.5370\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6681 - accuracy: 0.5369 - val_loss: 0.6947 - val_accuracy: 0.5376\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6671 - accuracy: 0.5373 - val_loss: 0.6948 - val_accuracy: 0.5376\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6672 - accuracy: 0.5372 - val_loss: 0.6978 - val_accuracy: 0.5376\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6668 - accuracy: 0.5378 - val_loss: 0.6988 - val_accuracy: 0.5373\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6667 - accuracy: 0.5375 - val_loss: 0.6962 - val_accuracy: 0.5382\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6671 - accuracy: 0.5352 - val_loss: 0.6931 - val_accuracy: 0.5375\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6669 - accuracy: 0.5374 - val_loss: 0.6960 - val_accuracy: 0.5371\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6661 - accuracy: 0.5375 - val_loss: 0.6974 - val_accuracy: 0.5379\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6659 - accuracy: 0.5345 - val_loss: 0.6983 - val_accuracy: 0.5367\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6657 - accuracy: 0.5384 - val_loss: 0.6994 - val_accuracy: 0.5374\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6661 - accuracy: 0.5381 - val_loss: 0.6976 - val_accuracy: 0.5372\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6654 - accuracy: 0.5385 - val_loss: 0.6992 - val_accuracy: 0.5377\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6652 - accuracy: 0.5384 - val_loss: 0.6976 - val_accuracy: 0.5374\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6652 - accuracy: 0.5386 - val_loss: 0.7005 - val_accuracy: 0.5377\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6652 - accuracy: 0.5387 - val_loss: 0.7015 - val_accuracy: 0.5379\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6649 - accuracy: 0.5389 - val_loss: 0.7001 - val_accuracy: 0.5367\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6645 - accuracy: 0.5384 - val_loss: 0.7010 - val_accuracy: 0.5371\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6647 - accuracy: 0.5388 - val_loss: 0.6979 - val_accuracy: 0.5374\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6646 - accuracy: 0.5392 - val_loss: 0.6994 - val_accuracy: 0.5374\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6644 - accuracy: 0.5394 - val_loss: 0.6980 - val_accuracy: 0.5371\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6649 - accuracy: 0.5387 - val_loss: 0.6998 - val_accuracy: 0.5376\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6640 - accuracy: 0.5396 - val_loss: 0.6998 - val_accuracy: 0.5376\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6635 - accuracy: 0.5400 - val_loss: 0.7011 - val_accuracy: 0.5371\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6635 - accuracy: 0.5399 - val_loss: 0.7036 - val_accuracy: 0.5371\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6634 - accuracy: 0.5399 - val_loss: 0.7010 - val_accuracy: 0.5381\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6636 - accuracy: 0.5392 - val_loss: 0.7005 - val_accuracy: 0.5381\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6635 - accuracy: 0.5402 - val_loss: 0.7018 - val_accuracy: 0.5368\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6635 - accuracy: 0.5397 - val_loss: 0.7047 - val_accuracy: 0.5381\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6636 - accuracy: 0.5398 - val_loss: 0.7018 - val_accuracy: 0.5375\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6627 - accuracy: 0.5403 - val_loss: 0.7050 - val_accuracy: 0.5374\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6626 - accuracy: 0.5403 - val_loss: 0.7052 - val_accuracy: 0.5380\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6632 - accuracy: 0.5402 - val_loss: 0.6991 - val_accuracy: 0.5375\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6627 - accuracy: 0.5405 - val_loss: 0.7062 - val_accuracy: 0.5379\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6631 - accuracy: 0.5403 - val_loss: 0.7055 - val_accuracy: 0.5378\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6627 - accuracy: 0.5406 - val_loss: 0.7042 - val_accuracy: 0.5375\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6626 - accuracy: 0.5343 - val_loss: 0.7050 - val_accuracy: 0.5377\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6624 - accuracy: 0.5406 - val_loss: 0.7037 - val_accuracy: 0.5375\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6621 - accuracy: 0.5408 - val_loss: 0.7059 - val_accuracy: 0.5377\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6623 - accuracy: 0.5408 - val_loss: 0.7064 - val_accuracy: 0.5372\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6619 - accuracy: 0.5408 - val_loss: 0.7068 - val_accuracy: 0.5377\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6617 - accuracy: 0.5412 - val_loss: 0.7048 - val_accuracy: 0.5381\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6622 - accuracy: 0.5408 - val_loss: 0.7061 - val_accuracy: 0.5378\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6617 - accuracy: 0.5410 - val_loss: 0.7062 - val_accuracy: 0.5369\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6615 - accuracy: 0.5413 - val_loss: 0.7111 - val_accuracy: 0.5377\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6614 - accuracy: 0.5413 - val_loss: 0.7081 - val_accuracy: 0.5380\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6615 - accuracy: 0.5411 - val_loss: 0.7070 - val_accuracy: 0.5381\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6615 - accuracy: 0.5400 - val_loss: 0.7051 - val_accuracy: 0.5377\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6615 - accuracy: 0.5411 - val_loss: 0.7107 - val_accuracy: 0.5375\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6613 - accuracy: 0.5413 - val_loss: 0.7075 - val_accuracy: 0.5377\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6611 - accuracy: 0.5415 - val_loss: 0.7053 - val_accuracy: 0.5379\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6610 - accuracy: 0.5415 - val_loss: 0.7080 - val_accuracy: 0.5373\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6612 - accuracy: 0.5414 - val_loss: 0.7073 - val_accuracy: 0.5380\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6612 - accuracy: 0.5413 - val_loss: 0.7059 - val_accuracy: 0.5374\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6608 - accuracy: 0.5414 - val_loss: 0.7082 - val_accuracy: 0.5375\n",
            "19/19 [==============================] - 1s 19ms/step - loss: 0.7112 - accuracy: 0.5358\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 6s 64ms/step - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6867 - val_accuracy: 0.5033\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6876 - accuracy: 0.5298 - val_loss: 0.6864 - val_accuracy: 0.5032\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6864 - accuracy: 0.5304 - val_loss: 0.6870 - val_accuracy: 0.5027\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6852 - accuracy: 0.5324 - val_loss: 0.6867 - val_accuracy: 0.5030\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6839 - accuracy: 0.5327 - val_loss: 0.6877 - val_accuracy: 0.5007\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6836 - accuracy: 0.5340 - val_loss: 0.6865 - val_accuracy: 0.5035\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6828 - accuracy: 0.5343 - val_loss: 0.6876 - val_accuracy: 0.5008\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6820 - accuracy: 0.5350 - val_loss: 0.6882 - val_accuracy: 0.4999\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6814 - accuracy: 0.5357 - val_loss: 0.6867 - val_accuracy: 0.5022\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6805 - accuracy: 0.5363 - val_loss: 0.6865 - val_accuracy: 0.5027\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 4s 57ms/step - loss: 0.6798 - accuracy: 0.5364 - val_loss: 0.6872 - val_accuracy: 0.5030\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6794 - accuracy: 0.5369 - val_loss: 0.6870 - val_accuracy: 0.5021\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6784 - accuracy: 0.5379 - val_loss: 0.6873 - val_accuracy: 0.5025\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6779 - accuracy: 0.5379 - val_loss: 0.6877 - val_accuracy: 0.5022\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6775 - accuracy: 0.5384 - val_loss: 0.6873 - val_accuracy: 0.5019\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6770 - accuracy: 0.5388 - val_loss: 0.6877 - val_accuracy: 0.5030\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6765 - accuracy: 0.5390 - val_loss: 0.6877 - val_accuracy: 0.5007\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6757 - accuracy: 0.5397 - val_loss: 0.6874 - val_accuracy: 0.5025\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6757 - accuracy: 0.5397 - val_loss: 0.6876 - val_accuracy: 0.5021\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6751 - accuracy: 0.5404 - val_loss: 0.6878 - val_accuracy: 0.5022\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6746 - accuracy: 0.5409 - val_loss: 0.6887 - val_accuracy: 0.4998\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6748 - accuracy: 0.5406 - val_loss: 0.6892 - val_accuracy: 0.5031\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6740 - accuracy: 0.5412 - val_loss: 0.6884 - val_accuracy: 0.5011\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6734 - accuracy: 0.5413 - val_loss: 0.6897 - val_accuracy: 0.5001\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6738 - accuracy: 0.5417 - val_loss: 0.6894 - val_accuracy: 0.5033\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6724 - accuracy: 0.5424 - val_loss: 0.6890 - val_accuracy: 0.5024\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6721 - accuracy: 0.5424 - val_loss: 0.6906 - val_accuracy: 0.4999\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6716 - accuracy: 0.5428 - val_loss: 0.6889 - val_accuracy: 0.5014\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6719 - accuracy: 0.5425 - val_loss: 0.6906 - val_accuracy: 0.5026\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6717 - accuracy: 0.5427 - val_loss: 0.6890 - val_accuracy: 0.5028\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6710 - accuracy: 0.5434 - val_loss: 0.6902 - val_accuracy: 0.5011\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6711 - accuracy: 0.5432 - val_loss: 0.6901 - val_accuracy: 0.5024\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6705 - accuracy: 0.5438 - val_loss: 0.6892 - val_accuracy: 0.5029\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6699 - accuracy: 0.5441 - val_loss: 0.6908 - val_accuracy: 0.5017\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6704 - accuracy: 0.5441 - val_loss: 0.6896 - val_accuracy: 0.5011\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6699 - accuracy: 0.5440 - val_loss: 0.6901 - val_accuracy: 0.5009\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6694 - accuracy: 0.5444 - val_loss: 0.6913 - val_accuracy: 0.5016\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6691 - accuracy: 0.5444 - val_loss: 0.6921 - val_accuracy: 0.5008\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6690 - accuracy: 0.5448 - val_loss: 0.6926 - val_accuracy: 0.5012\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6689 - accuracy: 0.5447 - val_loss: 0.6930 - val_accuracy: 0.5023\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6683 - accuracy: 0.5453 - val_loss: 0.6934 - val_accuracy: 0.5029\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6681 - accuracy: 0.5457 - val_loss: 0.6940 - val_accuracy: 0.5026\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6676 - accuracy: 0.5459 - val_loss: 0.6939 - val_accuracy: 0.5022\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6674 - accuracy: 0.5458 - val_loss: 0.6934 - val_accuracy: 0.5032\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6671 - accuracy: 0.5462 - val_loss: 0.6931 - val_accuracy: 0.5023\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6670 - accuracy: 0.5462 - val_loss: 0.6948 - val_accuracy: 0.5033\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6668 - accuracy: 0.5464 - val_loss: 0.6950 - val_accuracy: 0.5034\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6667 - accuracy: 0.5466 - val_loss: 0.6944 - val_accuracy: 0.5016\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6663 - accuracy: 0.5467 - val_loss: 0.6946 - val_accuracy: 0.5026\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6664 - accuracy: 0.5466 - val_loss: 0.6935 - val_accuracy: 0.5012\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6657 - accuracy: 0.5472 - val_loss: 0.6951 - val_accuracy: 0.5007\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6655 - accuracy: 0.5471 - val_loss: 0.6955 - val_accuracy: 0.5029\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6656 - accuracy: 0.5472 - val_loss: 0.6961 - val_accuracy: 0.5019\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 4s 58ms/step - loss: 0.6660 - accuracy: 0.5471 - val_loss: 0.6957 - val_accuracy: 0.5031\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6660 - accuracy: 0.5469 - val_loss: 0.6955 - val_accuracy: 0.5022\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6653 - accuracy: 0.5475 - val_loss: 0.6967 - val_accuracy: 0.5028\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6649 - accuracy: 0.5477 - val_loss: 0.6969 - val_accuracy: 0.5022\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 4s 59ms/step - loss: 0.6644 - accuracy: 0.5480 - val_loss: 0.6984 - val_accuracy: 0.5023\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6646 - accuracy: 0.5478 - val_loss: 0.6986 - val_accuracy: 0.5012\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6646 - accuracy: 0.5477 - val_loss: 0.6979 - val_accuracy: 0.5010\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6647 - accuracy: 0.5480 - val_loss: 0.6979 - val_accuracy: 0.5020\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6642 - accuracy: 0.5482 - val_loss: 0.6973 - val_accuracy: 0.5013\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6640 - accuracy: 0.5483 - val_loss: 0.6957 - val_accuracy: 0.5022\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6639 - accuracy: 0.5485 - val_loss: 0.6991 - val_accuracy: 0.5003\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6638 - accuracy: 0.5489 - val_loss: 0.7002 - val_accuracy: 0.5017\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6638 - accuracy: 0.5484 - val_loss: 0.6972 - val_accuracy: 0.5018\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6640 - accuracy: 0.5485 - val_loss: 0.6984 - val_accuracy: 0.5019\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6639 - accuracy: 0.5486 - val_loss: 0.6970 - val_accuracy: 0.4998\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6631 - accuracy: 0.5490 - val_loss: 0.6991 - val_accuracy: 0.5010\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6627 - accuracy: 0.5493 - val_loss: 0.7012 - val_accuracy: 0.5019\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6633 - accuracy: 0.5490 - val_loss: 0.6999 - val_accuracy: 0.5010\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6630 - accuracy: 0.5491 - val_loss: 0.6995 - val_accuracy: 0.5027\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6627 - accuracy: 0.5495 - val_loss: 0.6990 - val_accuracy: 0.5013\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6627 - accuracy: 0.5493 - val_loss: 0.6978 - val_accuracy: 0.5010\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6625 - accuracy: 0.5497 - val_loss: 0.6986 - val_accuracy: 0.5010\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6630 - accuracy: 0.5493 - val_loss: 0.6993 - val_accuracy: 0.5024\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6630 - accuracy: 0.5492 - val_loss: 0.6982 - val_accuracy: 0.5020\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6621 - accuracy: 0.5493 - val_loss: 0.7003 - val_accuracy: 0.5023\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6622 - accuracy: 0.5495 - val_loss: 0.6994 - val_accuracy: 0.5004\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6625 - accuracy: 0.5495 - val_loss: 0.7006 - val_accuracy: 0.5021\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6617 - accuracy: 0.5502 - val_loss: 0.7002 - val_accuracy: 0.5013\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6617 - accuracy: 0.5501 - val_loss: 0.6998 - val_accuracy: 0.5009\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6622 - accuracy: 0.5501 - val_loss: 0.6999 - val_accuracy: 0.5018\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6617 - accuracy: 0.5501 - val_loss: 0.7007 - val_accuracy: 0.5017\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6617 - accuracy: 0.5499 - val_loss: 0.7019 - val_accuracy: 0.5005\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6618 - accuracy: 0.5500 - val_loss: 0.7027 - val_accuracy: 0.5014\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6616 - accuracy: 0.5501 - val_loss: 0.7017 - val_accuracy: 0.5014\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6612 - accuracy: 0.5504 - val_loss: 0.7020 - val_accuracy: 0.5018\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6612 - accuracy: 0.5505 - val_loss: 0.7018 - val_accuracy: 0.5020\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6610 - accuracy: 0.5504 - val_loss: 0.7022 - val_accuracy: 0.5015\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6613 - accuracy: 0.5504 - val_loss: 0.7021 - val_accuracy: 0.5012\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6613 - accuracy: 0.5504 - val_loss: 0.7004 - val_accuracy: 0.5009\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6608 - accuracy: 0.5506 - val_loss: 0.7030 - val_accuracy: 0.5009\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6612 - accuracy: 0.5506 - val_loss: 0.7012 - val_accuracy: 0.5002\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6609 - accuracy: 0.5496 - val_loss: 0.7016 - val_accuracy: 0.4998\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6606 - accuracy: 0.5507 - val_loss: 0.7027 - val_accuracy: 0.5002\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6605 - accuracy: 0.5509 - val_loss: 0.7018 - val_accuracy: 0.5003\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6609 - accuracy: 0.5505 - val_loss: 0.7032 - val_accuracy: 0.5012\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6604 - accuracy: 0.5509 - val_loss: 0.7034 - val_accuracy: 0.5015\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6606 - accuracy: 0.5508 - val_loss: 0.7013 - val_accuracy: 0.5010\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 0.7041 - accuracy: 0.5002\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 8s 90ms/step - loss: 0.6903 - accuracy: 0.5053 - val_loss: 0.6884 - val_accuracy: 0.4946\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6877 - accuracy: 0.5141 - val_loss: 0.6873 - val_accuracy: 0.5344\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6861 - accuracy: 0.5226 - val_loss: 0.6869 - val_accuracy: 0.5346\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6851 - accuracy: 0.5237 - val_loss: 0.6863 - val_accuracy: 0.5344\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6844 - accuracy: 0.5243 - val_loss: 0.6856 - val_accuracy: 0.5351\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6835 - accuracy: 0.5252 - val_loss: 0.6858 - val_accuracy: 0.5349\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6827 - accuracy: 0.5261 - val_loss: 0.6854 - val_accuracy: 0.5355\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6816 - accuracy: 0.5267 - val_loss: 0.6854 - val_accuracy: 0.5355\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6813 - accuracy: 0.5275 - val_loss: 0.6851 - val_accuracy: 0.5354\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6803 - accuracy: 0.5284 - val_loss: 0.6856 - val_accuracy: 0.5353\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6797 - accuracy: 0.5288 - val_loss: 0.6854 - val_accuracy: 0.5355\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6789 - accuracy: 0.5289 - val_loss: 0.6861 - val_accuracy: 0.5354\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6784 - accuracy: 0.5297 - val_loss: 0.6863 - val_accuracy: 0.5352\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6783 - accuracy: 0.5299 - val_loss: 0.6864 - val_accuracy: 0.5338\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6777 - accuracy: 0.5302 - val_loss: 0.6868 - val_accuracy: 0.5340\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6769 - accuracy: 0.5309 - val_loss: 0.6891 - val_accuracy: 0.5347\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6766 - accuracy: 0.5311 - val_loss: 0.6916 - val_accuracy: 0.5348\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6761 - accuracy: 0.5312 - val_loss: 0.6887 - val_accuracy: 0.5348\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6757 - accuracy: 0.5316 - val_loss: 0.6881 - val_accuracy: 0.5340\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6756 - accuracy: 0.5318 - val_loss: 0.6891 - val_accuracy: 0.5349\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6751 - accuracy: 0.5322 - val_loss: 0.6907 - val_accuracy: 0.5352\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6743 - accuracy: 0.5329 - val_loss: 0.6904 - val_accuracy: 0.5339\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6736 - accuracy: 0.5334 - val_loss: 0.6921 - val_accuracy: 0.5349\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6739 - accuracy: 0.5332 - val_loss: 0.6930 - val_accuracy: 0.5354\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6732 - accuracy: 0.5341 - val_loss: 0.6926 - val_accuracy: 0.5349\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6730 - accuracy: 0.5337 - val_loss: 0.6906 - val_accuracy: 0.5325\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6726 - accuracy: 0.5344 - val_loss: 0.6956 - val_accuracy: 0.5343\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6722 - accuracy: 0.5343 - val_loss: 0.6931 - val_accuracy: 0.5346\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6719 - accuracy: 0.5350 - val_loss: 0.6917 - val_accuracy: 0.5331\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6718 - accuracy: 0.5348 - val_loss: 0.6927 - val_accuracy: 0.5344\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6710 - accuracy: 0.5356 - val_loss: 0.6931 - val_accuracy: 0.5344\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6706 - accuracy: 0.5356 - val_loss: 0.6952 - val_accuracy: 0.5347\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6705 - accuracy: 0.5355 - val_loss: 0.6943 - val_accuracy: 0.5347\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6703 - accuracy: 0.5359 - val_loss: 0.6963 - val_accuracy: 0.5355\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6696 - accuracy: 0.5360 - val_loss: 0.6978 - val_accuracy: 0.5352\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6697 - accuracy: 0.5363 - val_loss: 0.6966 - val_accuracy: 0.5343\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6694 - accuracy: 0.5365 - val_loss: 0.6994 - val_accuracy: 0.5354\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6691 - accuracy: 0.5365 - val_loss: 0.6977 - val_accuracy: 0.5347\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6687 - accuracy: 0.5371 - val_loss: 0.6955 - val_accuracy: 0.5340\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6685 - accuracy: 0.5367 - val_loss: 0.6974 - val_accuracy: 0.5343\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6681 - accuracy: 0.5373 - val_loss: 0.6985 - val_accuracy: 0.5349\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6683 - accuracy: 0.5372 - val_loss: 0.6973 - val_accuracy: 0.5348\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6676 - accuracy: 0.5378 - val_loss: 0.6980 - val_accuracy: 0.5347\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6675 - accuracy: 0.5323 - val_loss: 0.7017 - val_accuracy: 0.5354\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6676 - accuracy: 0.5376 - val_loss: 0.6986 - val_accuracy: 0.5347\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6673 - accuracy: 0.5381 - val_loss: 0.6990 - val_accuracy: 0.5345\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6668 - accuracy: 0.5381 - val_loss: 0.6988 - val_accuracy: 0.5346\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6667 - accuracy: 0.5385 - val_loss: 0.7003 - val_accuracy: 0.5340\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6663 - accuracy: 0.5337 - val_loss: 0.7028 - val_accuracy: 0.5350\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6666 - accuracy: 0.5383 - val_loss: 0.7004 - val_accuracy: 0.5346\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6663 - accuracy: 0.5385 - val_loss: 0.7010 - val_accuracy: 0.5346\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6665 - accuracy: 0.5383 - val_loss: 0.7005 - val_accuracy: 0.5349\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6658 - accuracy: 0.5388 - val_loss: 0.6981 - val_accuracy: 0.5339\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6659 - accuracy: 0.5389 - val_loss: 0.7017 - val_accuracy: 0.5351\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6654 - accuracy: 0.5392 - val_loss: 0.7012 - val_accuracy: 0.5350\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6655 - accuracy: 0.5390 - val_loss: 0.7016 - val_accuracy: 0.5348\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6651 - accuracy: 0.5397 - val_loss: 0.7039 - val_accuracy: 0.5352\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6651 - accuracy: 0.5395 - val_loss: 0.7005 - val_accuracy: 0.5347\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6650 - accuracy: 0.5396 - val_loss: 0.7040 - val_accuracy: 0.5350\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6647 - accuracy: 0.5395 - val_loss: 0.7035 - val_accuracy: 0.5341\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6648 - accuracy: 0.5395 - val_loss: 0.7042 - val_accuracy: 0.5350\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6644 - accuracy: 0.5399 - val_loss: 0.7048 - val_accuracy: 0.5350\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6639 - accuracy: 0.5403 - val_loss: 0.7046 - val_accuracy: 0.5352\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6637 - accuracy: 0.5403 - val_loss: 0.7036 - val_accuracy: 0.5345\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6642 - accuracy: 0.5401 - val_loss: 0.7068 - val_accuracy: 0.5346\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6640 - accuracy: 0.5401 - val_loss: 0.7054 - val_accuracy: 0.5348\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6639 - accuracy: 0.5401 - val_loss: 0.7064 - val_accuracy: 0.5352\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 4s 60ms/step - loss: 0.6636 - accuracy: 0.5404 - val_loss: 0.7053 - val_accuracy: 0.5348\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6638 - accuracy: 0.5384 - val_loss: 0.7035 - val_accuracy: 0.5347\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6637 - accuracy: 0.5405 - val_loss: 0.7051 - val_accuracy: 0.5343\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6633 - accuracy: 0.5404 - val_loss: 0.7051 - val_accuracy: 0.5347\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6632 - accuracy: 0.5406 - val_loss: 0.7054 - val_accuracy: 0.5345\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6630 - accuracy: 0.5408 - val_loss: 0.7089 - val_accuracy: 0.5347\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6630 - accuracy: 0.5409 - val_loss: 0.7096 - val_accuracy: 0.5348\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6633 - accuracy: 0.5404 - val_loss: 0.7108 - val_accuracy: 0.5352\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6630 - accuracy: 0.5407 - val_loss: 0.7078 - val_accuracy: 0.5351\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6626 - accuracy: 0.5412 - val_loss: 0.7063 - val_accuracy: 0.5344\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6625 - accuracy: 0.5413 - val_loss: 0.7061 - val_accuracy: 0.5347\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6626 - accuracy: 0.5413 - val_loss: 0.7061 - val_accuracy: 0.5349\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6624 - accuracy: 0.5415 - val_loss: 0.7089 - val_accuracy: 0.5352\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6621 - accuracy: 0.5416 - val_loss: 0.7077 - val_accuracy: 0.5345\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6619 - accuracy: 0.5417 - val_loss: 0.7069 - val_accuracy: 0.5345\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6620 - accuracy: 0.5415 - val_loss: 0.7081 - val_accuracy: 0.5347\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6620 - accuracy: 0.5413 - val_loss: 0.7084 - val_accuracy: 0.5350\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6618 - accuracy: 0.5414 - val_loss: 0.7086 - val_accuracy: 0.5353\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6617 - accuracy: 0.5417 - val_loss: 0.7086 - val_accuracy: 0.5347\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6615 - accuracy: 0.5419 - val_loss: 0.7098 - val_accuracy: 0.5348\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6615 - accuracy: 0.5395 - val_loss: 0.7087 - val_accuracy: 0.5353\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6617 - accuracy: 0.5417 - val_loss: 0.7068 - val_accuracy: 0.5344\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6617 - accuracy: 0.5418 - val_loss: 0.7069 - val_accuracy: 0.5345\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6611 - accuracy: 0.5418 - val_loss: 0.7112 - val_accuracy: 0.5350\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6609 - accuracy: 0.5421 - val_loss: 0.7101 - val_accuracy: 0.5350\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6613 - accuracy: 0.5417 - val_loss: 0.7092 - val_accuracy: 0.5348\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6613 - accuracy: 0.5420 - val_loss: 0.7114 - val_accuracy: 0.5348\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6608 - accuracy: 0.5423 - val_loss: 0.7088 - val_accuracy: 0.5346\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6606 - accuracy: 0.5423 - val_loss: 0.7092 - val_accuracy: 0.5343\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6607 - accuracy: 0.5423 - val_loss: 0.7066 - val_accuracy: 0.5341\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6614 - accuracy: 0.5408 - val_loss: 0.7106 - val_accuracy: 0.5355\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6606 - accuracy: 0.5426 - val_loss: 0.7112 - val_accuracy: 0.5348\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6606 - accuracy: 0.5424 - val_loss: 0.7103 - val_accuracy: 0.5340\n",
            "19/19 [==============================] - 1s 17ms/step - loss: 0.7122 - accuracy: 0.5332\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 6s 71ms/step - loss: 0.6907 - accuracy: 0.5046 - val_loss: 0.6899 - val_accuracy: 0.5098\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6871 - accuracy: 0.5271 - val_loss: 0.6888 - val_accuracy: 0.5099\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6853 - accuracy: 0.5285 - val_loss: 0.6889 - val_accuracy: 0.5105\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6840 - accuracy: 0.5300 - val_loss: 0.6892 - val_accuracy: 0.5095\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6834 - accuracy: 0.5305 - val_loss: 0.6897 - val_accuracy: 0.5105\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 61ms/step - loss: 0.6819 - accuracy: 0.5313 - val_loss: 0.6898 - val_accuracy: 0.5096\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6811 - accuracy: 0.5326 - val_loss: 0.6912 - val_accuracy: 0.5078\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6800 - accuracy: 0.5334 - val_loss: 0.6909 - val_accuracy: 0.5098\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6797 - accuracy: 0.5341 - val_loss: 0.6918 - val_accuracy: 0.5102\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6789 - accuracy: 0.5345 - val_loss: 0.6924 - val_accuracy: 0.5101\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6783 - accuracy: 0.5352 - val_loss: 0.6935 - val_accuracy: 0.5088\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6775 - accuracy: 0.5354 - val_loss: 0.6935 - val_accuracy: 0.5088\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6770 - accuracy: 0.5359 - val_loss: 0.6954 - val_accuracy: 0.5077\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6761 - accuracy: 0.5368 - val_loss: 0.6963 - val_accuracy: 0.5080\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6757 - accuracy: 0.5371 - val_loss: 0.6969 - val_accuracy: 0.5079\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6747 - accuracy: 0.5374 - val_loss: 0.6989 - val_accuracy: 0.5081\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6753 - accuracy: 0.5372 - val_loss: 0.6976 - val_accuracy: 0.5084\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6740 - accuracy: 0.5384 - val_loss: 0.7002 - val_accuracy: 0.5085\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6740 - accuracy: 0.5383 - val_loss: 0.7001 - val_accuracy: 0.5082\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6733 - accuracy: 0.5389 - val_loss: 0.6989 - val_accuracy: 0.5078\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6730 - accuracy: 0.5391 - val_loss: 0.7021 - val_accuracy: 0.5082\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6720 - accuracy: 0.5398 - val_loss: 0.7017 - val_accuracy: 0.5073\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6717 - accuracy: 0.5400 - val_loss: 0.7017 - val_accuracy: 0.5053\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6722 - accuracy: 0.5395 - val_loss: 0.7029 - val_accuracy: 0.5052\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6713 - accuracy: 0.5402 - val_loss: 0.7035 - val_accuracy: 0.5067\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6711 - accuracy: 0.5405 - val_loss: 0.7037 - val_accuracy: 0.5065\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6708 - accuracy: 0.5410 - val_loss: 0.7037 - val_accuracy: 0.5053\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6703 - accuracy: 0.5410 - val_loss: 0.7081 - val_accuracy: 0.5081\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6697 - accuracy: 0.5412 - val_loss: 0.7095 - val_accuracy: 0.5083\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6695 - accuracy: 0.5414 - val_loss: 0.7089 - val_accuracy: 0.5073\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6692 - accuracy: 0.5419 - val_loss: 0.7079 - val_accuracy: 0.5069\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6692 - accuracy: 0.5416 - val_loss: 0.7083 - val_accuracy: 0.5065\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6688 - accuracy: 0.5421 - val_loss: 0.7099 - val_accuracy: 0.5074\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6682 - accuracy: 0.5427 - val_loss: 0.7088 - val_accuracy: 0.5061\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6680 - accuracy: 0.5424 - val_loss: 0.7100 - val_accuracy: 0.5060\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6679 - accuracy: 0.5431 - val_loss: 0.7092 - val_accuracy: 0.5052\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6674 - accuracy: 0.5433 - val_loss: 0.7098 - val_accuracy: 0.5064\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6671 - accuracy: 0.5434 - val_loss: 0.7159 - val_accuracy: 0.5060\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6676 - accuracy: 0.5432 - val_loss: 0.7123 - val_accuracy: 0.5071\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6664 - accuracy: 0.5436 - val_loss: 0.7160 - val_accuracy: 0.5077\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6665 - accuracy: 0.5439 - val_loss: 0.7120 - val_accuracy: 0.5064\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6661 - accuracy: 0.5440 - val_loss: 0.7176 - val_accuracy: 0.5083\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6663 - accuracy: 0.5439 - val_loss: 0.7177 - val_accuracy: 0.5078\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6656 - accuracy: 0.5445 - val_loss: 0.7158 - val_accuracy: 0.5071\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6653 - accuracy: 0.5446 - val_loss: 0.7159 - val_accuracy: 0.5063\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6654 - accuracy: 0.5445 - val_loss: 0.7172 - val_accuracy: 0.5067\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6649 - accuracy: 0.5448 - val_loss: 0.7180 - val_accuracy: 0.5074\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6650 - accuracy: 0.5450 - val_loss: 0.7188 - val_accuracy: 0.5068\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6650 - accuracy: 0.5355 - val_loss: 0.7185 - val_accuracy: 0.5067\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6640 - accuracy: 0.5456 - val_loss: 0.7259 - val_accuracy: 0.5081\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6645 - accuracy: 0.5449 - val_loss: 0.7181 - val_accuracy: 0.5062\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6642 - accuracy: 0.5455 - val_loss: 0.7182 - val_accuracy: 0.5062\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6640 - accuracy: 0.5455 - val_loss: 0.7181 - val_accuracy: 0.5051\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6642 - accuracy: 0.5455 - val_loss: 0.7190 - val_accuracy: 0.5067\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6635 - accuracy: 0.5459 - val_loss: 0.7184 - val_accuracy: 0.5060\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6638 - accuracy: 0.5458 - val_loss: 0.7184 - val_accuracy: 0.5062\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6628 - accuracy: 0.5464 - val_loss: 0.7217 - val_accuracy: 0.5066\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6630 - accuracy: 0.5461 - val_loss: 0.7189 - val_accuracy: 0.5065\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6628 - accuracy: 0.5466 - val_loss: 0.7257 - val_accuracy: 0.5086\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6634 - accuracy: 0.5458 - val_loss: 0.7198 - val_accuracy: 0.5048\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6626 - accuracy: 0.5463 - val_loss: 0.7218 - val_accuracy: 0.5064\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6626 - accuracy: 0.5463 - val_loss: 0.7217 - val_accuracy: 0.5069\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6622 - accuracy: 0.5469 - val_loss: 0.7235 - val_accuracy: 0.5061\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6617 - accuracy: 0.5471 - val_loss: 0.7230 - val_accuracy: 0.5067\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6620 - accuracy: 0.5468 - val_loss: 0.7185 - val_accuracy: 0.5053\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6621 - accuracy: 0.5469 - val_loss: 0.7225 - val_accuracy: 0.5059\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6614 - accuracy: 0.5471 - val_loss: 0.7229 - val_accuracy: 0.5069\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6612 - accuracy: 0.5477 - val_loss: 0.7250 - val_accuracy: 0.5062\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6619 - accuracy: 0.5473 - val_loss: 0.7231 - val_accuracy: 0.5063\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6612 - accuracy: 0.5475 - val_loss: 0.7232 - val_accuracy: 0.5068\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6614 - accuracy: 0.5472 - val_loss: 0.7223 - val_accuracy: 0.5054\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6609 - accuracy: 0.5478 - val_loss: 0.7260 - val_accuracy: 0.5065\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6608 - accuracy: 0.5476 - val_loss: 0.7245 - val_accuracy: 0.5066\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6610 - accuracy: 0.5479 - val_loss: 0.7235 - val_accuracy: 0.5054\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6607 - accuracy: 0.5478 - val_loss: 0.7234 - val_accuracy: 0.5059\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6606 - accuracy: 0.5481 - val_loss: 0.7243 - val_accuracy: 0.5053\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6603 - accuracy: 0.5481 - val_loss: 0.7257 - val_accuracy: 0.5066\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6605 - accuracy: 0.5482 - val_loss: 0.7257 - val_accuracy: 0.5061\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6602 - accuracy: 0.5480 - val_loss: 0.7242 - val_accuracy: 0.5052\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6607 - accuracy: 0.5479 - val_loss: 0.7254 - val_accuracy: 0.5067\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6602 - accuracy: 0.5483 - val_loss: 0.7261 - val_accuracy: 0.5064\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6601 - accuracy: 0.5482 - val_loss: 0.7243 - val_accuracy: 0.5063\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6595 - accuracy: 0.5485 - val_loss: 0.7246 - val_accuracy: 0.5058\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6597 - accuracy: 0.5485 - val_loss: 0.7237 - val_accuracy: 0.5060\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6598 - accuracy: 0.5485 - val_loss: 0.7258 - val_accuracy: 0.5061\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6597 - accuracy: 0.5487 - val_loss: 0.7253 - val_accuracy: 0.5058\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6596 - accuracy: 0.5489 - val_loss: 0.7230 - val_accuracy: 0.5061\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6601 - accuracy: 0.5482 - val_loss: 0.7241 - val_accuracy: 0.5061\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6596 - accuracy: 0.5486 - val_loss: 0.7250 - val_accuracy: 0.5055\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6594 - accuracy: 0.5484 - val_loss: 0.7270 - val_accuracy: 0.5063\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6594 - accuracy: 0.5487 - val_loss: 0.7268 - val_accuracy: 0.5060\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6593 - accuracy: 0.5486 - val_loss: 0.7269 - val_accuracy: 0.5070\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6591 - accuracy: 0.5490 - val_loss: 0.7269 - val_accuracy: 0.5060\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6592 - accuracy: 0.5490 - val_loss: 0.7266 - val_accuracy: 0.5059\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6589 - accuracy: 0.5491 - val_loss: 0.7268 - val_accuracy: 0.5060\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6590 - accuracy: 0.5490 - val_loss: 0.7264 - val_accuracy: 0.5063\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6594 - accuracy: 0.5490 - val_loss: 0.7257 - val_accuracy: 0.5062\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6585 - accuracy: 0.5493 - val_loss: 0.7276 - val_accuracy: 0.5065\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6587 - accuracy: 0.5492 - val_loss: 0.7281 - val_accuracy: 0.5065\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6583 - accuracy: 0.5496 - val_loss: 0.7249 - val_accuracy: 0.5059\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 0.7246 - accuracy: 0.5058\n",
            "Best accuracy for dataset 2: 0.5439110994338989\n",
            "2308\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 83ms/step - loss: 0.6889 - accuracy: 0.5069 - val_loss: 0.6882 - val_accuracy: 0.5351\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6870 - accuracy: 0.5198 - val_loss: 0.6870 - val_accuracy: 0.5410\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6854 - accuracy: 0.5217 - val_loss: 0.6869 - val_accuracy: 0.5408\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6845 - accuracy: 0.5229 - val_loss: 0.6874 - val_accuracy: 0.5416\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6836 - accuracy: 0.5238 - val_loss: 0.6868 - val_accuracy: 0.5420\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6829 - accuracy: 0.5247 - val_loss: 0.6879 - val_accuracy: 0.5410\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6824 - accuracy: 0.5253 - val_loss: 0.6869 - val_accuracy: 0.5418\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6818 - accuracy: 0.5264 - val_loss: 0.6873 - val_accuracy: 0.5418\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6805 - accuracy: 0.5266 - val_loss: 0.6878 - val_accuracy: 0.5411\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 4s 61ms/step - loss: 0.6800 - accuracy: 0.5268 - val_loss: 0.6880 - val_accuracy: 0.5418\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6794 - accuracy: 0.5276 - val_loss: 0.6883 - val_accuracy: 0.5407\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6787 - accuracy: 0.5283 - val_loss: 0.6883 - val_accuracy: 0.5416\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6781 - accuracy: 0.5283 - val_loss: 0.6885 - val_accuracy: 0.5402\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6770 - accuracy: 0.5294 - val_loss: 0.6896 - val_accuracy: 0.5411\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6766 - accuracy: 0.5296 - val_loss: 0.6898 - val_accuracy: 0.5408\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6766 - accuracy: 0.5299 - val_loss: 0.6908 - val_accuracy: 0.5414\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6758 - accuracy: 0.5301 - val_loss: 0.6902 - val_accuracy: 0.5411\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6755 - accuracy: 0.5306 - val_loss: 0.6903 - val_accuracy: 0.5408\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6747 - accuracy: 0.5307 - val_loss: 0.6901 - val_accuracy: 0.5406\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6740 - accuracy: 0.5316 - val_loss: 0.6911 - val_accuracy: 0.5405\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6737 - accuracy: 0.5314 - val_loss: 0.6929 - val_accuracy: 0.5409\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6732 - accuracy: 0.5318 - val_loss: 0.6932 - val_accuracy: 0.5402\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6732 - accuracy: 0.5317 - val_loss: 0.6911 - val_accuracy: 0.5404\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6721 - accuracy: 0.5325 - val_loss: 0.6925 - val_accuracy: 0.5407\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6719 - accuracy: 0.5328 - val_loss: 0.6923 - val_accuracy: 0.5400\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6714 - accuracy: 0.5335 - val_loss: 0.6953 - val_accuracy: 0.5399\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6713 - accuracy: 0.5332 - val_loss: 0.6928 - val_accuracy: 0.5398\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6705 - accuracy: 0.5338 - val_loss: 0.6938 - val_accuracy: 0.5396\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6703 - accuracy: 0.5341 - val_loss: 0.6946 - val_accuracy: 0.5390\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6700 - accuracy: 0.5341 - val_loss: 0.6942 - val_accuracy: 0.5400\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6696 - accuracy: 0.5346 - val_loss: 0.6947 - val_accuracy: 0.5393\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6693 - accuracy: 0.5347 - val_loss: 0.6969 - val_accuracy: 0.5400\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6690 - accuracy: 0.5349 - val_loss: 0.6960 - val_accuracy: 0.5392\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6686 - accuracy: 0.5353 - val_loss: 0.6979 - val_accuracy: 0.5397\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6691 - accuracy: 0.5349 - val_loss: 0.6976 - val_accuracy: 0.5401\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6683 - accuracy: 0.5357 - val_loss: 0.6948 - val_accuracy: 0.5385\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6681 - accuracy: 0.5291 - val_loss: 0.6968 - val_accuracy: 0.5394\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6675 - accuracy: 0.5363 - val_loss: 0.6993 - val_accuracy: 0.5397\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6672 - accuracy: 0.5361 - val_loss: 0.6984 - val_accuracy: 0.5401\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6670 - accuracy: 0.5364 - val_loss: 0.6998 - val_accuracy: 0.5393\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6667 - accuracy: 0.5366 - val_loss: 0.6997 - val_accuracy: 0.5390\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6665 - accuracy: 0.5368 - val_loss: 0.7022 - val_accuracy: 0.5391\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6663 - accuracy: 0.5369 - val_loss: 0.7026 - val_accuracy: 0.5394\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6664 - accuracy: 0.5370 - val_loss: 0.7015 - val_accuracy: 0.5385\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6659 - accuracy: 0.5372 - val_loss: 0.7001 - val_accuracy: 0.5389\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.6657 - accuracy: 0.5374 - val_loss: 0.7009 - val_accuracy: 0.5385\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6650 - accuracy: 0.5378 - val_loss: 0.7015 - val_accuracy: 0.5387\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6652 - accuracy: 0.5376 - val_loss: 0.7017 - val_accuracy: 0.5371\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6653 - accuracy: 0.5376 - val_loss: 0.7025 - val_accuracy: 0.5379\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6647 - accuracy: 0.5381 - val_loss: 0.7023 - val_accuracy: 0.5388\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6643 - accuracy: 0.5381 - val_loss: 0.7040 - val_accuracy: 0.5393\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6642 - accuracy: 0.5387 - val_loss: 0.7099 - val_accuracy: 0.5392\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6642 - accuracy: 0.5384 - val_loss: 0.7053 - val_accuracy: 0.5388\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6635 - accuracy: 0.5389 - val_loss: 0.7097 - val_accuracy: 0.5393\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6637 - accuracy: 0.5374 - val_loss: 0.7052 - val_accuracy: 0.5384\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6635 - accuracy: 0.5386 - val_loss: 0.7054 - val_accuracy: 0.5381\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6634 - accuracy: 0.5388 - val_loss: 0.7057 - val_accuracy: 0.5379\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6630 - accuracy: 0.5392 - val_loss: 0.7073 - val_accuracy: 0.5392\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6629 - accuracy: 0.5391 - val_loss: 0.7069 - val_accuracy: 0.5379\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6633 - accuracy: 0.5390 - val_loss: 0.7063 - val_accuracy: 0.5382\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6628 - accuracy: 0.5393 - val_loss: 0.7102 - val_accuracy: 0.5391\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6624 - accuracy: 0.5395 - val_loss: 0.7080 - val_accuracy: 0.5388\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6624 - accuracy: 0.5395 - val_loss: 0.7071 - val_accuracy: 0.5385\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6623 - accuracy: 0.5397 - val_loss: 0.7075 - val_accuracy: 0.5393\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6622 - accuracy: 0.5386 - val_loss: 0.7086 - val_accuracy: 0.5388\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6619 - accuracy: 0.5398 - val_loss: 0.7078 - val_accuracy: 0.5390\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6616 - accuracy: 0.5399 - val_loss: 0.7076 - val_accuracy: 0.5388\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6616 - accuracy: 0.5402 - val_loss: 0.7080 - val_accuracy: 0.5389\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6612 - accuracy: 0.5384 - val_loss: 0.7125 - val_accuracy: 0.5391\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6612 - accuracy: 0.5402 - val_loss: 0.7105 - val_accuracy: 0.5396\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6613 - accuracy: 0.5405 - val_loss: 0.7098 - val_accuracy: 0.5376\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6610 - accuracy: 0.5406 - val_loss: 0.7103 - val_accuracy: 0.5401\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6610 - accuracy: 0.5406 - val_loss: 0.7105 - val_accuracy: 0.5388\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6613 - accuracy: 0.5401 - val_loss: 0.7111 - val_accuracy: 0.5396\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6612 - accuracy: 0.5402 - val_loss: 0.7088 - val_accuracy: 0.5388\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6607 - accuracy: 0.5408 - val_loss: 0.7121 - val_accuracy: 0.5395\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6605 - accuracy: 0.5409 - val_loss: 0.7112 - val_accuracy: 0.5388\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6605 - accuracy: 0.5407 - val_loss: 0.7121 - val_accuracy: 0.5396\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6603 - accuracy: 0.5409 - val_loss: 0.7134 - val_accuracy: 0.5380\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6602 - accuracy: 0.5408 - val_loss: 0.7117 - val_accuracy: 0.5386\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6601 - accuracy: 0.5411 - val_loss: 0.7128 - val_accuracy: 0.5396\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6601 - accuracy: 0.5409 - val_loss: 0.7122 - val_accuracy: 0.5393\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6599 - accuracy: 0.5407 - val_loss: 0.7130 - val_accuracy: 0.5390\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 4s 62ms/step - loss: 0.6605 - accuracy: 0.5404 - val_loss: 0.7120 - val_accuracy: 0.5388\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6604 - accuracy: 0.5403 - val_loss: 0.7119 - val_accuracy: 0.5376\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6599 - accuracy: 0.5415 - val_loss: 0.7131 - val_accuracy: 0.5384\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6598 - accuracy: 0.5414 - val_loss: 0.7128 - val_accuracy: 0.5378\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6597 - accuracy: 0.5414 - val_loss: 0.7137 - val_accuracy: 0.5386\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6594 - accuracy: 0.5414 - val_loss: 0.7106 - val_accuracy: 0.5383\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6595 - accuracy: 0.5417 - val_loss: 0.7131 - val_accuracy: 0.5380\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6596 - accuracy: 0.5414 - val_loss: 0.7147 - val_accuracy: 0.5396\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6594 - accuracy: 0.5417 - val_loss: 0.7159 - val_accuracy: 0.5392\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 62ms/step - loss: 0.6587 - accuracy: 0.5423 - val_loss: 0.7147 - val_accuracy: 0.5384\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6589 - accuracy: 0.5417 - val_loss: 0.7160 - val_accuracy: 0.5393\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6596 - accuracy: 0.5372 - val_loss: 0.7124 - val_accuracy: 0.5388\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6590 - accuracy: 0.5418 - val_loss: 0.7178 - val_accuracy: 0.5395\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6590 - accuracy: 0.5418 - val_loss: 0.7167 - val_accuracy: 0.5396\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6588 - accuracy: 0.5419 - val_loss: 0.7178 - val_accuracy: 0.5396\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6584 - accuracy: 0.5420 - val_loss: 0.7173 - val_accuracy: 0.5391\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6585 - accuracy: 0.5422 - val_loss: 0.7162 - val_accuracy: 0.5395\n",
            "19/19 [==============================] - 1s 19ms/step - loss: 0.7218 - accuracy: 0.5374\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 8s 87ms/step - loss: 0.6893 - accuracy: 0.5062 - val_loss: 0.6892 - val_accuracy: 0.5303\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6864 - accuracy: 0.5224 - val_loss: 0.6888 - val_accuracy: 0.5318\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6852 - accuracy: 0.5237 - val_loss: 0.6890 - val_accuracy: 0.5324\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6841 - accuracy: 0.5250 - val_loss: 0.6886 - val_accuracy: 0.5329\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6830 - accuracy: 0.5252 - val_loss: 0.6892 - val_accuracy: 0.5331\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6825 - accuracy: 0.5263 - val_loss: 0.6894 - val_accuracy: 0.5340\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6814 - accuracy: 0.5273 - val_loss: 0.6897 - val_accuracy: 0.5344\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6807 - accuracy: 0.5283 - val_loss: 0.6904 - val_accuracy: 0.5340\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6800 - accuracy: 0.5286 - val_loss: 0.6898 - val_accuracy: 0.5342\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6792 - accuracy: 0.5290 - val_loss: 0.6906 - val_accuracy: 0.5342\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6785 - accuracy: 0.5298 - val_loss: 0.6908 - val_accuracy: 0.5344\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6778 - accuracy: 0.5301 - val_loss: 0.6910 - val_accuracy: 0.5335\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6772 - accuracy: 0.5305 - val_loss: 0.6903 - val_accuracy: 0.5333\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6769 - accuracy: 0.5309 - val_loss: 0.6925 - val_accuracy: 0.5337\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6762 - accuracy: 0.5311 - val_loss: 0.6934 - val_accuracy: 0.5345\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6753 - accuracy: 0.5320 - val_loss: 0.6923 - val_accuracy: 0.5333\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6749 - accuracy: 0.5322 - val_loss: 0.6951 - val_accuracy: 0.5340\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6748 - accuracy: 0.5324 - val_loss: 0.6943 - val_accuracy: 0.5337\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6745 - accuracy: 0.5325 - val_loss: 0.6937 - val_accuracy: 0.5336\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6733 - accuracy: 0.5332 - val_loss: 0.6957 - val_accuracy: 0.5335\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6732 - accuracy: 0.5334 - val_loss: 0.6923 - val_accuracy: 0.5324\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6726 - accuracy: 0.5339 - val_loss: 0.6970 - val_accuracy: 0.5341\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6718 - accuracy: 0.5346 - val_loss: 0.6968 - val_accuracy: 0.5334\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6720 - accuracy: 0.5344 - val_loss: 0.6987 - val_accuracy: 0.5334\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6715 - accuracy: 0.5346 - val_loss: 0.6975 - val_accuracy: 0.5336\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6710 - accuracy: 0.5351 - val_loss: 0.6989 - val_accuracy: 0.5338\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6706 - accuracy: 0.5352 - val_loss: 0.6950 - val_accuracy: 0.5331\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6707 - accuracy: 0.5353 - val_loss: 0.6990 - val_accuracy: 0.5335\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6696 - accuracy: 0.5358 - val_loss: 0.6994 - val_accuracy: 0.5334\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6694 - accuracy: 0.5361 - val_loss: 0.7037 - val_accuracy: 0.5335\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6694 - accuracy: 0.5362 - val_loss: 0.7020 - val_accuracy: 0.5334\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6689 - accuracy: 0.5362 - val_loss: 0.7008 - val_accuracy: 0.5332\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6684 - accuracy: 0.5365 - val_loss: 0.7019 - val_accuracy: 0.5333\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6680 - accuracy: 0.5369 - val_loss: 0.7011 - val_accuracy: 0.5334\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6680 - accuracy: 0.5372 - val_loss: 0.7042 - val_accuracy: 0.5330\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6680 - accuracy: 0.5371 - val_loss: 0.7004 - val_accuracy: 0.5324\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6679 - accuracy: 0.5371 - val_loss: 0.6999 - val_accuracy: 0.5324\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6674 - accuracy: 0.5375 - val_loss: 0.7005 - val_accuracy: 0.5324\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6670 - accuracy: 0.5377 - val_loss: 0.7058 - val_accuracy: 0.5335\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6667 - accuracy: 0.5379 - val_loss: 0.7040 - val_accuracy: 0.5325\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6665 - accuracy: 0.5383 - val_loss: 0.7035 - val_accuracy: 0.5324\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6663 - accuracy: 0.5383 - val_loss: 0.7032 - val_accuracy: 0.5326\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6657 - accuracy: 0.5385 - val_loss: 0.7022 - val_accuracy: 0.5326\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6657 - accuracy: 0.5387 - val_loss: 0.7052 - val_accuracy: 0.5327\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6655 - accuracy: 0.5385 - val_loss: 0.7058 - val_accuracy: 0.5331\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6653 - accuracy: 0.5389 - val_loss: 0.7041 - val_accuracy: 0.5327\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6648 - accuracy: 0.5392 - val_loss: 0.7103 - val_accuracy: 0.5334\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6647 - accuracy: 0.5393 - val_loss: 0.7084 - val_accuracy: 0.5332\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6644 - accuracy: 0.5394 - val_loss: 0.7050 - val_accuracy: 0.5330\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6643 - accuracy: 0.5395 - val_loss: 0.7113 - val_accuracy: 0.5330\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6643 - accuracy: 0.5396 - val_loss: 0.7077 - val_accuracy: 0.5325\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6645 - accuracy: 0.5394 - val_loss: 0.7084 - val_accuracy: 0.5329\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6635 - accuracy: 0.5400 - val_loss: 0.7085 - val_accuracy: 0.5326\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6644 - accuracy: 0.5398 - val_loss: 0.7113 - val_accuracy: 0.5331\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6635 - accuracy: 0.5401 - val_loss: 0.7108 - val_accuracy: 0.5330\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6640 - accuracy: 0.5400 - val_loss: 0.7128 - val_accuracy: 0.5333\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6631 - accuracy: 0.5406 - val_loss: 0.7112 - val_accuracy: 0.5330\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6632 - accuracy: 0.5402 - val_loss: 0.7109 - val_accuracy: 0.5334\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6628 - accuracy: 0.5404 - val_loss: 0.7123 - val_accuracy: 0.5329\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6625 - accuracy: 0.5407 - val_loss: 0.7144 - val_accuracy: 0.5333\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6627 - accuracy: 0.5408 - val_loss: 0.7130 - val_accuracy: 0.5327\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6624 - accuracy: 0.5409 - val_loss: 0.7133 - val_accuracy: 0.5330\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6623 - accuracy: 0.5411 - val_loss: 0.7110 - val_accuracy: 0.5325\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6620 - accuracy: 0.5410 - val_loss: 0.7116 - val_accuracy: 0.5325\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6622 - accuracy: 0.5413 - val_loss: 0.7099 - val_accuracy: 0.5326\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6619 - accuracy: 0.5413 - val_loss: 0.7129 - val_accuracy: 0.5330\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6620 - accuracy: 0.5413 - val_loss: 0.7146 - val_accuracy: 0.5331\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6618 - accuracy: 0.5413 - val_loss: 0.7148 - val_accuracy: 0.5330\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6611 - accuracy: 0.5418 - val_loss: 0.7144 - val_accuracy: 0.5327\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6617 - accuracy: 0.5415 - val_loss: 0.7157 - val_accuracy: 0.5328\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6612 - accuracy: 0.5417 - val_loss: 0.7129 - val_accuracy: 0.5330\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6614 - accuracy: 0.5418 - val_loss: 0.7123 - val_accuracy: 0.5325\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6609 - accuracy: 0.5418 - val_loss: 0.7179 - val_accuracy: 0.5330\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6612 - accuracy: 0.5417 - val_loss: 0.7151 - val_accuracy: 0.5328\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6608 - accuracy: 0.5421 - val_loss: 0.7187 - val_accuracy: 0.5331\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6606 - accuracy: 0.5420 - val_loss: 0.7175 - val_accuracy: 0.5327\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6605 - accuracy: 0.5424 - val_loss: 0.7139 - val_accuracy: 0.5322\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6606 - accuracy: 0.5423 - val_loss: 0.7146 - val_accuracy: 0.5325\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6605 - accuracy: 0.5423 - val_loss: 0.7149 - val_accuracy: 0.5322\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6604 - accuracy: 0.5422 - val_loss: 0.7168 - val_accuracy: 0.5325\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6602 - accuracy: 0.5424 - val_loss: 0.7192 - val_accuracy: 0.5326\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6599 - accuracy: 0.5426 - val_loss: 0.7179 - val_accuracy: 0.5328\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6598 - accuracy: 0.5428 - val_loss: 0.7151 - val_accuracy: 0.5319\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6600 - accuracy: 0.5424 - val_loss: 0.7191 - val_accuracy: 0.5328\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6601 - accuracy: 0.5427 - val_loss: 0.7184 - val_accuracy: 0.5329\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6600 - accuracy: 0.5427 - val_loss: 0.7202 - val_accuracy: 0.5329\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6596 - accuracy: 0.5426 - val_loss: 0.7167 - val_accuracy: 0.5326\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6596 - accuracy: 0.5431 - val_loss: 0.7179 - val_accuracy: 0.5327\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6596 - accuracy: 0.5427 - val_loss: 0.7216 - val_accuracy: 0.5331\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6592 - accuracy: 0.5431 - val_loss: 0.7185 - val_accuracy: 0.5327\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6593 - accuracy: 0.5433 - val_loss: 0.7175 - val_accuracy: 0.5327\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6592 - accuracy: 0.5433 - val_loss: 0.7198 - val_accuracy: 0.5327\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6596 - accuracy: 0.5427 - val_loss: 0.7193 - val_accuracy: 0.5323\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6593 - accuracy: 0.5377 - val_loss: 0.7167 - val_accuracy: 0.5328\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6590 - accuracy: 0.5428 - val_loss: 0.7158 - val_accuracy: 0.5324\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6590 - accuracy: 0.5434 - val_loss: 0.7179 - val_accuracy: 0.5324\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6589 - accuracy: 0.5431 - val_loss: 0.7182 - val_accuracy: 0.5322\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6591 - accuracy: 0.5431 - val_loss: 0.7203 - val_accuracy: 0.5331\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6592 - accuracy: 0.5430 - val_loss: 0.7196 - val_accuracy: 0.5326\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6589 - accuracy: 0.5433 - val_loss: 0.7204 - val_accuracy: 0.5327\n",
            "19/19 [==============================] - 1s 21ms/step - loss: 0.7261 - accuracy: 0.5311\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 8s 92ms/step - loss: 0.6907 - accuracy: 0.5175 - val_loss: 0.6896 - val_accuracy: 0.5056\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6873 - accuracy: 0.5281 - val_loss: 0.6868 - val_accuracy: 0.5068\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6857 - accuracy: 0.5303 - val_loss: 0.6878 - val_accuracy: 0.5040\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6847 - accuracy: 0.5317 - val_loss: 0.6890 - val_accuracy: 0.5023\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6839 - accuracy: 0.5324 - val_loss: 0.6870 - val_accuracy: 0.5057\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6832 - accuracy: 0.5333 - val_loss: 0.6877 - val_accuracy: 0.5044\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6826 - accuracy: 0.5336 - val_loss: 0.6870 - val_accuracy: 0.5061\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6819 - accuracy: 0.5344 - val_loss: 0.6884 - val_accuracy: 0.5041\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6814 - accuracy: 0.5351 - val_loss: 0.6880 - val_accuracy: 0.5059\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6801 - accuracy: 0.5359 - val_loss: 0.6892 - val_accuracy: 0.5063\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6800 - accuracy: 0.5359 - val_loss: 0.6893 - val_accuracy: 0.5062\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6789 - accuracy: 0.5368 - val_loss: 0.6913 - val_accuracy: 0.5036\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6790 - accuracy: 0.5369 - val_loss: 0.6913 - val_accuracy: 0.5045\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6781 - accuracy: 0.5376 - val_loss: 0.6915 - val_accuracy: 0.5041\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6771 - accuracy: 0.5383 - val_loss: 0.6920 - val_accuracy: 0.5034\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6767 - accuracy: 0.5386 - val_loss: 0.6933 - val_accuracy: 0.5055\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6769 - accuracy: 0.5384 - val_loss: 0.6943 - val_accuracy: 0.5057\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6759 - accuracy: 0.5395 - val_loss: 0.6966 - val_accuracy: 0.5018\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6759 - accuracy: 0.5391 - val_loss: 0.6940 - val_accuracy: 0.5023\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6747 - accuracy: 0.5403 - val_loss: 0.6953 - val_accuracy: 0.5015\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6746 - accuracy: 0.5401 - val_loss: 0.6958 - val_accuracy: 0.5045\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6742 - accuracy: 0.5405 - val_loss: 0.6958 - val_accuracy: 0.5043\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6733 - accuracy: 0.5412 - val_loss: 0.6983 - val_accuracy: 0.5016\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6731 - accuracy: 0.5414 - val_loss: 0.6988 - val_accuracy: 0.5028\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6727 - accuracy: 0.5410 - val_loss: 0.7001 - val_accuracy: 0.5035\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6720 - accuracy: 0.5419 - val_loss: 0.7004 - val_accuracy: 0.5051\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6720 - accuracy: 0.5420 - val_loss: 0.7000 - val_accuracy: 0.5049\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6716 - accuracy: 0.5422 - val_loss: 0.7014 - val_accuracy: 0.5039\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6712 - accuracy: 0.5424 - val_loss: 0.7028 - val_accuracy: 0.5035\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6706 - accuracy: 0.5431 - val_loss: 0.7021 - val_accuracy: 0.5026\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6705 - accuracy: 0.5431 - val_loss: 0.7026 - val_accuracy: 0.5013\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6703 - accuracy: 0.5430 - val_loss: 0.7018 - val_accuracy: 0.5024\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6695 - accuracy: 0.5436 - val_loss: 0.7041 - val_accuracy: 0.5044\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6698 - accuracy: 0.5435 - val_loss: 0.7047 - val_accuracy: 0.5045\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6690 - accuracy: 0.5441 - val_loss: 0.7047 - val_accuracy: 0.5023\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6687 - accuracy: 0.5444 - val_loss: 0.7066 - val_accuracy: 0.5045\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6686 - accuracy: 0.5446 - val_loss: 0.7066 - val_accuracy: 0.5029\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 63ms/step - loss: 0.6683 - accuracy: 0.5446 - val_loss: 0.7078 - val_accuracy: 0.5049\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6680 - accuracy: 0.5448 - val_loss: 0.7086 - val_accuracy: 0.5051\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6682 - accuracy: 0.5411 - val_loss: 0.7101 - val_accuracy: 0.5044\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6681 - accuracy: 0.5448 - val_loss: 0.7064 - val_accuracy: 0.5032\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6673 - accuracy: 0.5453 - val_loss: 0.7104 - val_accuracy: 0.5052\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6672 - accuracy: 0.5452 - val_loss: 0.7091 - val_accuracy: 0.5021\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6666 - accuracy: 0.5456 - val_loss: 0.7142 - val_accuracy: 0.5050\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6663 - accuracy: 0.5457 - val_loss: 0.7132 - val_accuracy: 0.5047\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6661 - accuracy: 0.5464 - val_loss: 0.7160 - val_accuracy: 0.5037\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6663 - accuracy: 0.5461 - val_loss: 0.7141 - val_accuracy: 0.5031\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6656 - accuracy: 0.5464 - val_loss: 0.7149 - val_accuracy: 0.5030\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6654 - accuracy: 0.5466 - val_loss: 0.7150 - val_accuracy: 0.5019\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6654 - accuracy: 0.5466 - val_loss: 0.7147 - val_accuracy: 0.5035\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6652 - accuracy: 0.5468 - val_loss: 0.7159 - val_accuracy: 0.5020\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6649 - accuracy: 0.5470 - val_loss: 0.7157 - val_accuracy: 0.5008\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6648 - accuracy: 0.5467 - val_loss: 0.7168 - val_accuracy: 0.5048\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6650 - accuracy: 0.5471 - val_loss: 0.7143 - val_accuracy: 0.5018\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6646 - accuracy: 0.5472 - val_loss: 0.7174 - val_accuracy: 0.5046\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6646 - accuracy: 0.5472 - val_loss: 0.7194 - val_accuracy: 0.5038\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6643 - accuracy: 0.5474 - val_loss: 0.7189 - val_accuracy: 0.5043\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6640 - accuracy: 0.5477 - val_loss: 0.7176 - val_accuracy: 0.5036\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6640 - accuracy: 0.5474 - val_loss: 0.7159 - val_accuracy: 0.5029\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6641 - accuracy: 0.5474 - val_loss: 0.7183 - val_accuracy: 0.5029\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6634 - accuracy: 0.5477 - val_loss: 0.7164 - val_accuracy: 0.5033\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6633 - accuracy: 0.5481 - val_loss: 0.7208 - val_accuracy: 0.5034\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6638 - accuracy: 0.5478 - val_loss: 0.7195 - val_accuracy: 0.5032\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6630 - accuracy: 0.5483 - val_loss: 0.7193 - val_accuracy: 0.5025\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6630 - accuracy: 0.5482 - val_loss: 0.7200 - val_accuracy: 0.5033\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6626 - accuracy: 0.5484 - val_loss: 0.7213 - val_accuracy: 0.5032\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6630 - accuracy: 0.5483 - val_loss: 0.7222 - val_accuracy: 0.5042\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6626 - accuracy: 0.5485 - val_loss: 0.7211 - val_accuracy: 0.5031\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6626 - accuracy: 0.5487 - val_loss: 0.7214 - val_accuracy: 0.5039\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6622 - accuracy: 0.5487 - val_loss: 0.7234 - val_accuracy: 0.5035\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6623 - accuracy: 0.5487 - val_loss: 0.7211 - val_accuracy: 0.5009\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6621 - accuracy: 0.5492 - val_loss: 0.7217 - val_accuracy: 0.5027\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6617 - accuracy: 0.5492 - val_loss: 0.7252 - val_accuracy: 0.5040\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6619 - accuracy: 0.5492 - val_loss: 0.7257 - val_accuracy: 0.5026\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6619 - accuracy: 0.5491 - val_loss: 0.7263 - val_accuracy: 0.5023\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6619 - accuracy: 0.5490 - val_loss: 0.7214 - val_accuracy: 0.5019\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6619 - accuracy: 0.5493 - val_loss: 0.7245 - val_accuracy: 0.5040\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6614 - accuracy: 0.5492 - val_loss: 0.7267 - val_accuracy: 0.5018\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6613 - accuracy: 0.5495 - val_loss: 0.7269 - val_accuracy: 0.5037\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6615 - accuracy: 0.5493 - val_loss: 0.7258 - val_accuracy: 0.5009\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6614 - accuracy: 0.5494 - val_loss: 0.7258 - val_accuracy: 0.5037\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6615 - accuracy: 0.5493 - val_loss: 0.7249 - val_accuracy: 0.5027\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6607 - accuracy: 0.5496 - val_loss: 0.7263 - val_accuracy: 0.5031\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6608 - accuracy: 0.5497 - val_loss: 0.7263 - val_accuracy: 0.5014\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6605 - accuracy: 0.5499 - val_loss: 0.7278 - val_accuracy: 0.5033\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6608 - accuracy: 0.5497 - val_loss: 0.7266 - val_accuracy: 0.5033\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6603 - accuracy: 0.5502 - val_loss: 0.7292 - val_accuracy: 0.5043\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6609 - accuracy: 0.5498 - val_loss: 0.7275 - val_accuracy: 0.5040\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6605 - accuracy: 0.5500 - val_loss: 0.7269 - val_accuracy: 0.5032\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6603 - accuracy: 0.5498 - val_loss: 0.7259 - val_accuracy: 0.5026\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6603 - accuracy: 0.5500 - val_loss: 0.7275 - val_accuracy: 0.5022\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6607 - accuracy: 0.5499 - val_loss: 0.7268 - val_accuracy: 0.5030\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6607 - accuracy: 0.5498 - val_loss: 0.7272 - val_accuracy: 0.5027\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6602 - accuracy: 0.5501 - val_loss: 0.7261 - val_accuracy: 0.5033\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6603 - accuracy: 0.5499 - val_loss: 0.7293 - val_accuracy: 0.5032\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6601 - accuracy: 0.5502 - val_loss: 0.7278 - val_accuracy: 0.5034\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6598 - accuracy: 0.5502 - val_loss: 0.7296 - val_accuracy: 0.5031\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6596 - accuracy: 0.5505 - val_loss: 0.7287 - val_accuracy: 0.5026\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6598 - accuracy: 0.5504 - val_loss: 0.7301 - val_accuracy: 0.5041\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6592 - accuracy: 0.5508 - val_loss: 0.7294 - val_accuracy: 0.5032\n",
            "19/19 [==============================] - 1s 20ms/step - loss: 0.7393 - accuracy: 0.4999\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 69ms/step - loss: 0.6905 - accuracy: 0.5061 - val_loss: 0.6872 - val_accuracy: 0.5304\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6880 - accuracy: 0.5203 - val_loss: 0.6846 - val_accuracy: 0.5336\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6865 - accuracy: 0.5223 - val_loss: 0.6836 - val_accuracy: 0.5374\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6854 - accuracy: 0.5235 - val_loss: 0.6834 - val_accuracy: 0.5377\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6847 - accuracy: 0.5246 - val_loss: 0.6829 - val_accuracy: 0.5366\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6841 - accuracy: 0.5248 - val_loss: 0.6830 - val_accuracy: 0.5387\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6832 - accuracy: 0.5263 - val_loss: 0.6825 - val_accuracy: 0.5384\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6823 - accuracy: 0.5269 - val_loss: 0.6825 - val_accuracy: 0.5394\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6817 - accuracy: 0.5278 - val_loss: 0.6830 - val_accuracy: 0.5386\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6811 - accuracy: 0.5278 - val_loss: 0.6828 - val_accuracy: 0.5390\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6801 - accuracy: 0.5286 - val_loss: 0.6839 - val_accuracy: 0.5379\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6796 - accuracy: 0.5291 - val_loss: 0.6831 - val_accuracy: 0.5392\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6791 - accuracy: 0.5293 - val_loss: 0.6835 - val_accuracy: 0.5384\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6781 - accuracy: 0.5306 - val_loss: 0.6839 - val_accuracy: 0.5380\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6778 - accuracy: 0.5306 - val_loss: 0.6840 - val_accuracy: 0.5388\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6776 - accuracy: 0.5306 - val_loss: 0.6841 - val_accuracy: 0.5388\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6767 - accuracy: 0.5316 - val_loss: 0.6844 - val_accuracy: 0.5389\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6759 - accuracy: 0.5317 - val_loss: 0.6851 - val_accuracy: 0.5387\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6755 - accuracy: 0.5321 - val_loss: 0.6846 - val_accuracy: 0.5370\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6753 - accuracy: 0.5326 - val_loss: 0.6844 - val_accuracy: 0.5385\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6742 - accuracy: 0.5332 - val_loss: 0.6851 - val_accuracy: 0.5386\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6743 - accuracy: 0.5329 - val_loss: 0.6850 - val_accuracy: 0.5383\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6739 - accuracy: 0.5331 - val_loss: 0.6860 - val_accuracy: 0.5381\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6734 - accuracy: 0.5339 - val_loss: 0.6858 - val_accuracy: 0.5384\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6727 - accuracy: 0.5339 - val_loss: 0.6860 - val_accuracy: 0.5377\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6725 - accuracy: 0.5343 - val_loss: 0.6869 - val_accuracy: 0.5381\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6719 - accuracy: 0.5346 - val_loss: 0.6886 - val_accuracy: 0.5377\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6715 - accuracy: 0.5350 - val_loss: 0.6886 - val_accuracy: 0.5373\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6714 - accuracy: 0.5349 - val_loss: 0.6879 - val_accuracy: 0.5366\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6709 - accuracy: 0.5353 - val_loss: 0.6883 - val_accuracy: 0.5367\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6709 - accuracy: 0.5349 - val_loss: 0.6888 - val_accuracy: 0.5374\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6701 - accuracy: 0.5355 - val_loss: 0.6890 - val_accuracy: 0.5375\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6702 - accuracy: 0.5358 - val_loss: 0.6910 - val_accuracy: 0.5381\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6697 - accuracy: 0.5361 - val_loss: 0.6900 - val_accuracy: 0.5376\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.6697 - accuracy: 0.5363 - val_loss: 0.6891 - val_accuracy: 0.5372\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6691 - accuracy: 0.5363 - val_loss: 0.6920 - val_accuracy: 0.5374\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6687 - accuracy: 0.5365 - val_loss: 0.6906 - val_accuracy: 0.5371\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6687 - accuracy: 0.5367 - val_loss: 0.6903 - val_accuracy: 0.5376\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6688 - accuracy: 0.5374 - val_loss: 0.6918 - val_accuracy: 0.5367\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6680 - accuracy: 0.5375 - val_loss: 0.6919 - val_accuracy: 0.5371\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6680 - accuracy: 0.5375 - val_loss: 0.6913 - val_accuracy: 0.5366\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6674 - accuracy: 0.5376 - val_loss: 0.6908 - val_accuracy: 0.5369\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6675 - accuracy: 0.5377 - val_loss: 0.6921 - val_accuracy: 0.5367\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6670 - accuracy: 0.5379 - val_loss: 0.6935 - val_accuracy: 0.5365\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6674 - accuracy: 0.5377 - val_loss: 0.6936 - val_accuracy: 0.5370\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6668 - accuracy: 0.5384 - val_loss: 0.6932 - val_accuracy: 0.5369\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6662 - accuracy: 0.5386 - val_loss: 0.6925 - val_accuracy: 0.5366\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6659 - accuracy: 0.5387 - val_loss: 0.6942 - val_accuracy: 0.5369\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6657 - accuracy: 0.5390 - val_loss: 0.6941 - val_accuracy: 0.5369\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6657 - accuracy: 0.5391 - val_loss: 0.6957 - val_accuracy: 0.5365\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6657 - accuracy: 0.5389 - val_loss: 0.6961 - val_accuracy: 0.5366\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6653 - accuracy: 0.5392 - val_loss: 0.6950 - val_accuracy: 0.5369\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6650 - accuracy: 0.5393 - val_loss: 0.6959 - val_accuracy: 0.5373\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6646 - accuracy: 0.5397 - val_loss: 0.6955 - val_accuracy: 0.5366\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6647 - accuracy: 0.5393 - val_loss: 0.6957 - val_accuracy: 0.5369\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6645 - accuracy: 0.5398 - val_loss: 0.6971 - val_accuracy: 0.5368\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6643 - accuracy: 0.5397 - val_loss: 0.6965 - val_accuracy: 0.5373\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6644 - accuracy: 0.5397 - val_loss: 0.6979 - val_accuracy: 0.5369\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6641 - accuracy: 0.5401 - val_loss: 0.6981 - val_accuracy: 0.5371\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6636 - accuracy: 0.5404 - val_loss: 0.6965 - val_accuracy: 0.5367\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6642 - accuracy: 0.5400 - val_loss: 0.6964 - val_accuracy: 0.5371\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6636 - accuracy: 0.5403 - val_loss: 0.6979 - val_accuracy: 0.5369\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6635 - accuracy: 0.5404 - val_loss: 0.6984 - val_accuracy: 0.5365\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6631 - accuracy: 0.5405 - val_loss: 0.6993 - val_accuracy: 0.5368\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6634 - accuracy: 0.5405 - val_loss: 0.6974 - val_accuracy: 0.5370\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6632 - accuracy: 0.5405 - val_loss: 0.6990 - val_accuracy: 0.5364\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6629 - accuracy: 0.5407 - val_loss: 0.6981 - val_accuracy: 0.5369\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6627 - accuracy: 0.5406 - val_loss: 0.6996 - val_accuracy: 0.5362\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6628 - accuracy: 0.5410 - val_loss: 0.6987 - val_accuracy: 0.5365\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6623 - accuracy: 0.5411 - val_loss: 0.6998 - val_accuracy: 0.5371\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6625 - accuracy: 0.5410 - val_loss: 0.6998 - val_accuracy: 0.5365\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6625 - accuracy: 0.5412 - val_loss: 0.6982 - val_accuracy: 0.5369\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6621 - accuracy: 0.5415 - val_loss: 0.6985 - val_accuracy: 0.5364\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6623 - accuracy: 0.5412 - val_loss: 0.6970 - val_accuracy: 0.5373\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6621 - accuracy: 0.5411 - val_loss: 0.6987 - val_accuracy: 0.5368\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6621 - accuracy: 0.5416 - val_loss: 0.6983 - val_accuracy: 0.5368\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6618 - accuracy: 0.5415 - val_loss: 0.7003 - val_accuracy: 0.5369\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6621 - accuracy: 0.5414 - val_loss: 0.6994 - val_accuracy: 0.5370\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6616 - accuracy: 0.5411 - val_loss: 0.6991 - val_accuracy: 0.5367\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6614 - accuracy: 0.5417 - val_loss: 0.7011 - val_accuracy: 0.5368\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6612 - accuracy: 0.5419 - val_loss: 0.7017 - val_accuracy: 0.5370\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6613 - accuracy: 0.5421 - val_loss: 0.7022 - val_accuracy: 0.5366\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6616 - accuracy: 0.5417 - val_loss: 0.7011 - val_accuracy: 0.5368\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6613 - accuracy: 0.5420 - val_loss: 0.7003 - val_accuracy: 0.5366\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6609 - accuracy: 0.5424 - val_loss: 0.7017 - val_accuracy: 0.5365\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6608 - accuracy: 0.5422 - val_loss: 0.7031 - val_accuracy: 0.5367\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6607 - accuracy: 0.5423 - val_loss: 0.7013 - val_accuracy: 0.5367\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6604 - accuracy: 0.5426 - val_loss: 0.7030 - val_accuracy: 0.5362\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6609 - accuracy: 0.5423 - val_loss: 0.7011 - val_accuracy: 0.5370\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6604 - accuracy: 0.5425 - val_loss: 0.7034 - val_accuracy: 0.5370\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6609 - accuracy: 0.5424 - val_loss: 0.7011 - val_accuracy: 0.5369\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6605 - accuracy: 0.5417 - val_loss: 0.7024 - val_accuracy: 0.5362\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6608 - accuracy: 0.5421 - val_loss: 0.7021 - val_accuracy: 0.5370\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6605 - accuracy: 0.5425 - val_loss: 0.7028 - val_accuracy: 0.5371\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6599 - accuracy: 0.5426 - val_loss: 0.7026 - val_accuracy: 0.5369\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6599 - accuracy: 0.5427 - val_loss: 0.7059 - val_accuracy: 0.5372\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6602 - accuracy: 0.5427 - val_loss: 0.7065 - val_accuracy: 0.5366\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6601 - accuracy: 0.5427 - val_loss: 0.7049 - val_accuracy: 0.5371\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6597 - accuracy: 0.5430 - val_loss: 0.7063 - val_accuracy: 0.5371\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6601 - accuracy: 0.5428 - val_loss: 0.7022 - val_accuracy: 0.5368\n",
            "19/19 [==============================] - 1s 23ms/step - loss: 0.7061 - accuracy: 0.5357\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 8s 89ms/step - loss: 0.6901 - accuracy: 0.5178 - val_loss: 0.6874 - val_accuracy: 0.5116\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6869 - accuracy: 0.5269 - val_loss: 0.6871 - val_accuracy: 0.5121\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6856 - accuracy: 0.5292 - val_loss: 0.6865 - val_accuracy: 0.5127\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6848 - accuracy: 0.5297 - val_loss: 0.6864 - val_accuracy: 0.5127\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6833 - accuracy: 0.5316 - val_loss: 0.6876 - val_accuracy: 0.5119\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6833 - accuracy: 0.5314 - val_loss: 0.6864 - val_accuracy: 0.5131\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6820 - accuracy: 0.5329 - val_loss: 0.6869 - val_accuracy: 0.5132\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6811 - accuracy: 0.5336 - val_loss: 0.6875 - val_accuracy: 0.5125\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6804 - accuracy: 0.5337 - val_loss: 0.6870 - val_accuracy: 0.5135\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6797 - accuracy: 0.5345 - val_loss: 0.6876 - val_accuracy: 0.5133\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6791 - accuracy: 0.5347 - val_loss: 0.6879 - val_accuracy: 0.5137\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6785 - accuracy: 0.5354 - val_loss: 0.6888 - val_accuracy: 0.5133\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6777 - accuracy: 0.5358 - val_loss: 0.6884 - val_accuracy: 0.5132\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6769 - accuracy: 0.5363 - val_loss: 0.6896 - val_accuracy: 0.5141\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6766 - accuracy: 0.5365 - val_loss: 0.6895 - val_accuracy: 0.5107\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6762 - accuracy: 0.5370 - val_loss: 0.6901 - val_accuracy: 0.5135\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6756 - accuracy: 0.5374 - val_loss: 0.6889 - val_accuracy: 0.5129\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6751 - accuracy: 0.5377 - val_loss: 0.6896 - val_accuracy: 0.5131\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6741 - accuracy: 0.5383 - val_loss: 0.6905 - val_accuracy: 0.5127\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6742 - accuracy: 0.5379 - val_loss: 0.6903 - val_accuracy: 0.5097\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6744 - accuracy: 0.5379 - val_loss: 0.6907 - val_accuracy: 0.5124\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6736 - accuracy: 0.5386 - val_loss: 0.6911 - val_accuracy: 0.5132\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6726 - accuracy: 0.5394 - val_loss: 0.6910 - val_accuracy: 0.5118\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6725 - accuracy: 0.5393 - val_loss: 0.6930 - val_accuracy: 0.5122\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6721 - accuracy: 0.5397 - val_loss: 0.6913 - val_accuracy: 0.5123\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6722 - accuracy: 0.5392 - val_loss: 0.6923 - val_accuracy: 0.5127\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6711 - accuracy: 0.5402 - val_loss: 0.6919 - val_accuracy: 0.5131\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6711 - accuracy: 0.5404 - val_loss: 0.6928 - val_accuracy: 0.5118\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6706 - accuracy: 0.5406 - val_loss: 0.6935 - val_accuracy: 0.5123\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6699 - accuracy: 0.5412 - val_loss: 0.6936 - val_accuracy: 0.5134\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6701 - accuracy: 0.5409 - val_loss: 0.6932 - val_accuracy: 0.5119\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6695 - accuracy: 0.5412 - val_loss: 0.6954 - val_accuracy: 0.5142\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6698 - accuracy: 0.5410 - val_loss: 0.6935 - val_accuracy: 0.5123\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6692 - accuracy: 0.5415 - val_loss: 0.6946 - val_accuracy: 0.5128\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6688 - accuracy: 0.5420 - val_loss: 0.6954 - val_accuracy: 0.5120\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6683 - accuracy: 0.5420 - val_loss: 0.6962 - val_accuracy: 0.5122\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6680 - accuracy: 0.5421 - val_loss: 0.6957 - val_accuracy: 0.5116\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6680 - accuracy: 0.5421 - val_loss: 0.6978 - val_accuracy: 0.5130\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6674 - accuracy: 0.5426 - val_loss: 0.6974 - val_accuracy: 0.5125\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6673 - accuracy: 0.5427 - val_loss: 0.6986 - val_accuracy: 0.5122\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6669 - accuracy: 0.5431 - val_loss: 0.6987 - val_accuracy: 0.5120\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6670 - accuracy: 0.5428 - val_loss: 0.6970 - val_accuracy: 0.5124\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6667 - accuracy: 0.5430 - val_loss: 0.6981 - val_accuracy: 0.5122\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6662 - accuracy: 0.5435 - val_loss: 0.6972 - val_accuracy: 0.5112\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6665 - accuracy: 0.5435 - val_loss: 0.6998 - val_accuracy: 0.5129\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6663 - accuracy: 0.5435 - val_loss: 0.6990 - val_accuracy: 0.5126\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6654 - accuracy: 0.5439 - val_loss: 0.6998 - val_accuracy: 0.5131\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6658 - accuracy: 0.5438 - val_loss: 0.6991 - val_accuracy: 0.5127\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6656 - accuracy: 0.5443 - val_loss: 0.7008 - val_accuracy: 0.5106\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6653 - accuracy: 0.5443 - val_loss: 0.6997 - val_accuracy: 0.5120\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6646 - accuracy: 0.5445 - val_loss: 0.6984 - val_accuracy: 0.5133\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6649 - accuracy: 0.5447 - val_loss: 0.7045 - val_accuracy: 0.5140\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6647 - accuracy: 0.5443 - val_loss: 0.6997 - val_accuracy: 0.5121\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6643 - accuracy: 0.5444 - val_loss: 0.6997 - val_accuracy: 0.5127\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6640 - accuracy: 0.5451 - val_loss: 0.7014 - val_accuracy: 0.5115\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6645 - accuracy: 0.5449 - val_loss: 0.7013 - val_accuracy: 0.5126\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6640 - accuracy: 0.5446 - val_loss: 0.7003 - val_accuracy: 0.5124\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6637 - accuracy: 0.5451 - val_loss: 0.7017 - val_accuracy: 0.5122\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6636 - accuracy: 0.5454 - val_loss: 0.7032 - val_accuracy: 0.5130\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6634 - accuracy: 0.5455 - val_loss: 0.7023 - val_accuracy: 0.5138\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6634 - accuracy: 0.5456 - val_loss: 0.7031 - val_accuracy: 0.5135\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6631 - accuracy: 0.5455 - val_loss: 0.7026 - val_accuracy: 0.5124\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6632 - accuracy: 0.5459 - val_loss: 0.7022 - val_accuracy: 0.5123\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6629 - accuracy: 0.5457 - val_loss: 0.7030 - val_accuracy: 0.5124\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6628 - accuracy: 0.5459 - val_loss: 0.7034 - val_accuracy: 0.5136\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6626 - accuracy: 0.5459 - val_loss: 0.7034 - val_accuracy: 0.5117\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6623 - accuracy: 0.5459 - val_loss: 0.7031 - val_accuracy: 0.5131\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6627 - accuracy: 0.5390 - val_loss: 0.7020 - val_accuracy: 0.5122\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6624 - accuracy: 0.5440 - val_loss: 0.7033 - val_accuracy: 0.5126\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6623 - accuracy: 0.5467 - val_loss: 0.7048 - val_accuracy: 0.5136\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6623 - accuracy: 0.5462 - val_loss: 0.7038 - val_accuracy: 0.5121\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6615 - accuracy: 0.5468 - val_loss: 0.7053 - val_accuracy: 0.5138\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6618 - accuracy: 0.5464 - val_loss: 0.7028 - val_accuracy: 0.5130\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6619 - accuracy: 0.5466 - val_loss: 0.7053 - val_accuracy: 0.5133\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6613 - accuracy: 0.5469 - val_loss: 0.7058 - val_accuracy: 0.5127\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6619 - accuracy: 0.5465 - val_loss: 0.7025 - val_accuracy: 0.5124\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6615 - accuracy: 0.5467 - val_loss: 0.7056 - val_accuracy: 0.5138\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6611 - accuracy: 0.5470 - val_loss: 0.7039 - val_accuracy: 0.5123\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6615 - accuracy: 0.5467 - val_loss: 0.7052 - val_accuracy: 0.5133\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6609 - accuracy: 0.5473 - val_loss: 0.7059 - val_accuracy: 0.5139\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6609 - accuracy: 0.5472 - val_loss: 0.7069 - val_accuracy: 0.5141\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6603 - accuracy: 0.5475 - val_loss: 0.7079 - val_accuracy: 0.5141\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6606 - accuracy: 0.5473 - val_loss: 0.7066 - val_accuracy: 0.5139\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6603 - accuracy: 0.5477 - val_loss: 0.7052 - val_accuracy: 0.5131\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6601 - accuracy: 0.5475 - val_loss: 0.7083 - val_accuracy: 0.5135\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6602 - accuracy: 0.5476 - val_loss: 0.7060 - val_accuracy: 0.5128\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6607 - accuracy: 0.5472 - val_loss: 0.7056 - val_accuracy: 0.5137\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6601 - accuracy: 0.5477 - val_loss: 0.7098 - val_accuracy: 0.5139\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6599 - accuracy: 0.5477 - val_loss: 0.7077 - val_accuracy: 0.5139\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6602 - accuracy: 0.5476 - val_loss: 0.7073 - val_accuracy: 0.5133\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6607 - accuracy: 0.5399 - val_loss: 0.7064 - val_accuracy: 0.5133\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6597 - accuracy: 0.5480 - val_loss: 0.7091 - val_accuracy: 0.5141\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6597 - accuracy: 0.5479 - val_loss: 0.7065 - val_accuracy: 0.5120\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6602 - accuracy: 0.5476 - val_loss: 0.7081 - val_accuracy: 0.5138\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6596 - accuracy: 0.5479 - val_loss: 0.7094 - val_accuracy: 0.5132\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6595 - accuracy: 0.5479 - val_loss: 0.7076 - val_accuracy: 0.5139\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6595 - accuracy: 0.5481 - val_loss: 0.7120 - val_accuracy: 0.5144\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6594 - accuracy: 0.5481 - val_loss: 0.7087 - val_accuracy: 0.5133\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6590 - accuracy: 0.5484 - val_loss: 0.7088 - val_accuracy: 0.5141\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6596 - accuracy: 0.5447 - val_loss: 0.7080 - val_accuracy: 0.5134\n",
            "19/19 [==============================] - 1s 18ms/step - loss: 0.7087 - accuracy: 0.5129\n",
            "Best accuracy for dataset 3: 0.5373842716217041\n",
            "2308\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 77ms/step - loss: 0.6898 - accuracy: 0.5078 - val_loss: 0.6872 - val_accuracy: 0.5409\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6873 - accuracy: 0.5193 - val_loss: 0.6854 - val_accuracy: 0.5439\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6861 - accuracy: 0.5205 - val_loss: 0.6850 - val_accuracy: 0.5456\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6854 - accuracy: 0.5219 - val_loss: 0.6842 - val_accuracy: 0.5458\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6843 - accuracy: 0.5225 - val_loss: 0.6840 - val_accuracy: 0.5447\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6834 - accuracy: 0.5237 - val_loss: 0.6841 - val_accuracy: 0.5445\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6833 - accuracy: 0.5239 - val_loss: 0.6842 - val_accuracy: 0.5475\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6823 - accuracy: 0.5246 - val_loss: 0.6838 - val_accuracy: 0.5473\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 64ms/step - loss: 0.6816 - accuracy: 0.5251 - val_loss: 0.6841 - val_accuracy: 0.5471\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6804 - accuracy: 0.5260 - val_loss: 0.6837 - val_accuracy: 0.5471\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6806 - accuracy: 0.5262 - val_loss: 0.6843 - val_accuracy: 0.5469\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6791 - accuracy: 0.5269 - val_loss: 0.6854 - val_accuracy: 0.5466\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6787 - accuracy: 0.5275 - val_loss: 0.6851 - val_accuracy: 0.5469\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6778 - accuracy: 0.5277 - val_loss: 0.6853 - val_accuracy: 0.5468\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6774 - accuracy: 0.5280 - val_loss: 0.6856 - val_accuracy: 0.5466\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6767 - accuracy: 0.5287 - val_loss: 0.6858 - val_accuracy: 0.5470\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6762 - accuracy: 0.5294 - val_loss: 0.6872 - val_accuracy: 0.5469\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6754 - accuracy: 0.5296 - val_loss: 0.6869 - val_accuracy: 0.5458\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6751 - accuracy: 0.5297 - val_loss: 0.6871 - val_accuracy: 0.5468\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6744 - accuracy: 0.5304 - val_loss: 0.6896 - val_accuracy: 0.5468\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6739 - accuracy: 0.5309 - val_loss: 0.6896 - val_accuracy: 0.5460\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6737 - accuracy: 0.5310 - val_loss: 0.6882 - val_accuracy: 0.5470\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6732 - accuracy: 0.5312 - val_loss: 0.6908 - val_accuracy: 0.5472\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6728 - accuracy: 0.5317 - val_loss: 0.6896 - val_accuracy: 0.5458\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6723 - accuracy: 0.5318 - val_loss: 0.6916 - val_accuracy: 0.5463\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6718 - accuracy: 0.5317 - val_loss: 0.6920 - val_accuracy: 0.5464\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6716 - accuracy: 0.5322 - val_loss: 0.6907 - val_accuracy: 0.5458\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6713 - accuracy: 0.5325 - val_loss: 0.6911 - val_accuracy: 0.5468\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6707 - accuracy: 0.5327 - val_loss: 0.6913 - val_accuracy: 0.5461\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 5s 65ms/step - loss: 0.6709 - accuracy: 0.5329 - val_loss: 0.6918 - val_accuracy: 0.5455\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6704 - accuracy: 0.5330 - val_loss: 0.6934 - val_accuracy: 0.5468\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6698 - accuracy: 0.5335 - val_loss: 0.6957 - val_accuracy: 0.5458\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6695 - accuracy: 0.5338 - val_loss: 0.6930 - val_accuracy: 0.5462\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6691 - accuracy: 0.5338 - val_loss: 0.6955 - val_accuracy: 0.5464\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6689 - accuracy: 0.5342 - val_loss: 0.6948 - val_accuracy: 0.5458\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6692 - accuracy: 0.5338 - val_loss: 0.6933 - val_accuracy: 0.5462\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6684 - accuracy: 0.5344 - val_loss: 0.6951 - val_accuracy: 0.5457\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6679 - accuracy: 0.5348 - val_loss: 0.6950 - val_accuracy: 0.5461\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6678 - accuracy: 0.5349 - val_loss: 0.6946 - val_accuracy: 0.5460\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6679 - accuracy: 0.5350 - val_loss: 0.6953 - val_accuracy: 0.5465\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6676 - accuracy: 0.5348 - val_loss: 0.6959 - val_accuracy: 0.5461\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6673 - accuracy: 0.5354 - val_loss: 0.6958 - val_accuracy: 0.5457\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6666 - accuracy: 0.5359 - val_loss: 0.6963 - val_accuracy: 0.5457\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6670 - accuracy: 0.5351 - val_loss: 0.6985 - val_accuracy: 0.5467\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6666 - accuracy: 0.5362 - val_loss: 0.6974 - val_accuracy: 0.5453\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6662 - accuracy: 0.5328 - val_loss: 0.6993 - val_accuracy: 0.5454\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6659 - accuracy: 0.5361 - val_loss: 0.6991 - val_accuracy: 0.5457\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6657 - accuracy: 0.5362 - val_loss: 0.6992 - val_accuracy: 0.5457\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6657 - accuracy: 0.5367 - val_loss: 0.7037 - val_accuracy: 0.5451\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6657 - accuracy: 0.5363 - val_loss: 0.6991 - val_accuracy: 0.5456\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6651 - accuracy: 0.5369 - val_loss: 0.6986 - val_accuracy: 0.5452\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6650 - accuracy: 0.5369 - val_loss: 0.7013 - val_accuracy: 0.5457\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6650 - accuracy: 0.5370 - val_loss: 0.7008 - val_accuracy: 0.5459\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6647 - accuracy: 0.5374 - val_loss: 0.7028 - val_accuracy: 0.5456\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6643 - accuracy: 0.5374 - val_loss: 0.7000 - val_accuracy: 0.5455\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6643 - accuracy: 0.5375 - val_loss: 0.7011 - val_accuracy: 0.5460\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6640 - accuracy: 0.5375 - val_loss: 0.7029 - val_accuracy: 0.5458\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6640 - accuracy: 0.5375 - val_loss: 0.7012 - val_accuracy: 0.5452\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 7s 91ms/step - loss: 0.6634 - accuracy: 0.5380 - val_loss: 0.7045 - val_accuracy: 0.5452\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6636 - accuracy: 0.5379 - val_loss: 0.7030 - val_accuracy: 0.5449\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6633 - accuracy: 0.5381 - val_loss: 0.7028 - val_accuracy: 0.5455\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6632 - accuracy: 0.5379 - val_loss: 0.7023 - val_accuracy: 0.5450\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6630 - accuracy: 0.5384 - val_loss: 0.7040 - val_accuracy: 0.5454\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6631 - accuracy: 0.5381 - val_loss: 0.7051 - val_accuracy: 0.5458\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6630 - accuracy: 0.5381 - val_loss: 0.7051 - val_accuracy: 0.5454\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6625 - accuracy: 0.5385 - val_loss: 0.7049 - val_accuracy: 0.5457\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6631 - accuracy: 0.5384 - val_loss: 0.7059 - val_accuracy: 0.5456\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6648 - accuracy: 0.5385 - val_loss: 0.7062 - val_accuracy: 0.5456\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6624 - accuracy: 0.5388 - val_loss: 0.7036 - val_accuracy: 0.5450\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6626 - accuracy: 0.5389 - val_loss: 0.7055 - val_accuracy: 0.5458\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6625 - accuracy: 0.5386 - val_loss: 0.7063 - val_accuracy: 0.5452\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6624 - accuracy: 0.5387 - val_loss: 0.7090 - val_accuracy: 0.5454\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6626 - accuracy: 0.5352 - val_loss: 0.7077 - val_accuracy: 0.5456\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6621 - accuracy: 0.5387 - val_loss: 0.7066 - val_accuracy: 0.5450\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6621 - accuracy: 0.5389 - val_loss: 0.7072 - val_accuracy: 0.5457\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6618 - accuracy: 0.5394 - val_loss: 0.7092 - val_accuracy: 0.5455\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6617 - accuracy: 0.5392 - val_loss: 0.7093 - val_accuracy: 0.5456\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6614 - accuracy: 0.5396 - val_loss: 0.7077 - val_accuracy: 0.5459\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6617 - accuracy: 0.5392 - val_loss: 0.7089 - val_accuracy: 0.5455\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6617 - accuracy: 0.5391 - val_loss: 0.7086 - val_accuracy: 0.5457\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6613 - accuracy: 0.5395 - val_loss: 0.7100 - val_accuracy: 0.5451\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6614 - accuracy: 0.5394 - val_loss: 0.7082 - val_accuracy: 0.5455\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6610 - accuracy: 0.5397 - val_loss: 0.7081 - val_accuracy: 0.5458\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6607 - accuracy: 0.5399 - val_loss: 0.7101 - val_accuracy: 0.5455\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6609 - accuracy: 0.5397 - val_loss: 0.7099 - val_accuracy: 0.5459\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6609 - accuracy: 0.5398 - val_loss: 0.7106 - val_accuracy: 0.5457\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6605 - accuracy: 0.5401 - val_loss: 0.7076 - val_accuracy: 0.5446\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6608 - accuracy: 0.5397 - val_loss: 0.7076 - val_accuracy: 0.5447\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6607 - accuracy: 0.5401 - val_loss: 0.7113 - val_accuracy: 0.5455\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6602 - accuracy: 0.5401 - val_loss: 0.7101 - val_accuracy: 0.5456\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6599 - accuracy: 0.5405 - val_loss: 0.7110 - val_accuracy: 0.5455\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6604 - accuracy: 0.5378 - val_loss: 0.7129 - val_accuracy: 0.5457\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6601 - accuracy: 0.5404 - val_loss: 0.7122 - val_accuracy: 0.5455\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6600 - accuracy: 0.5406 - val_loss: 0.7131 - val_accuracy: 0.5453\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6601 - accuracy: 0.5403 - val_loss: 0.7097 - val_accuracy: 0.5455\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6601 - accuracy: 0.5403 - val_loss: 0.7085 - val_accuracy: 0.5452\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6604 - accuracy: 0.5404 - val_loss: 0.7091 - val_accuracy: 0.5457\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6599 - accuracy: 0.5406 - val_loss: 0.7122 - val_accuracy: 0.5454\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.6594 - accuracy: 0.5410 - val_loss: 0.7088 - val_accuracy: 0.5449\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6594 - accuracy: 0.5405 - val_loss: 0.7115 - val_accuracy: 0.5457\n",
            "19/19 [==============================] - 1s 23ms/step - loss: 0.7181 - accuracy: 0.5434\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 73ms/step - loss: 0.6904 - accuracy: 0.5048 - val_loss: 0.6890 - val_accuracy: 0.5293\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6869 - accuracy: 0.5206 - val_loss: 0.6881 - val_accuracy: 0.5337\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.6854 - accuracy: 0.5234 - val_loss: 0.6875 - val_accuracy: 0.5343\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6840 - accuracy: 0.5244 - val_loss: 0.6875 - val_accuracy: 0.5352\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6833 - accuracy: 0.5255 - val_loss: 0.6874 - val_accuracy: 0.5349\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 7s 97ms/step - loss: 0.6831 - accuracy: 0.5262 - val_loss: 0.6876 - val_accuracy: 0.5366\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6814 - accuracy: 0.5270 - val_loss: 0.6879 - val_accuracy: 0.5361\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6806 - accuracy: 0.5280 - val_loss: 0.6891 - val_accuracy: 0.5360\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6801 - accuracy: 0.5287 - val_loss: 0.6901 - val_accuracy: 0.5358\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6792 - accuracy: 0.5290 - val_loss: 0.6922 - val_accuracy: 0.5354\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6783 - accuracy: 0.5292 - val_loss: 0.6896 - val_accuracy: 0.5364\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6776 - accuracy: 0.5300 - val_loss: 0.6910 - val_accuracy: 0.5358\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6772 - accuracy: 0.5300 - val_loss: 0.6925 - val_accuracy: 0.5357\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6771 - accuracy: 0.5299 - val_loss: 0.6921 - val_accuracy: 0.5363\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6760 - accuracy: 0.5311 - val_loss: 0.6933 - val_accuracy: 0.5353\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6754 - accuracy: 0.5315 - val_loss: 0.6949 - val_accuracy: 0.5362\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6751 - accuracy: 0.5317 - val_loss: 0.6941 - val_accuracy: 0.5349\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6742 - accuracy: 0.5325 - val_loss: 0.6941 - val_accuracy: 0.5352\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6743 - accuracy: 0.5323 - val_loss: 0.6989 - val_accuracy: 0.5360\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6736 - accuracy: 0.5327 - val_loss: 0.6971 - val_accuracy: 0.5343\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6736 - accuracy: 0.5330 - val_loss: 0.6961 - val_accuracy: 0.5346\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6724 - accuracy: 0.5338 - val_loss: 0.7015 - val_accuracy: 0.5353\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6721 - accuracy: 0.5339 - val_loss: 0.7014 - val_accuracy: 0.5344\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6718 - accuracy: 0.5340 - val_loss: 0.7049 - val_accuracy: 0.5353\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6712 - accuracy: 0.5346 - val_loss: 0.7013 - val_accuracy: 0.5341\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6709 - accuracy: 0.5348 - val_loss: 0.7021 - val_accuracy: 0.5344\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6705 - accuracy: 0.5352 - val_loss: 0.7021 - val_accuracy: 0.5350\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6701 - accuracy: 0.5352 - val_loss: 0.7020 - val_accuracy: 0.5323\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6700 - accuracy: 0.5357 - val_loss: 0.7059 - val_accuracy: 0.5347\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6694 - accuracy: 0.5359 - val_loss: 0.7022 - val_accuracy: 0.5336\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6689 - accuracy: 0.5364 - val_loss: 0.7058 - val_accuracy: 0.5338\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6690 - accuracy: 0.5363 - val_loss: 0.7076 - val_accuracy: 0.5350\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6686 - accuracy: 0.5368 - val_loss: 0.7067 - val_accuracy: 0.5348\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6680 - accuracy: 0.5366 - val_loss: 0.7079 - val_accuracy: 0.5344\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6678 - accuracy: 0.5370 - val_loss: 0.7072 - val_accuracy: 0.5329\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6671 - accuracy: 0.5374 - val_loss: 0.7096 - val_accuracy: 0.5345\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6672 - accuracy: 0.5375 - val_loss: 0.7112 - val_accuracy: 0.5348\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6674 - accuracy: 0.5374 - val_loss: 0.7069 - val_accuracy: 0.5345\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6669 - accuracy: 0.5378 - val_loss: 0.7100 - val_accuracy: 0.5337\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6667 - accuracy: 0.5377 - val_loss: 0.7099 - val_accuracy: 0.5339\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6660 - accuracy: 0.5382 - val_loss: 0.7094 - val_accuracy: 0.5331\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6662 - accuracy: 0.5385 - val_loss: 0.7093 - val_accuracy: 0.5330\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6656 - accuracy: 0.5385 - val_loss: 0.7113 - val_accuracy: 0.5336\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6655 - accuracy: 0.5389 - val_loss: 0.7152 - val_accuracy: 0.5341\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6655 - accuracy: 0.5390 - val_loss: 0.7114 - val_accuracy: 0.5335\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6652 - accuracy: 0.5389 - val_loss: 0.7123 - val_accuracy: 0.5334\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6648 - accuracy: 0.5394 - val_loss: 0.7141 - val_accuracy: 0.5334\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6644 - accuracy: 0.5395 - val_loss: 0.7153 - val_accuracy: 0.5341\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6647 - accuracy: 0.5392 - val_loss: 0.7160 - val_accuracy: 0.5342\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6646 - accuracy: 0.5386 - val_loss: 0.7153 - val_accuracy: 0.5334\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6640 - accuracy: 0.5399 - val_loss: 0.7159 - val_accuracy: 0.5343\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6637 - accuracy: 0.5400 - val_loss: 0.7158 - val_accuracy: 0.5330\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6639 - accuracy: 0.5397 - val_loss: 0.7172 - val_accuracy: 0.5341\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6634 - accuracy: 0.5400 - val_loss: 0.7162 - val_accuracy: 0.5343\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6630 - accuracy: 0.5405 - val_loss: 0.7165 - val_accuracy: 0.5341\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6632 - accuracy: 0.5396 - val_loss: 0.7184 - val_accuracy: 0.5342\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6631 - accuracy: 0.5402 - val_loss: 0.7186 - val_accuracy: 0.5341\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6626 - accuracy: 0.5408 - val_loss: 0.7185 - val_accuracy: 0.5343\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6629 - accuracy: 0.5404 - val_loss: 0.7181 - val_accuracy: 0.5338\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6627 - accuracy: 0.5408 - val_loss: 0.7173 - val_accuracy: 0.5330\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6621 - accuracy: 0.5413 - val_loss: 0.7226 - val_accuracy: 0.5341\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6617 - accuracy: 0.5415 - val_loss: 0.7172 - val_accuracy: 0.5333\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6622 - accuracy: 0.5409 - val_loss: 0.7205 - val_accuracy: 0.5331\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6622 - accuracy: 0.5412 - val_loss: 0.7210 - val_accuracy: 0.5333\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6622 - accuracy: 0.5411 - val_loss: 0.7230 - val_accuracy: 0.5336\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6622 - accuracy: 0.5406 - val_loss: 0.7192 - val_accuracy: 0.5332\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6618 - accuracy: 0.5415 - val_loss: 0.7213 - val_accuracy: 0.5338\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6615 - accuracy: 0.5416 - val_loss: 0.7218 - val_accuracy: 0.5335\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6617 - accuracy: 0.5415 - val_loss: 0.7206 - val_accuracy: 0.5338\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6611 - accuracy: 0.5416 - val_loss: 0.7227 - val_accuracy: 0.5333\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6608 - accuracy: 0.5420 - val_loss: 0.7202 - val_accuracy: 0.5327\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6609 - accuracy: 0.5420 - val_loss: 0.7239 - val_accuracy: 0.5332\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6607 - accuracy: 0.5411 - val_loss: 0.7248 - val_accuracy: 0.5333\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6606 - accuracy: 0.5420 - val_loss: 0.7306 - val_accuracy: 0.5340\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6606 - accuracy: 0.5421 - val_loss: 0.7240 - val_accuracy: 0.5335\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6607 - accuracy: 0.5419 - val_loss: 0.7232 - val_accuracy: 0.5333\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6602 - accuracy: 0.5424 - val_loss: 0.7262 - val_accuracy: 0.5337\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6602 - accuracy: 0.5424 - val_loss: 0.7250 - val_accuracy: 0.5336\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6602 - accuracy: 0.5425 - val_loss: 0.7242 - val_accuracy: 0.5336\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6602 - accuracy: 0.5425 - val_loss: 0.7247 - val_accuracy: 0.5338\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6601 - accuracy: 0.5420 - val_loss: 0.7281 - val_accuracy: 0.5333\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6599 - accuracy: 0.5425 - val_loss: 0.7266 - val_accuracy: 0.5335\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6596 - accuracy: 0.5407 - val_loss: 0.7235 - val_accuracy: 0.5325\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6599 - accuracy: 0.5427 - val_loss: 0.7256 - val_accuracy: 0.5339\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6596 - accuracy: 0.5427 - val_loss: 0.7287 - val_accuracy: 0.5334\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6596 - accuracy: 0.5430 - val_loss: 0.7262 - val_accuracy: 0.5334\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6591 - accuracy: 0.5431 - val_loss: 0.7286 - val_accuracy: 0.5340\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6595 - accuracy: 0.5431 - val_loss: 0.7293 - val_accuracy: 0.5340\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6591 - accuracy: 0.5432 - val_loss: 0.7268 - val_accuracy: 0.5330\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6589 - accuracy: 0.5434 - val_loss: 0.7275 - val_accuracy: 0.5325\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6592 - accuracy: 0.5424 - val_loss: 0.7287 - val_accuracy: 0.5330\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6592 - accuracy: 0.5434 - val_loss: 0.7297 - val_accuracy: 0.5335\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 7s 93ms/step - loss: 0.6590 - accuracy: 0.5430 - val_loss: 0.7306 - val_accuracy: 0.5345\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6584 - accuracy: 0.5435 - val_loss: 0.7308 - val_accuracy: 0.5338\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6592 - accuracy: 0.5430 - val_loss: 0.7276 - val_accuracy: 0.5339\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6590 - accuracy: 0.5429 - val_loss: 0.7279 - val_accuracy: 0.5343\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6581 - accuracy: 0.5438 - val_loss: 0.7286 - val_accuracy: 0.5335\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6584 - accuracy: 0.5436 - val_loss: 0.7284 - val_accuracy: 0.5336\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6586 - accuracy: 0.5440 - val_loss: 0.7309 - val_accuracy: 0.5331\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6581 - accuracy: 0.5432 - val_loss: 0.7294 - val_accuracy: 0.5334\n",
            "19/19 [==============================] - 1s 28ms/step - loss: 0.7338 - accuracy: 0.5317\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 7s 74ms/step - loss: 0.6909 - accuracy: 0.5104 - val_loss: 0.6876 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6875 - accuracy: 0.5291 - val_loss: 0.6868 - val_accuracy: 0.5029\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6864 - accuracy: 0.5306 - val_loss: 0.6861 - val_accuracy: 0.5039\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6848 - accuracy: 0.5323 - val_loss: 0.6865 - val_accuracy: 0.5033\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6840 - accuracy: 0.5333 - val_loss: 0.6864 - val_accuracy: 0.5040\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6834 - accuracy: 0.5339 - val_loss: 0.6879 - val_accuracy: 0.5005\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6824 - accuracy: 0.5354 - val_loss: 0.6865 - val_accuracy: 0.5033\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6815 - accuracy: 0.5353 - val_loss: 0.6877 - val_accuracy: 0.5005\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6810 - accuracy: 0.5364 - val_loss: 0.6878 - val_accuracy: 0.5002\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6803 - accuracy: 0.5368 - val_loss: 0.6886 - val_accuracy: 0.5025\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6795 - accuracy: 0.5376 - val_loss: 0.6880 - val_accuracy: 0.4999\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 7s 90ms/step - loss: 0.6786 - accuracy: 0.5379 - val_loss: 0.6883 - val_accuracy: 0.5006\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6777 - accuracy: 0.5387 - val_loss: 0.6878 - val_accuracy: 0.5018\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6769 - accuracy: 0.5394 - val_loss: 0.6888 - val_accuracy: 0.5029\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 7s 89ms/step - loss: 0.6765 - accuracy: 0.5397 - val_loss: 0.6888 - val_accuracy: 0.5006\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6760 - accuracy: 0.5401 - val_loss: 0.6896 - val_accuracy: 0.4995\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6752 - accuracy: 0.5405 - val_loss: 0.6890 - val_accuracy: 0.5007\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6748 - accuracy: 0.5407 - val_loss: 0.6892 - val_accuracy: 0.5007\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6744 - accuracy: 0.5411 - val_loss: 0.6901 - val_accuracy: 0.4997\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6738 - accuracy: 0.5414 - val_loss: 0.6895 - val_accuracy: 0.5020\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6736 - accuracy: 0.5420 - val_loss: 0.6891 - val_accuracy: 0.4999\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6729 - accuracy: 0.5422 - val_loss: 0.6908 - val_accuracy: 0.5021\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6728 - accuracy: 0.5422 - val_loss: 0.6911 - val_accuracy: 0.5015\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6723 - accuracy: 0.5422 - val_loss: 0.6898 - val_accuracy: 0.5010\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6725 - accuracy: 0.5424 - val_loss: 0.6906 - val_accuracy: 0.5006\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6715 - accuracy: 0.5430 - val_loss: 0.6921 - val_accuracy: 0.4991\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6713 - accuracy: 0.5435 - val_loss: 0.6928 - val_accuracy: 0.4984\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6706 - accuracy: 0.5438 - val_loss: 0.6937 - val_accuracy: 0.5012\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6702 - accuracy: 0.5439 - val_loss: 0.6925 - val_accuracy: 0.5003\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6697 - accuracy: 0.5443 - val_loss: 0.6936 - val_accuracy: 0.4985\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6697 - accuracy: 0.5443 - val_loss: 0.6930 - val_accuracy: 0.4994\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6695 - accuracy: 0.5444 - val_loss: 0.6939 - val_accuracy: 0.5003\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6690 - accuracy: 0.5445 - val_loss: 0.6921 - val_accuracy: 0.5011\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6687 - accuracy: 0.5448 - val_loss: 0.6943 - val_accuracy: 0.5008\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6684 - accuracy: 0.5452 - val_loss: 0.6933 - val_accuracy: 0.5013\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6682 - accuracy: 0.5454 - val_loss: 0.6946 - val_accuracy: 0.5009\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6679 - accuracy: 0.5456 - val_loss: 0.6934 - val_accuracy: 0.5004\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6676 - accuracy: 0.5457 - val_loss: 0.6933 - val_accuracy: 0.5002\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6672 - accuracy: 0.5460 - val_loss: 0.6947 - val_accuracy: 0.5011\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6672 - accuracy: 0.5458 - val_loss: 0.6952 - val_accuracy: 0.5017\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6672 - accuracy: 0.5462 - val_loss: 0.6939 - val_accuracy: 0.5014\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6668 - accuracy: 0.5462 - val_loss: 0.6961 - val_accuracy: 0.5008\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6663 - accuracy: 0.5465 - val_loss: 0.6969 - val_accuracy: 0.5006\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6661 - accuracy: 0.5467 - val_loss: 0.6967 - val_accuracy: 0.5023\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6658 - accuracy: 0.5467 - val_loss: 0.6952 - val_accuracy: 0.5013\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6663 - accuracy: 0.5466 - val_loss: 0.6950 - val_accuracy: 0.5008\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6656 - accuracy: 0.5470 - val_loss: 0.7017 - val_accuracy: 0.4999\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6659 - accuracy: 0.5471 - val_loss: 0.6965 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6657 - accuracy: 0.5471 - val_loss: 0.6971 - val_accuracy: 0.4999\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6650 - accuracy: 0.5477 - val_loss: 0.6952 - val_accuracy: 0.5006\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6653 - accuracy: 0.5473 - val_loss: 0.6981 - val_accuracy: 0.5013\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6644 - accuracy: 0.5480 - val_loss: 0.6977 - val_accuracy: 0.4998\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6648 - accuracy: 0.5477 - val_loss: 0.6972 - val_accuracy: 0.5017\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6643 - accuracy: 0.5481 - val_loss: 0.6957 - val_accuracy: 0.5014\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6641 - accuracy: 0.5479 - val_loss: 0.6976 - val_accuracy: 0.5015\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6639 - accuracy: 0.5485 - val_loss: 0.6987 - val_accuracy: 0.4998\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6635 - accuracy: 0.5486 - val_loss: 0.6983 - val_accuracy: 0.5008\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6635 - accuracy: 0.5487 - val_loss: 0.6995 - val_accuracy: 0.5007\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6634 - accuracy: 0.5488 - val_loss: 0.7005 - val_accuracy: 0.5025\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6635 - accuracy: 0.5446 - val_loss: 0.7008 - val_accuracy: 0.5004\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6630 - accuracy: 0.5488 - val_loss: 0.7009 - val_accuracy: 0.5013\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6628 - accuracy: 0.5491 - val_loss: 0.7000 - val_accuracy: 0.5025\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6628 - accuracy: 0.5492 - val_loss: 0.6985 - val_accuracy: 0.5022\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 5s 67ms/step - loss: 0.6625 - accuracy: 0.5493 - val_loss: 0.7002 - val_accuracy: 0.5004\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6631 - accuracy: 0.5494 - val_loss: 0.7011 - val_accuracy: 0.5017\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6625 - accuracy: 0.5493 - val_loss: 0.7004 - val_accuracy: 0.5014\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6621 - accuracy: 0.5494 - val_loss: 0.7008 - val_accuracy: 0.5019\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6620 - accuracy: 0.5494 - val_loss: 0.6996 - val_accuracy: 0.5015\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6622 - accuracy: 0.5494 - val_loss: 0.7011 - val_accuracy: 0.5019\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6617 - accuracy: 0.5498 - val_loss: 0.7011 - val_accuracy: 0.5022\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6619 - accuracy: 0.5496 - val_loss: 0.7022 - val_accuracy: 0.5010\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6615 - accuracy: 0.5498 - val_loss: 0.7012 - val_accuracy: 0.5005\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6624 - accuracy: 0.5497 - val_loss: 0.7002 - val_accuracy: 0.5010\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6613 - accuracy: 0.5502 - val_loss: 0.7010 - val_accuracy: 0.5015\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6613 - accuracy: 0.5498 - val_loss: 0.7016 - val_accuracy: 0.5016\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6610 - accuracy: 0.5502 - val_loss: 0.7026 - val_accuracy: 0.5024\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6610 - accuracy: 0.5501 - val_loss: 0.7024 - val_accuracy: 0.5017\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6608 - accuracy: 0.5503 - val_loss: 0.7034 - val_accuracy: 0.5014\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6606 - accuracy: 0.5504 - val_loss: 0.7015 - val_accuracy: 0.5015\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6607 - accuracy: 0.5505 - val_loss: 0.7023 - val_accuracy: 0.5014\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6607 - accuracy: 0.5504 - val_loss: 0.7020 - val_accuracy: 0.5004\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6605 - accuracy: 0.5507 - val_loss: 0.7033 - val_accuracy: 0.5012\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6605 - accuracy: 0.5502 - val_loss: 0.7019 - val_accuracy: 0.5017\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6602 - accuracy: 0.5505 - val_loss: 0.7050 - val_accuracy: 0.5005\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6602 - accuracy: 0.5506 - val_loss: 0.7034 - val_accuracy: 0.5012\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6603 - accuracy: 0.5505 - val_loss: 0.7060 - val_accuracy: 0.5027\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6605 - accuracy: 0.5504 - val_loss: 0.7022 - val_accuracy: 0.5012\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6596 - accuracy: 0.5511 - val_loss: 0.7053 - val_accuracy: 0.5017\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6603 - accuracy: 0.5507 - val_loss: 0.7042 - val_accuracy: 0.5023\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6597 - accuracy: 0.5510 - val_loss: 0.7046 - val_accuracy: 0.5010\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6595 - accuracy: 0.5509 - val_loss: 0.7054 - val_accuracy: 0.5011\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6593 - accuracy: 0.5512 - val_loss: 0.7066 - val_accuracy: 0.5015\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6589 - accuracy: 0.5514 - val_loss: 0.7059 - val_accuracy: 0.5019\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6592 - accuracy: 0.5516 - val_loss: 0.7057 - val_accuracy: 0.5021\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6598 - accuracy: 0.5508 - val_loss: 0.7055 - val_accuracy: 0.5013\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6591 - accuracy: 0.5514 - val_loss: 0.7063 - val_accuracy: 0.5005\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 66ms/step - loss: 0.6591 - accuracy: 0.5513 - val_loss: 0.7052 - val_accuracy: 0.5013\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6591 - accuracy: 0.5514 - val_loss: 0.7062 - val_accuracy: 0.5015\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6589 - accuracy: 0.5516 - val_loss: 0.7068 - val_accuracy: 0.5012\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6590 - accuracy: 0.5513 - val_loss: 0.7088 - val_accuracy: 0.5021\n",
            "19/19 [==============================] - 1s 20ms/step - loss: 0.7154 - accuracy: 0.5007\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 11s 134ms/step - loss: 0.6901 - accuracy: 0.5058 - val_loss: 0.6878 - val_accuracy: 0.5286\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6873 - accuracy: 0.5217 - val_loss: 0.6865 - val_accuracy: 0.5339\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 9s 130ms/step - loss: 0.6860 - accuracy: 0.5237 - val_loss: 0.6858 - val_accuracy: 0.5344\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6847 - accuracy: 0.5246 - val_loss: 0.6854 - val_accuracy: 0.5352\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6839 - accuracy: 0.5260 - val_loss: 0.6853 - val_accuracy: 0.5359\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6825 - accuracy: 0.5272 - val_loss: 0.6859 - val_accuracy: 0.5359\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6821 - accuracy: 0.5270 - val_loss: 0.6858 - val_accuracy: 0.5358\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6812 - accuracy: 0.5282 - val_loss: 0.6859 - val_accuracy: 0.5358\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6806 - accuracy: 0.5286 - val_loss: 0.6866 - val_accuracy: 0.5365\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6793 - accuracy: 0.5291 - val_loss: 0.6867 - val_accuracy: 0.5345\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6792 - accuracy: 0.5297 - val_loss: 0.6867 - val_accuracy: 0.5361\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6783 - accuracy: 0.5303 - val_loss: 0.6871 - val_accuracy: 0.5362\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6777 - accuracy: 0.5307 - val_loss: 0.6869 - val_accuracy: 0.5355\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6769 - accuracy: 0.5310 - val_loss: 0.6894 - val_accuracy: 0.5354\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6760 - accuracy: 0.5317 - val_loss: 0.6884 - val_accuracy: 0.5347\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6759 - accuracy: 0.5319 - val_loss: 0.6891 - val_accuracy: 0.5353\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6748 - accuracy: 0.5327 - val_loss: 0.6901 - val_accuracy: 0.5355\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6747 - accuracy: 0.5329 - val_loss: 0.6904 - val_accuracy: 0.5351\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6745 - accuracy: 0.5330 - val_loss: 0.6908 - val_accuracy: 0.5353\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6737 - accuracy: 0.5334 - val_loss: 0.6898 - val_accuracy: 0.5338\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6732 - accuracy: 0.5340 - val_loss: 0.6926 - val_accuracy: 0.5351\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6725 - accuracy: 0.5342 - val_loss: 0.6924 - val_accuracy: 0.5351\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6721 - accuracy: 0.5347 - val_loss: 0.6918 - val_accuracy: 0.5332\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6720 - accuracy: 0.5352 - val_loss: 0.6922 - val_accuracy: 0.5341\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6714 - accuracy: 0.5355 - val_loss: 0.6935 - val_accuracy: 0.5343\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6710 - accuracy: 0.5356 - val_loss: 0.6961 - val_accuracy: 0.5341\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6704 - accuracy: 0.5359 - val_loss: 0.6936 - val_accuracy: 0.5324\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6701 - accuracy: 0.5362 - val_loss: 0.6958 - val_accuracy: 0.5325\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6701 - accuracy: 0.5363 - val_loss: 0.6952 - val_accuracy: 0.5337\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6692 - accuracy: 0.5371 - val_loss: 0.6959 - val_accuracy: 0.5335\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6691 - accuracy: 0.5371 - val_loss: 0.6956 - val_accuracy: 0.5334\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6685 - accuracy: 0.5374 - val_loss: 0.6990 - val_accuracy: 0.5344\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6686 - accuracy: 0.5377 - val_loss: 0.6980 - val_accuracy: 0.5334\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6680 - accuracy: 0.5376 - val_loss: 0.6972 - val_accuracy: 0.5320\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6681 - accuracy: 0.5379 - val_loss: 0.6996 - val_accuracy: 0.5333\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6674 - accuracy: 0.5381 - val_loss: 0.7010 - val_accuracy: 0.5338\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6676 - accuracy: 0.5379 - val_loss: 0.7016 - val_accuracy: 0.5337\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6671 - accuracy: 0.5381 - val_loss: 0.6997 - val_accuracy: 0.5328\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6666 - accuracy: 0.5387 - val_loss: 0.7009 - val_accuracy: 0.5327\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6668 - accuracy: 0.5385 - val_loss: 0.6997 - val_accuracy: 0.5331\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6660 - accuracy: 0.5393 - val_loss: 0.7036 - val_accuracy: 0.5334\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6658 - accuracy: 0.5392 - val_loss: 0.7025 - val_accuracy: 0.5334\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6655 - accuracy: 0.5394 - val_loss: 0.7019 - val_accuracy: 0.5323\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6655 - accuracy: 0.5396 - val_loss: 0.7025 - val_accuracy: 0.5328\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6655 - accuracy: 0.5395 - val_loss: 0.7032 - val_accuracy: 0.5323\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6645 - accuracy: 0.5399 - val_loss: 0.7057 - val_accuracy: 0.5335\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6649 - accuracy: 0.5400 - val_loss: 0.7027 - val_accuracy: 0.5331\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6646 - accuracy: 0.5399 - val_loss: 0.7068 - val_accuracy: 0.5339\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6648 - accuracy: 0.5399 - val_loss: 0.7059 - val_accuracy: 0.5335\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6641 - accuracy: 0.5405 - val_loss: 0.7047 - val_accuracy: 0.5333\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6639 - accuracy: 0.5405 - val_loss: 0.7056 - val_accuracy: 0.5334\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6636 - accuracy: 0.5409 - val_loss: 0.7060 - val_accuracy: 0.5326\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6636 - accuracy: 0.5405 - val_loss: 0.7068 - val_accuracy: 0.5334\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6636 - accuracy: 0.5399 - val_loss: 0.7093 - val_accuracy: 0.5337\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6631 - accuracy: 0.5411 - val_loss: 0.7081 - val_accuracy: 0.5332\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6633 - accuracy: 0.5408 - val_loss: 0.7097 - val_accuracy: 0.5332\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6626 - accuracy: 0.5398 - val_loss: 0.7094 - val_accuracy: 0.5331\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6630 - accuracy: 0.5411 - val_loss: 0.7085 - val_accuracy: 0.5331\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6624 - accuracy: 0.5417 - val_loss: 0.7115 - val_accuracy: 0.5336\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6626 - accuracy: 0.5412 - val_loss: 0.7067 - val_accuracy: 0.5328\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6623 - accuracy: 0.5416 - val_loss: 0.7091 - val_accuracy: 0.5328\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6621 - accuracy: 0.5415 - val_loss: 0.7127 - val_accuracy: 0.5331\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6628 - accuracy: 0.5414 - val_loss: 0.7081 - val_accuracy: 0.5328\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6619 - accuracy: 0.5412 - val_loss: 0.7092 - val_accuracy: 0.5334\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6616 - accuracy: 0.5420 - val_loss: 0.7099 - val_accuracy: 0.5326\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6615 - accuracy: 0.5420 - val_loss: 0.7082 - val_accuracy: 0.5329\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6616 - accuracy: 0.5421 - val_loss: 0.7086 - val_accuracy: 0.5327\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6612 - accuracy: 0.5425 - val_loss: 0.7095 - val_accuracy: 0.5334\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6617 - accuracy: 0.5422 - val_loss: 0.7108 - val_accuracy: 0.5327\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6611 - accuracy: 0.5425 - val_loss: 0.7106 - val_accuracy: 0.5329\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6613 - accuracy: 0.5423 - val_loss: 0.7101 - val_accuracy: 0.5325\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6606 - accuracy: 0.5423 - val_loss: 0.7123 - val_accuracy: 0.5327\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6609 - accuracy: 0.5428 - val_loss: 0.7155 - val_accuracy: 0.5340\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 68ms/step - loss: 0.6610 - accuracy: 0.5424 - val_loss: 0.7110 - val_accuracy: 0.5332\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6603 - accuracy: 0.5426 - val_loss: 0.7107 - val_accuracy: 0.5329\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6608 - accuracy: 0.5425 - val_loss: 0.7105 - val_accuracy: 0.5321\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6607 - accuracy: 0.5426 - val_loss: 0.7110 - val_accuracy: 0.5323\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6602 - accuracy: 0.5428 - val_loss: 0.7130 - val_accuracy: 0.5330\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6604 - accuracy: 0.5429 - val_loss: 0.7114 - val_accuracy: 0.5335\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6601 - accuracy: 0.5432 - val_loss: 0.7117 - val_accuracy: 0.5321\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6604 - accuracy: 0.5425 - val_loss: 0.7118 - val_accuracy: 0.5327\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6604 - accuracy: 0.5429 - val_loss: 0.7123 - val_accuracy: 0.5333\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6600 - accuracy: 0.5430 - val_loss: 0.7137 - val_accuracy: 0.5324\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6599 - accuracy: 0.5433 - val_loss: 0.7142 - val_accuracy: 0.5330\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6599 - accuracy: 0.5432 - val_loss: 0.7111 - val_accuracy: 0.5328\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6597 - accuracy: 0.5430 - val_loss: 0.7132 - val_accuracy: 0.5330\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6596 - accuracy: 0.5434 - val_loss: 0.7128 - val_accuracy: 0.5325\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6596 - accuracy: 0.5434 - val_loss: 0.7124 - val_accuracy: 0.5331\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6595 - accuracy: 0.5435 - val_loss: 0.7126 - val_accuracy: 0.5329\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6593 - accuracy: 0.5434 - val_loss: 0.7122 - val_accuracy: 0.5330\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6591 - accuracy: 0.5436 - val_loss: 0.7121 - val_accuracy: 0.5326\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6592 - accuracy: 0.5436 - val_loss: 0.7130 - val_accuracy: 0.5328\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6591 - accuracy: 0.5433 - val_loss: 0.7138 - val_accuracy: 0.5327\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6590 - accuracy: 0.5437 - val_loss: 0.7158 - val_accuracy: 0.5333\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6588 - accuracy: 0.5440 - val_loss: 0.7146 - val_accuracy: 0.5331\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6586 - accuracy: 0.5441 - val_loss: 0.7144 - val_accuracy: 0.5335\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6587 - accuracy: 0.5441 - val_loss: 0.7156 - val_accuracy: 0.5335\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6586 - accuracy: 0.5438 - val_loss: 0.7173 - val_accuracy: 0.5335\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6586 - accuracy: 0.5438 - val_loss: 0.7125 - val_accuracy: 0.5325\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6587 - accuracy: 0.5440 - val_loss: 0.7142 - val_accuracy: 0.5331\n",
            "19/19 [==============================] - 1s 20ms/step - loss: 0.7165 - accuracy: 0.5320\n",
            "2309\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 12s 138ms/step - loss: 0.6907 - accuracy: 0.5093 - val_loss: 0.6876 - val_accuracy: 0.5098\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6874 - accuracy: 0.5265 - val_loss: 0.6871 - val_accuracy: 0.5145\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 5s 69ms/step - loss: 0.6857 - accuracy: 0.5282 - val_loss: 0.6865 - val_accuracy: 0.5148\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6845 - accuracy: 0.5295 - val_loss: 0.6867 - val_accuracy: 0.5146\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6834 - accuracy: 0.5303 - val_loss: 0.6870 - val_accuracy: 0.5144\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6832 - accuracy: 0.5313 - val_loss: 0.6864 - val_accuracy: 0.5156\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6817 - accuracy: 0.5323 - val_loss: 0.6868 - val_accuracy: 0.5153\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6809 - accuracy: 0.5334 - val_loss: 0.6873 - val_accuracy: 0.5151\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6807 - accuracy: 0.5331 - val_loss: 0.6871 - val_accuracy: 0.5148\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6800 - accuracy: 0.5340 - val_loss: 0.6880 - val_accuracy: 0.5159\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6789 - accuracy: 0.5345 - val_loss: 0.6885 - val_accuracy: 0.5156\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6784 - accuracy: 0.5351 - val_loss: 0.6887 - val_accuracy: 0.5162\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6776 - accuracy: 0.5355 - val_loss: 0.6895 - val_accuracy: 0.5155\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6774 - accuracy: 0.5356 - val_loss: 0.6894 - val_accuracy: 0.5141\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6766 - accuracy: 0.5361 - val_loss: 0.6905 - val_accuracy: 0.5162\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6763 - accuracy: 0.5366 - val_loss: 0.6905 - val_accuracy: 0.5153\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6755 - accuracy: 0.5369 - val_loss: 0.6914 - val_accuracy: 0.5131\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6752 - accuracy: 0.5372 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6747 - accuracy: 0.5376 - val_loss: 0.6915 - val_accuracy: 0.5155\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6741 - accuracy: 0.5379 - val_loss: 0.6928 - val_accuracy: 0.5147\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6738 - accuracy: 0.5382 - val_loss: 0.6926 - val_accuracy: 0.5148\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6737 - accuracy: 0.5383 - val_loss: 0.6940 - val_accuracy: 0.5154\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6728 - accuracy: 0.5387 - val_loss: 0.6930 - val_accuracy: 0.5138\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6723 - accuracy: 0.5394 - val_loss: 0.6952 - val_accuracy: 0.5147\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6723 - accuracy: 0.5394 - val_loss: 0.6958 - val_accuracy: 0.5146\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6719 - accuracy: 0.5396 - val_loss: 0.6971 - val_accuracy: 0.5145\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6712 - accuracy: 0.5400 - val_loss: 0.6990 - val_accuracy: 0.5151\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 6s 89ms/step - loss: 0.6711 - accuracy: 0.5401 - val_loss: 0.6980 - val_accuracy: 0.5150\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6705 - accuracy: 0.5403 - val_loss: 0.6971 - val_accuracy: 0.5135\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6702 - accuracy: 0.5408 - val_loss: 0.6968 - val_accuracy: 0.5139\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 6s 88ms/step - loss: 0.6700 - accuracy: 0.5410 - val_loss: 0.6994 - val_accuracy: 0.5141\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6696 - accuracy: 0.5414 - val_loss: 0.6994 - val_accuracy: 0.5149\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6702 - accuracy: 0.5359 - val_loss: 0.6983 - val_accuracy: 0.5145\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6690 - accuracy: 0.5414 - val_loss: 0.6997 - val_accuracy: 0.5133\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6686 - accuracy: 0.5421 - val_loss: 0.7008 - val_accuracy: 0.5120\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6686 - accuracy: 0.5421 - val_loss: 0.6982 - val_accuracy: 0.5129\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 7s 90ms/step - loss: 0.6685 - accuracy: 0.5421 - val_loss: 0.7000 - val_accuracy: 0.5140\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6681 - accuracy: 0.5422 - val_loss: 0.7009 - val_accuracy: 0.5129\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6682 - accuracy: 0.5424 - val_loss: 0.7014 - val_accuracy: 0.5129\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6675 - accuracy: 0.5427 - val_loss: 0.7023 - val_accuracy: 0.5142\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6675 - accuracy: 0.5428 - val_loss: 0.7030 - val_accuracy: 0.5147\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6671 - accuracy: 0.5429 - val_loss: 0.7009 - val_accuracy: 0.5126\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6667 - accuracy: 0.5432 - val_loss: 0.7080 - val_accuracy: 0.5115\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6681 - accuracy: 0.5428 - val_loss: 0.7010 - val_accuracy: 0.5129\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6668 - accuracy: 0.5430 - val_loss: 0.7029 - val_accuracy: 0.5123\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 6s 87ms/step - loss: 0.6662 - accuracy: 0.5436 - val_loss: 0.7040 - val_accuracy: 0.5124\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 5s 75ms/step - loss: 0.6662 - accuracy: 0.5436 - val_loss: 0.7051 - val_accuracy: 0.5142\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6654 - accuracy: 0.5441 - val_loss: 0.7057 - val_accuracy: 0.5139\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6655 - accuracy: 0.5440 - val_loss: 0.7045 - val_accuracy: 0.5137\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6653 - accuracy: 0.5443 - val_loss: 0.7050 - val_accuracy: 0.5141\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6649 - accuracy: 0.5446 - val_loss: 0.7043 - val_accuracy: 0.5134\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6647 - accuracy: 0.5447 - val_loss: 0.7047 - val_accuracy: 0.5141\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6646 - accuracy: 0.5448 - val_loss: 0.7051 - val_accuracy: 0.5136\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6641 - accuracy: 0.5450 - val_loss: 0.7076 - val_accuracy: 0.5140\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 6s 86ms/step - loss: 0.6643 - accuracy: 0.5449 - val_loss: 0.7059 - val_accuracy: 0.5138\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6645 - accuracy: 0.5447 - val_loss: 0.7075 - val_accuracy: 0.5141\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6641 - accuracy: 0.5449 - val_loss: 0.7067 - val_accuracy: 0.5143\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6637 - accuracy: 0.5452 - val_loss: 0.7064 - val_accuracy: 0.5136\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6638 - accuracy: 0.5454 - val_loss: 0.7073 - val_accuracy: 0.5133\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 6s 78ms/step - loss: 0.6637 - accuracy: 0.5456 - val_loss: 0.7090 - val_accuracy: 0.5134\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6632 - accuracy: 0.5455 - val_loss: 0.7075 - val_accuracy: 0.5134\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6634 - accuracy: 0.5454 - val_loss: 0.7070 - val_accuracy: 0.5140\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6631 - accuracy: 0.5456 - val_loss: 0.7092 - val_accuracy: 0.5137\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 6s 79ms/step - loss: 0.6629 - accuracy: 0.5459 - val_loss: 0.7116 - val_accuracy: 0.5146\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6629 - accuracy: 0.5457 - val_loss: 0.7078 - val_accuracy: 0.5132\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6625 - accuracy: 0.5461 - val_loss: 0.7091 - val_accuracy: 0.5137\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6630 - accuracy: 0.5456 - val_loss: 0.7079 - val_accuracy: 0.5127\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6627 - accuracy: 0.5457 - val_loss: 0.7104 - val_accuracy: 0.5144\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 6s 77ms/step - loss: 0.6621 - accuracy: 0.5463 - val_loss: 0.7103 - val_accuracy: 0.5138\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6622 - accuracy: 0.5462 - val_loss: 0.7100 - val_accuracy: 0.5142\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6622 - accuracy: 0.5465 - val_loss: 0.7082 - val_accuracy: 0.5132\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6620 - accuracy: 0.5464 - val_loss: 0.7101 - val_accuracy: 0.5133\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6618 - accuracy: 0.5465 - val_loss: 0.7098 - val_accuracy: 0.5136\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6619 - accuracy: 0.5465 - val_loss: 0.7109 - val_accuracy: 0.5134\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6617 - accuracy: 0.5464 - val_loss: 0.7119 - val_accuracy: 0.5132\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6617 - accuracy: 0.5467 - val_loss: 0.7112 - val_accuracy: 0.5139\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 5s 73ms/step - loss: 0.6613 - accuracy: 0.5468 - val_loss: 0.7159 - val_accuracy: 0.5140\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 7s 92ms/step - loss: 0.6613 - accuracy: 0.5469 - val_loss: 0.7135 - val_accuracy: 0.5139\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 7s 93ms/step - loss: 0.6612 - accuracy: 0.5471 - val_loss: 0.7133 - val_accuracy: 0.5134\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6613 - accuracy: 0.5469 - val_loss: 0.7142 - val_accuracy: 0.5140\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6611 - accuracy: 0.5471 - val_loss: 0.7148 - val_accuracy: 0.5148\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6610 - accuracy: 0.5470 - val_loss: 0.7133 - val_accuracy: 0.5136\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6607 - accuracy: 0.5474 - val_loss: 0.7139 - val_accuracy: 0.5143\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 6s 84ms/step - loss: 0.6609 - accuracy: 0.5466 - val_loss: 0.7140 - val_accuracy: 0.5135\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 6s 82ms/step - loss: 0.6605 - accuracy: 0.5474 - val_loss: 0.7128 - val_accuracy: 0.5128\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6606 - accuracy: 0.5474 - val_loss: 0.7133 - val_accuracy: 0.5135\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6604 - accuracy: 0.5473 - val_loss: 0.7152 - val_accuracy: 0.5133\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6604 - accuracy: 0.5476 - val_loss: 0.7138 - val_accuracy: 0.5129\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 5s 72ms/step - loss: 0.6599 - accuracy: 0.5473 - val_loss: 0.7165 - val_accuracy: 0.5133\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 6s 85ms/step - loss: 0.6604 - accuracy: 0.5478 - val_loss: 0.7141 - val_accuracy: 0.5139\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6602 - accuracy: 0.5477 - val_loss: 0.7136 - val_accuracy: 0.5136\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 5s 71ms/step - loss: 0.6604 - accuracy: 0.5474 - val_loss: 0.7167 - val_accuracy: 0.5142\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 6s 83ms/step - loss: 0.6602 - accuracy: 0.5477 - val_loss: 0.7156 - val_accuracy: 0.5142\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 6s 80ms/step - loss: 0.6598 - accuracy: 0.5463 - val_loss: 0.7150 - val_accuracy: 0.5132\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 5s 70ms/step - loss: 0.6597 - accuracy: 0.5480 - val_loss: 0.7154 - val_accuracy: 0.5128\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 7s 90ms/step - loss: 0.6598 - accuracy: 0.5479 - val_loss: 0.7158 - val_accuracy: 0.5131\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 5s 74ms/step - loss: 0.6598 - accuracy: 0.5479 - val_loss: 0.7140 - val_accuracy: 0.5133\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 6s 76ms/step - loss: 0.6595 - accuracy: 0.5480 - val_loss: 0.7147 - val_accuracy: 0.5129\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 6s 81ms/step - loss: 0.6596 - accuracy: 0.5481 - val_loss: 0.7149 - val_accuracy: 0.5135\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 6s 75ms/step - loss: 0.6594 - accuracy: 0.5481 - val_loss: 0.7148 - val_accuracy: 0.5136\n",
            "19/19 [==============================] - 1s 22ms/step - loss: 0.7178 - accuracy: 0.5128\n",
            "Best accuracy for dataset 4: 0.5434162616729736\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize dictionary to store best models and their performances\n",
        "best_models = {}\n",
        "\n",
        "for df_idx, df in enumerate(dfs):\n",
        "    best_accuracy = 0\n",
        "    best_model = None\n",
        "\n",
        "    # Prepare data\n",
        "    X_emb = pad_sequences(df['emb'], dtype='float32', padding='post')\n",
        "    y = np.array(df['label'])\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(kf.split(X_emb)):\n",
        "        X_emb_train, X_emb_val = X_emb[train_index], X_emb[val_index]\n",
        "        y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "        model = create_model()\n",
        "        print(len((y_train.reshape(-1, 1))))\n",
        "        history = model.fit(X_emb_train, y_train.reshape(-1, 1), epochs=100, batch_size=32, validation_data=(X_emb_val, y_val.reshape(-1, 1)))\n",
        "\n",
        "        # Evaluate model performance\n",
        "        _, accuracy = model.evaluate(X_emb_val, y_val)\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    # Save the best model for this dataset\n",
        "    best_models[f'df_{df_idx}'] = best_model\n",
        "    print(f\"Best accuracy for dataset {df_idx}: {best_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFwkcgJmoUv3",
        "outputId": "f236a092-16bf-438a-8bf0-2fa2b1554c04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "for idx, (name, model) in enumerate(best_models.items()):\n",
        "    model.save(f'/content/drive/MyDrive/best_model_bbbp{name}.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DIvTuGoETnp"
      },
      "source": [
        "load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9QKaH5dESs-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "best_models = []\n",
        "for cnt in range(5):\n",
        "  best_models.append(load_model('/content/drive/MyDrive/best_model_bbbpdf_' + str(cnt) + '.h5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0LqXD5WXxTc"
      },
      "source": [
        "Evaluating the performances of the best models using ROC\n",
        "fare file log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EVM5KRu---_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Open a file to write the results\n",
        "with open(\"/content/drive/MyDrive/metrics_results_bbbp_models.txt\", \"w\") as file:\n",
        "\n",
        "    # Loop through best models\n",
        "    for idx, model in enumerate(best_models):\n",
        "        file.write(f\"\\nModel {idx + 1}\\n\")\n",
        "\n",
        "        df = dfs[idx]\n",
        "        X_emb = pad_sequences(df['emb'], dtype='float32', padding='post')\n",
        "        y = np.array(df['label'])\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        X_emb_train, X_emb_test, y_train, y_test = train_test_split(X_emb, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "        # Pad sequences if necessary\n",
        "        X_emb_train = pad_sequences(X_emb_train, dtype='float32', padding='post')\n",
        "        X_emb_test = pad_sequences(X_emb_test, dtype='float32', padding='post')\n",
        "\n",
        "        # Reshape labels if necessary\n",
        "        y_train_reshaped = y_train.reshape(-1, 1)\n",
        "        y_test_reshaped = y_test.reshape(-1, 1)\n",
        "\n",
        "        # predict probabilities for test set\n",
        "        yhat_probs = model.predict(X_emb_test, verbose=0)\n",
        "        # predict crisp classes for test set\n",
        "        y_classes = np.argmax(yhat_probs, axis=1)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_classes)\n",
        "        precision = precision_score(y_test, y_classes, labels=[1] , average = 'weighted')\n",
        "        recall = recall_score(y_test, y_classes, labels=[1], average = 'weighted')\n",
        "        f1 = f1_score(y_test, y_classes, labels=[1], average = 'weighted')\n",
        "        conf_matrix = confusion_matrix(y_test, y_classes)\n",
        "\n",
        "        file.write(\"Accuracy: {}\\n\".format(accuracy))\n",
        "        file.write(\"Precision: {}\\n\".format(precision))\n",
        "        file.write(\"Recall: {}\\n\".format(recall))\n",
        "        file.write(\"F1 Score: {}\\n\".format(f1))\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        roc_auc = roc_auc_score(y_test, y_classes)\n",
        "        file.write(\"ROC AUC: {}\\n\".format(roc_auc))\n",
        "\n",
        "        # Plot ROC curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_classes)\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic (ROC)')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.savefig(\"ROC_Model{}.png\".format(idx + 1))  # Save ROC curve plot\n",
        "        plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOsT4DIMB35f"
      },
      "source": [
        "Integrated Gradients - on the classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb4mR4N3mhhi",
        "outputId": "1ecab155-82b8-4d51-ff20-92a3ca14f4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def integrated_gradients(input_data, model):\n",
        "    \"\"\"\n",
        "    Calculate integrated gradients for a given input_data and model\n",
        "    \"\"\"\n",
        "    # Define the baseline as all zeros\n",
        "    baseline = np.zeros_like(input_data)\n",
        "\n",
        "    # Create a linear interpolation path from baseline to the actual input\n",
        "    steps = 50\n",
        "    interpolated_points = [baseline + (i/steps) * (input_data - baseline) for i in range(steps+1)]\n",
        "\n",
        "    # Convert to numpy array\n",
        "    interpolated_points = np.array(interpolated_points)\n",
        "\n",
        "    # Convert to TensorFlow tensor\n",
        "    interpolated_points = tf.convert_to_tensor(interpolated_points, dtype=tf.float32)\n",
        "\n",
        "    # Get model predictions for the interpolated points\n",
        "    preds = model.predict(interpolated_points)\n",
        "\n",
        "    # Create a GradientTape to record operations for automatic differentiation\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_points)\n",
        "        predictions = model(interpolated_points)\n",
        "\n",
        "    # Calculate gradients with respect to input\n",
        "    gradients = tape.gradient(predictions, interpolated_points)\n",
        "\n",
        "    # Define the integrated gradients\n",
        "    integrated_grads = np.mean(gradients.numpy(), axis=0) * (input_data - baseline)\n",
        "\n",
        "    # Sum along the path to approximate the integral\n",
        "    integrated_grads = np.sum(integrated_grads, axis=1)\n",
        "\n",
        "    return integrated_grads\n",
        "\n",
        "# Example usage\n",
        "index_to_explain = 4  # Choose an index to explain\n",
        "embedding_to_explain = X_emb[index_to_explain]\n",
        "integrated_grads_result = integrated_gradients(embedding_to_explain, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "o1FqpJ0Q-5bR",
        "outputId": "3b8c6564-e35b-40f5-884d-2071d187b77b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create an array of indices to use as x-axis\n",
        "indices = np.arange(len(integrated_grads_result))\n",
        "\n",
        "# Filter out non-zero values and their corresponding indices\n",
        "non_zero_indices = [i for i, val in enumerate(integrated_grads_result) if val != 0]\n",
        "non_zero_values = [val for val in integrated_grads_result if val != 0]\n",
        "\n",
        "# Plot non-zero integrated gradients\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(non_zero_indices, non_zero_values, marker='o', linestyle='-', color='b')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Integrated Gradients (Non-zero)')\n",
        "plt.title('Non-zero Integrated Gradients for Explaining Model Prediction')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SDNE"
      ],
      "metadata": {
        "id": "-Bs0fWiRsIlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch import nn, optim\n",
        "\n",
        "# Assuming 'all_data' is already defined and contains the graph data\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, **node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, **edge_attributes)\n",
        "\n",
        "    return G, y.item()\n",
        "\n",
        "class SDNE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, alpha=1e-5, beta=5):\n",
        "        super(SDNE, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dims[1], hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # Encode\n",
        "        y = self.encoder(x)\n",
        "        # Decode\n",
        "        x_hat = self.decoder(y)\n",
        "        return x_hat, y\n",
        "\n",
        "    def loss_function(self, x, x_hat, y, adj):\n",
        "        # Reconstruction loss\n",
        "        mse = nn.MSELoss()\n",
        "        L_1st = mse(x_hat, x)\n",
        "\n",
        "        # Laplacian regularization\n",
        "        L_2nd = torch.sum(adj * torch.norm(y.unsqueeze(1) - y, dim=2))\n",
        "\n",
        "        return L_1st + self.alpha * L_1st + self.beta * L_2nd\n",
        "\n",
        "def train_sdne(graph, hidden_dims=[128, 64], epochs=100, lr=0.01):\n",
        "    # Create adjacency matrix\n",
        "    adj = nx.adjacency_matrix(graph).todense()\n",
        "    adj = torch.tensor(adj, dtype=torch.float32)\n",
        "\n",
        "    # Get node features\n",
        "    node_features = np.array([list(graph.nodes[i].values()) for i in range(graph.number_of_nodes())])\n",
        "\n",
        "    # Check if node features are empty\n",
        "    if node_features.shape[1] == 0:\n",
        "        raise ValueError(\"Node features are empty. Ensure nodes have features.\")\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    node_features = scaler.fit_transform(node_features)\n",
        "    node_features = torch.tensor(node_features, dtype=torch.float32)\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = node_features.shape[1]\n",
        "    model = SDNE(input_dim, hidden_dims)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, y = model(node_features, adj)\n",
        "        loss = model.loss_function(node_features, x_hat, y, adj)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #if (epoch + 1) % 10 == 0:\n",
        "            #print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    return model, y\n",
        "\n",
        "def balance_dataset(all_data):\n",
        "    label_0_indices = [i for i, data in enumerate(all_data) if data.y == 0]\n",
        "    label_1_indices = [i for i, data in enumerate(all_data) if data.y == 1]\n",
        "\n",
        "    min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "    random.shuffle(label_0_indices)\n",
        "    random.shuffle(label_1_indices)\n",
        "\n",
        "    label_0_indices = label_0_indices[:min_size_dataset]\n",
        "    label_1_indices = label_1_indices[:min_size_dataset]\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    balanced_indices = label_0_indices + label_1_indices\n",
        "    random.shuffle(balanced_indices)\n",
        "\n",
        "    balanced_data = [all_data[i] for i in balanced_indices]\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "# Generate and save embeddings for the balanced datasets\n",
        "if __name__ == \"__main__\":\n",
        "    all_graph_embeddings = []\n",
        "\n",
        "    for i in range(1):  # Loop to generate 5 different datasets\n",
        "        print(f'Generating dataset {i + 1}')\n",
        "        balanced_data = balance_dataset(all_data)\n",
        "\n",
        "        for data in balanced_data:\n",
        "            num_nodes = data.num_nodes\n",
        "            edge_index = data.edge_index\n",
        "            edge_attr = data.edge_attr\n",
        "            x = data.x\n",
        "            y = data.y\n",
        "\n",
        "            # Create graph\n",
        "            G, y_label = create_networkx_graph(edge_index, edge_attr, x, y, num_nodes)\n",
        "\n",
        "            # Train SDNE\n",
        "            model, embeddings = train_sdne(G, epochs=100)\n",
        "\n",
        "            # Collect node embeddings and aggregate them to obtain a graph-level embedding\n",
        "            embeddings_np = embeddings.detach().numpy()\n",
        "            graph_embedding = np.mean(embeddings_np, axis=0)  # Averaging node embeddings\n",
        "            all_graph_embeddings.append((graph_embedding.tolist(), y_label))\n",
        "\n",
        "    # Convert graph-level embeddings to DataFrame\n",
        "    df_graph_embeddings = pd.DataFrame(all_graph_embeddings, columns=[\"embedding\", \"label\"])\n",
        "\n",
        "    # Save the DataFrame to a CSV file (optional)\n",
        "    df_graph_embeddings.to_csv(\"graph_embeddings.csv\", index=False)\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df_graph_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxLnsdjK-Y2p",
        "outputId": "fb85988c-5635-4393-d742-9b3ff27fb51f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset 1\n",
            "112\n",
            "112\n",
            "                                             embedding  label\n",
            "0    [0.0639788806438446, 0.06521560251712799, 0.03...      1\n",
            "1    [-0.13483938574790955, -0.1800384223461151, -0...      1\n",
            "2    [0.08756901323795319, 0.06761772185564041, -0....      0\n",
            "3    [0.01694951206445694, -0.05306106433272362, 0....      1\n",
            "4    [-0.04527962580323219, 0.006519967690110207, 0...      0\n",
            "..                                                 ...    ...\n",
            "219  [0.06213023141026497, 0.07088954746723175, -0....      0\n",
            "220  [0.07343877106904984, 0.015459422022104263, 0....      1\n",
            "221  [-0.07301987707614899, -0.035584867000579834, ...      1\n",
            "222  [-0.042404189705848694, -0.005982905626296997,...      0\n",
            "223  [-0.11298348754644394, -0.04112539440393448, 0...      0\n",
            "\n",
            "[224 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_graph_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-07XH-30TkTh",
        "outputId": "6da0ccdf-d54c-4a56-dedf-01206bfd2e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              embedding  label\n",
              "0     [0.012872357852756977, 0.036167778074741364, 0...      1\n",
              "1     [0.02220860868692398, -0.0034232004545629025, ...      1\n",
              "2     [-0.034402377903461456, 0.03993811085820198, 0...      0\n",
              "3     [0.03250516951084137, -0.041709255427122116, 0...      1\n",
              "4     [0.0890597328543663, -0.018752433359622955, 0....      1\n",
              "...                                                 ...    ...\n",
              "2881  [-0.07019953429698944, 0.03325891122221947, 0....      0\n",
              "2882  [0.007876122370362282, 0.04717765375971794, 0....      1\n",
              "2883  [-0.11123344302177429, 0.02893875353038311, -0...      0\n",
              "2884  [-0.000383681443054229, -0.043122611939907074,...      1\n",
              "2885  [0.049928534775972366, -0.03744585067033768, -...      0\n",
              "\n",
              "[2886 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c053596-ad0c-4b57-b6af-476571d3179a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embedding</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.012872357852756977, 0.036167778074741364, 0...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.02220860868692398, -0.0034232004545629025, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.034402377903461456, 0.03993811085820198, 0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.03250516951084137, -0.041709255427122116, 0...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.0890597328543663, -0.018752433359622955, 0....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2881</th>\n",
              "      <td>[-0.07019953429698944, 0.03325891122221947, 0....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2882</th>\n",
              "      <td>[0.007876122370362282, 0.04717765375971794, 0....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2883</th>\n",
              "      <td>[-0.11123344302177429, 0.02893875353038311, -0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2884</th>\n",
              "      <td>[-0.000383681443054229, -0.043122611939907074,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885</th>\n",
              "      <td>[0.049928534775972366, -0.03744585067033768, -...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2886 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c053596-ad0c-4b57-b6af-476571d3179a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c053596-ad0c-4b57-b6af-476571d3179a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c053596-ad0c-4b57-b6af-476571d3179a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e573a062-bab1-4d84-ab47-6d0c9a91a315\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e573a062-bab1-4d84-ab47-6d0c9a91a315')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e573a062-bab1-4d84-ab47-6d0c9a91a315 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ba8ef02c-a0c1-4783-a174-2db693a7dc6a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_graph_embeddings')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba8ef02c-a0c1-4783-a174-2db693a7dc6a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_graph_embeddings');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_graph_embeddings",
              "summary": "{\n  \"name\": \"df_graph_embeddings\",\n  \"rows\": 2886,\n  \"fields\": [\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import ast\n",
        "\n",
        "# Load the balanced dataset\n",
        "df_graph_embeddings = pd.read_csv(\"graph_embeddings.csv\")\n",
        "\n",
        "# Extract features and labels\n",
        "def extract_features_labels(df):\n",
        "    embeddings = []\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    for emb in df['embedding']:\n",
        "        if isinstance(emb, str):\n",
        "            # Convert string representation of list back to list\n",
        "            emb = ast.literal_eval(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n",
        "\n",
        "X, y = extract_features_labels(df_graph_embeddings)\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "    raise ValueError(\"No valid embeddings found. Please check the DataFrame for formatting issues.\")\n",
        "\n",
        "# Define the neural network model\n",
        "def create_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Perform 5-fold cross-validation on the entire dataset\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "roc_aucs = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "histories = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f'Fold {fold_no}')\n",
        "\n",
        "    X_train_val, X_test = X[train_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Perform an additional split to get a validation set from the training+validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Create and train the neural network\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = create_model(input_dim)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy:.4f}')\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    histories.append(history.history)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Fold {fold_no} Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Predict probabilities and calculate metrics for the test set\n",
        "    y_test_pred_proba = model.predict(X_test).flatten()\n",
        "    y_test_pred = (y_test_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f'Fold {fold_no} ROC-AUC: {roc_auc:.4f}')\n",
        "    print(f'Fold {fold_no} Precision: {precision:.4f}')\n",
        "    print(f'Fold {fold_no} Recall: {recall:.4f}')\n",
        "    print(f'Fold {fold_no} F1-Score: {f1:.4f}')\n",
        "\n",
        "    roc_aucs.append(roc_auc)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Calculate and print the average validation accuracy and variance\n",
        "average_val_accuracy = np.mean(val_accuracies)\n",
        "variance_val_accuracy = np.var(val_accuracies)\n",
        "print(f'Average Validation Accuracy: {average_val_accuracy:.4f}')\n",
        "print(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}')\n",
        "\n",
        "# Calculate and print the average test accuracy and variance\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "variance_test_accuracy = np.var(test_accuracies)\n",
        "print(f'Average Test Accuracy: {average_test_accuracy:.4f}')\n",
        "print(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}')\n",
        "\n",
        "# Calculate and print the average ROC-AUC, Precision, Recall, and F1-Score\n",
        "average_roc_auc = np.mean(roc_aucs)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recall = np.mean(recalls)\n",
        "average_f1_score = np.mean(f1_scores)\n",
        "\n",
        "print(f'Average ROC-AUC: {average_roc_auc:.4f}')\n",
        "print(f'Average Precision: {average_precision:.4f}')\n",
        "print(f'Average Recall: {average_recall:.4f}')\n",
        "print(f'Average F1-Score: {average_f1_score:.4f}')\n",
        "\n",
        "# Save the average validation accuracy, variance, test accuracy, and metrics to a file\n",
        "with open(\"model_accuracies.txt\", \"w\") as f:\n",
        "    f.write(f'Average Validation Accuracy: {average_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Average Test Accuracy: {average_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Average ROC-AUC: {average_roc_auc:.4f}\\n')\n",
        "    f.write(f'Average Precision: {average_precision:.4f}\\n')\n",
        "    f.write(f'Average Recall: {average_recall:.4f}\\n')\n",
        "    f.write(f'Average F1-Score: {average_f1_score:.4f}\\n')\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Save training history for each fold (optional)\n",
        "with open(\"training_histories.txt\", \"w\") as f:\n",
        "    for i, history in enumerate(histories):\n",
        "        f.write(f'\\nFold {i + 1} History:\\n')\n",
        "        f.write(str(history))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAqVMiFSQA_I",
        "outputId": "232cdf63-dbdd-4a26-b803-8f1a63c2507c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 153ms/step - loss: 0.6947 - accuracy: 0.5035 - val_loss: 0.6927 - val_accuracy: 0.5556\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.6947 - accuracy: 0.4615 - val_loss: 0.6924 - val_accuracy: 0.5833\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.6934 - accuracy: 0.4685 - val_loss: 0.6925 - val_accuracy: 0.5833\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.6934 - accuracy: 0.4895 - val_loss: 0.6929 - val_accuracy: 0.5278\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.6884 - accuracy: 0.5594 - val_loss: 0.6931 - val_accuracy: 0.5556\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.6893 - accuracy: 0.5804 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6844 - accuracy: 0.6084 - val_loss: 0.6937 - val_accuracy: 0.5278\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.6872 - accuracy: 0.5524 - val_loss: 0.6946 - val_accuracy: 0.5278\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.6854 - accuracy: 0.5455 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.6871 - accuracy: 0.5734 - val_loss: 0.6963 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.6770 - accuracy: 0.6434 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.6801 - accuracy: 0.6434 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.6737 - accuracy: 0.6084 - val_loss: 0.7008 - val_accuracy: 0.5278\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6688 - accuracy: 0.6503 - val_loss: 0.7032 - val_accuracy: 0.5278\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.6697 - accuracy: 0.6154 - val_loss: 0.7060 - val_accuracy: 0.4722\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6634 - accuracy: 0.5804 - val_loss: 0.7101 - val_accuracy: 0.4722\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6564 - accuracy: 0.6783 - val_loss: 0.7155 - val_accuracy: 0.4444\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.6368 - accuracy: 0.7622 - val_loss: 0.7227 - val_accuracy: 0.4444\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6402 - accuracy: 0.7063 - val_loss: 0.7312 - val_accuracy: 0.4722\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.6008 - accuracy: 0.8392 - val_loss: 0.7428 - val_accuracy: 0.3611\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.6014 - accuracy: 0.7552 - val_loss: 0.7573 - val_accuracy: 0.4167\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5781 - accuracy: 0.7413 - val_loss: 0.7733 - val_accuracy: 0.3889\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5638 - accuracy: 0.7692 - val_loss: 0.7923 - val_accuracy: 0.3333\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.5359 - accuracy: 0.8182 - val_loss: 0.8154 - val_accuracy: 0.3056\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.4975 - accuracy: 0.8531 - val_loss: 0.8428 - val_accuracy: 0.3611\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.4866 - accuracy: 0.8182 - val_loss: 0.8770 - val_accuracy: 0.3889\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4471 - accuracy: 0.8671 - val_loss: 0.9234 - val_accuracy: 0.3889\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.4047 - accuracy: 0.8531 - val_loss: 0.9786 - val_accuracy: 0.3611\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.3654 - accuracy: 0.9161 - val_loss: 1.0372 - val_accuracy: 0.3333\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.3569 - accuracy: 0.8951 - val_loss: 1.0958 - val_accuracy: 0.3611\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.3473 - accuracy: 0.9091 - val_loss: 1.1625 - val_accuracy: 0.3611\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2428 - accuracy: 0.9371 - val_loss: 1.2449 - val_accuracy: 0.3056\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2751 - accuracy: 0.9231 - val_loss: 1.3073 - val_accuracy: 0.3611\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.2364 - accuracy: 0.9580 - val_loss: 1.3698 - val_accuracy: 0.3889\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2137 - accuracy: 0.9441 - val_loss: 1.4546 - val_accuracy: 0.3056\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1610 - accuracy: 0.9650 - val_loss: 1.5267 - val_accuracy: 0.3056\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1905 - accuracy: 0.9510 - val_loss: 1.5869 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.1443 - accuracy: 0.9650 - val_loss: 1.6390 - val_accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1237 - accuracy: 0.9860 - val_loss: 1.7132 - val_accuracy: 0.3611\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.1132 - accuracy: 0.9790 - val_loss: 1.7799 - val_accuracy: 0.3611\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1026 - accuracy: 0.9720 - val_loss: 1.8467 - val_accuracy: 0.3333\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0898 - accuracy: 0.9860 - val_loss: 1.9084 - val_accuracy: 0.3333\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0865 - accuracy: 0.9790 - val_loss: 1.9573 - val_accuracy: 0.3333\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1038 - accuracy: 0.9720 - val_loss: 2.0062 - val_accuracy: 0.3333\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0651 - accuracy: 0.9930 - val_loss: 2.0603 - val_accuracy: 0.3611\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0671 - accuracy: 0.9860 - val_loss: 2.1097 - val_accuracy: 0.3333\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 2.1673 - val_accuracy: 0.3889\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 2.2351 - val_accuracy: 0.3333\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 2.3058 - val_accuracy: 0.3889\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 2.3582 - val_accuracy: 0.3889\n",
            "Fold 1 Validation Accuracy: 0.3889\n",
            "Fold 1 Test Accuracy: 0.6000\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Fold 1 ROC-AUC: 0.6720\n",
            "Fold 1 Precision: 0.5500\n",
            "Fold 1 Recall: 0.5500\n",
            "Fold 1 F1-Score: 0.5500\n",
            "Fold 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 80ms/step - loss: 0.6964 - accuracy: 0.4336 - val_loss: 0.6915 - val_accuracy: 0.5278\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6927 - accuracy: 0.5315 - val_loss: 0.6914 - val_accuracy: 0.5833\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6893 - accuracy: 0.5315 - val_loss: 0.6916 - val_accuracy: 0.5833\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6903 - accuracy: 0.5524 - val_loss: 0.6923 - val_accuracy: 0.4722\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6891 - accuracy: 0.5664 - val_loss: 0.6931 - val_accuracy: 0.4722\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6801 - accuracy: 0.6713 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6831 - accuracy: 0.6154 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6789 - accuracy: 0.6993 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6742 - accuracy: 0.6923 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6634 - accuracy: 0.7273 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.6993 - val_loss: 0.6988 - val_accuracy: 0.4722\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6503 - accuracy: 0.7483 - val_loss: 0.7018 - val_accuracy: 0.4722\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6480 - accuracy: 0.7343 - val_loss: 0.7056 - val_accuracy: 0.4722\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6440 - accuracy: 0.7413 - val_loss: 0.7100 - val_accuracy: 0.4722\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6316 - accuracy: 0.7133 - val_loss: 0.7150 - val_accuracy: 0.4167\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5941 - accuracy: 0.8182 - val_loss: 0.7224 - val_accuracy: 0.4722\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5935 - accuracy: 0.7413 - val_loss: 0.7308 - val_accuracy: 0.4722\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5732 - accuracy: 0.8112 - val_loss: 0.7422 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5562 - accuracy: 0.8392 - val_loss: 0.7569 - val_accuracy: 0.4722\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5151 - accuracy: 0.8392 - val_loss: 0.7778 - val_accuracy: 0.4444\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5038 - accuracy: 0.8601 - val_loss: 0.8005 - val_accuracy: 0.4444\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4707 - accuracy: 0.8392 - val_loss: 0.8313 - val_accuracy: 0.4444\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4668 - accuracy: 0.8392 - val_loss: 0.8676 - val_accuracy: 0.4444\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4403 - accuracy: 0.8252 - val_loss: 0.9073 - val_accuracy: 0.4722\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3984 - accuracy: 0.8531 - val_loss: 0.9537 - val_accuracy: 0.4444\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3516 - accuracy: 0.8881 - val_loss: 1.0030 - val_accuracy: 0.4444\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3312 - accuracy: 0.8951 - val_loss: 1.0442 - val_accuracy: 0.4722\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3460 - accuracy: 0.8811 - val_loss: 1.0983 - val_accuracy: 0.4444\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2926 - accuracy: 0.9231 - val_loss: 1.1656 - val_accuracy: 0.4444\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2595 - accuracy: 0.9231 - val_loss: 1.2149 - val_accuracy: 0.4444\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2317 - accuracy: 0.9441 - val_loss: 1.2599 - val_accuracy: 0.4444\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2110 - accuracy: 0.9301 - val_loss: 1.3207 - val_accuracy: 0.4444\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2028 - accuracy: 0.9371 - val_loss: 1.3746 - val_accuracy: 0.4444\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1986 - accuracy: 0.9650 - val_loss: 1.4461 - val_accuracy: 0.4444\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1398 - accuracy: 0.9720 - val_loss: 1.5094 - val_accuracy: 0.4444\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1306 - accuracy: 0.9650 - val_loss: 1.5551 - val_accuracy: 0.4444\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1301 - accuracy: 0.9720 - val_loss: 1.5968 - val_accuracy: 0.4444\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.6428 - val_accuracy: 0.4444\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1082 - accuracy: 0.9790 - val_loss: 1.6912 - val_accuracy: 0.4444\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0819 - accuracy: 0.9860 - val_loss: 1.7515 - val_accuracy: 0.4722\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 1.8151 - val_accuracy: 0.4444\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 1.8706 - val_accuracy: 0.4722\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0733 - accuracy: 0.9790 - val_loss: 1.9313 - val_accuracy: 0.4722\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0769 - accuracy: 0.9860 - val_loss: 1.9844 - val_accuracy: 0.4444\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0738 - accuracy: 0.9790 - val_loss: 2.0510 - val_accuracy: 0.4722\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0597 - accuracy: 0.9860 - val_loss: 2.0766 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0559 - accuracy: 0.9930 - val_loss: 2.0795 - val_accuracy: 0.4444\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0635 - accuracy: 0.9790 - val_loss: 2.1172 - val_accuracy: 0.4722\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 2.1561 - val_accuracy: 0.4722\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0367 - accuracy: 0.9930 - val_loss: 2.1594 - val_accuracy: 0.4722\n",
            "Fold 2 Validation Accuracy: 0.4722\n",
            "Fold 2 Test Accuracy: 0.4889\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "Fold 2 ROC-AUC: 0.5179\n",
            "Fold 2 Precision: 0.4667\n",
            "Fold 2 Recall: 0.6667\n",
            "Fold 2 F1-Score: 0.5490\n",
            "Fold 3\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 112ms/step - loss: 0.6923 - accuracy: 0.4895 - val_loss: 0.6924 - val_accuracy: 0.5278\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6901 - accuracy: 0.5664 - val_loss: 0.6924 - val_accuracy: 0.5556\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6891 - accuracy: 0.5524 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6848 - accuracy: 0.6643 - val_loss: 0.6926 - val_accuracy: 0.5556\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6819 - accuracy: 0.6084 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.6838 - accuracy: 0.6084 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6793 - accuracy: 0.6224 - val_loss: 0.6945 - val_accuracy: 0.5278\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6770 - accuracy: 0.6503 - val_loss: 0.6946 - val_accuracy: 0.4722\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6741 - accuracy: 0.6713 - val_loss: 0.6949 - val_accuracy: 0.4444\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6708 - accuracy: 0.6853 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6602 - accuracy: 0.7063 - val_loss: 0.6971 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6514 - accuracy: 0.7133 - val_loss: 0.6996 - val_accuracy: 0.4444\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6568 - accuracy: 0.6573 - val_loss: 0.7026 - val_accuracy: 0.4444\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.6310 - accuracy: 0.7762 - val_loss: 0.7062 - val_accuracy: 0.4444\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6206 - accuracy: 0.7692 - val_loss: 0.7108 - val_accuracy: 0.4722\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5927 - accuracy: 0.8392 - val_loss: 0.7164 - val_accuracy: 0.4722\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5958 - accuracy: 0.7902 - val_loss: 0.7269 - val_accuracy: 0.4722\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5632 - accuracy: 0.7972 - val_loss: 0.7364 - val_accuracy: 0.4444\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5431 - accuracy: 0.8392 - val_loss: 0.7518 - val_accuracy: 0.4444\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5177 - accuracy: 0.7832 - val_loss: 0.7724 - val_accuracy: 0.4444\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4780 - accuracy: 0.8392 - val_loss: 0.7946 - val_accuracy: 0.4722\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4542 - accuracy: 0.8252 - val_loss: 0.8276 - val_accuracy: 0.4722\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4361 - accuracy: 0.8601 - val_loss: 0.8640 - val_accuracy: 0.4722\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4043 - accuracy: 0.8671 - val_loss: 0.8968 - val_accuracy: 0.4722\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3639 - accuracy: 0.8811 - val_loss: 0.9264 - val_accuracy: 0.4722\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3493 - accuracy: 0.8811 - val_loss: 0.9631 - val_accuracy: 0.4444\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3038 - accuracy: 0.9091 - val_loss: 0.9937 - val_accuracy: 0.4444\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2620 - accuracy: 0.9161 - val_loss: 1.0249 - val_accuracy: 0.4444\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2825 - accuracy: 0.8881 - val_loss: 1.0462 - val_accuracy: 0.4444\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2675 - accuracy: 0.9161 - val_loss: 1.0680 - val_accuracy: 0.4167\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2169 - accuracy: 0.9441 - val_loss: 1.1171 - val_accuracy: 0.4722\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2069 - accuracy: 0.9580 - val_loss: 1.1414 - val_accuracy: 0.4722\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1649 - accuracy: 0.9650 - val_loss: 1.1689 - val_accuracy: 0.4167\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1415 - accuracy: 0.9930 - val_loss: 1.2093 - val_accuracy: 0.3889\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1594 - accuracy: 0.9650 - val_loss: 1.2603 - val_accuracy: 0.3611\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1263 - accuracy: 0.9720 - val_loss: 1.3228 - val_accuracy: 0.4722\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1293 - accuracy: 0.9720 - val_loss: 1.3760 - val_accuracy: 0.4722\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1102 - accuracy: 0.9790 - val_loss: 1.4004 - val_accuracy: 0.4444\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0938 - accuracy: 0.9860 - val_loss: 1.4375 - val_accuracy: 0.3889\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0702 - accuracy: 0.9860 - val_loss: 1.4846 - val_accuracy: 0.3889\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1054 - accuracy: 0.9650 - val_loss: 1.5241 - val_accuracy: 0.3889\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0629 - accuracy: 0.9930 - val_loss: 1.5650 - val_accuracy: 0.4167\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0516 - accuracy: 0.9930 - val_loss: 1.5938 - val_accuracy: 0.4167\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0602 - accuracy: 0.9930 - val_loss: 1.6291 - val_accuracy: 0.4167\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0686 - accuracy: 0.9790 - val_loss: 1.6545 - val_accuracy: 0.4444\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 1.6928 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0451 - accuracy: 0.9930 - val_loss: 1.7265 - val_accuracy: 0.3611\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0453 - accuracy: 0.9930 - val_loss: 1.7746 - val_accuracy: 0.3611\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0381 - accuracy: 0.9930 - val_loss: 1.8436 - val_accuracy: 0.3611\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0496 - accuracy: 0.9860 - val_loss: 1.8879 - val_accuracy: 0.4444\n",
            "Fold 3 Validation Accuracy: 0.4444\n",
            "Fold 3 Test Accuracy: 0.5778\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Fold 3 ROC-AUC: 0.6107\n",
            "Fold 3 Precision: 0.5714\n",
            "Fold 3 Recall: 0.6957\n",
            "Fold 3 F1-Score: 0.6275\n",
            "Fold 4\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 81ms/step - loss: 0.6929 - accuracy: 0.5105 - val_loss: 0.6909 - val_accuracy: 0.5556\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6907 - accuracy: 0.5594 - val_loss: 0.6903 - val_accuracy: 0.6111\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6890 - accuracy: 0.6014 - val_loss: 0.6901 - val_accuracy: 0.5833\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6909 - accuracy: 0.5594 - val_loss: 0.6899 - val_accuracy: 0.5556\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6863 - accuracy: 0.5524 - val_loss: 0.6894 - val_accuracy: 0.5833\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6875 - accuracy: 0.5804 - val_loss: 0.6892 - val_accuracy: 0.5556\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6826 - accuracy: 0.6224 - val_loss: 0.6888 - val_accuracy: 0.5833\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6797 - accuracy: 0.6294 - val_loss: 0.6887 - val_accuracy: 0.5556\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6790 - accuracy: 0.6713 - val_loss: 0.6889 - val_accuracy: 0.5556\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6819 - accuracy: 0.6364 - val_loss: 0.6889 - val_accuracy: 0.5556\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6687 - accuracy: 0.6853 - val_loss: 0.6888 - val_accuracy: 0.5556\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6622 - accuracy: 0.7063 - val_loss: 0.6888 - val_accuracy: 0.5833\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6578 - accuracy: 0.7273 - val_loss: 0.6894 - val_accuracy: 0.5556\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6397 - accuracy: 0.8182 - val_loss: 0.6900 - val_accuracy: 0.5278\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6413 - accuracy: 0.7832 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.6313 - accuracy: 0.7133 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6129 - accuracy: 0.8392 - val_loss: 0.6948 - val_accuracy: 0.4444\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5971 - accuracy: 0.7832 - val_loss: 0.6984 - val_accuracy: 0.4444\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5885 - accuracy: 0.7972 - val_loss: 0.7041 - val_accuracy: 0.5278\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5531 - accuracy: 0.8392 - val_loss: 0.7104 - val_accuracy: 0.5278\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5481 - accuracy: 0.8322 - val_loss: 0.7212 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5208 - accuracy: 0.8252 - val_loss: 0.7330 - val_accuracy: 0.4722\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4613 - accuracy: 0.8741 - val_loss: 0.7501 - val_accuracy: 0.4722\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.4474 - accuracy: 0.8671 - val_loss: 0.7671 - val_accuracy: 0.4722\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4316 - accuracy: 0.8531 - val_loss: 0.7875 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.3812 - accuracy: 0.8881 - val_loss: 0.8084 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.3553 - accuracy: 0.9021 - val_loss: 0.8351 - val_accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.3514 - accuracy: 0.8951 - val_loss: 0.8640 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.3166 - accuracy: 0.9021 - val_loss: 0.8856 - val_accuracy: 0.5556\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.2860 - accuracy: 0.9161 - val_loss: 0.9171 - val_accuracy: 0.5278\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2571 - accuracy: 0.9091 - val_loss: 0.9451 - val_accuracy: 0.5278\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.2458 - accuracy: 0.9441 - val_loss: 0.9742 - val_accuracy: 0.5278\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.2185 - accuracy: 0.9441 - val_loss: 0.9946 - val_accuracy: 0.5556\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.1857 - accuracy: 0.9720 - val_loss: 1.0199 - val_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.1777 - accuracy: 0.9580 - val_loss: 1.0363 - val_accuracy: 0.5278\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1459 - accuracy: 0.9720 - val_loss: 1.0612 - val_accuracy: 0.5278\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.1213 - accuracy: 0.9790 - val_loss: 1.1137 - val_accuracy: 0.4722\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1181 - accuracy: 0.9720 - val_loss: 1.1765 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1101 - accuracy: 0.9720 - val_loss: 1.1566 - val_accuracy: 0.5556\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.0743 - accuracy: 0.9930 - val_loss: 1.1539 - val_accuracy: 0.5278\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0611 - accuracy: 0.9930 - val_loss: 1.1926 - val_accuracy: 0.5278\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0807 - accuracy: 0.9790 - val_loss: 1.2844 - val_accuracy: 0.5556\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0625 - accuracy: 0.9930 - val_loss: 1.4009 - val_accuracy: 0.5278\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 1.4054 - val_accuracy: 0.5278\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0520 - accuracy: 0.9930 - val_loss: 1.3658 - val_accuracy: 0.5556\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 1.3565 - val_accuracy: 0.5556\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.5556\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 1.4218 - val_accuracy: 0.5556\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 1.4858 - val_accuracy: 0.5556\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.5276 - val_accuracy: 0.5556\n",
            "Fold 4 Validation Accuracy: 0.5556\n",
            "Fold 4 Test Accuracy: 0.5111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79706fd8fe20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "Fold 4 ROC-AUC: 0.5120\n",
            "Fold 4 Precision: 0.5882\n",
            "Fold 4 Recall: 0.4000\n",
            "Fold 4 F1-Score: 0.4762\n",
            "Fold 5\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 3s 101ms/step - loss: 0.6930 - accuracy: 0.5069 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6942 - accuracy: 0.4722 - val_loss: 0.6960 - val_accuracy: 0.4444\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6924 - accuracy: 0.5278 - val_loss: 0.6958 - val_accuracy: 0.4167\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6911 - accuracy: 0.5278 - val_loss: 0.6958 - val_accuracy: 0.5278\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6886 - accuracy: 0.6111 - val_loss: 0.6957 - val_accuracy: 0.5278\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6925 - accuracy: 0.5833 - val_loss: 0.6959 - val_accuracy: 0.5278\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6858 - accuracy: 0.6042 - val_loss: 0.6960 - val_accuracy: 0.5556\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6825 - accuracy: 0.6458 - val_loss: 0.6958 - val_accuracy: 0.6111\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6796 - accuracy: 0.6875 - val_loss: 0.6957 - val_accuracy: 0.5833\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6819 - accuracy: 0.6181 - val_loss: 0.6956 - val_accuracy: 0.5556\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.6770 - accuracy: 0.6806 - val_loss: 0.6949 - val_accuracy: 0.5556\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6741 - accuracy: 0.6458 - val_loss: 0.6941 - val_accuracy: 0.6111\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6778 - accuracy: 0.6528 - val_loss: 0.6934 - val_accuracy: 0.5278\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6631 - accuracy: 0.7222 - val_loss: 0.6932 - val_accuracy: 0.5278\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6695 - accuracy: 0.6944 - val_loss: 0.6918 - val_accuracy: 0.5278\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6549 - accuracy: 0.7569 - val_loss: 0.6902 - val_accuracy: 0.4722\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6421 - accuracy: 0.7986 - val_loss: 0.6886 - val_accuracy: 0.4722\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6439 - accuracy: 0.7292 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.6183 - accuracy: 0.7986 - val_loss: 0.6851 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.5987 - accuracy: 0.8125 - val_loss: 0.6833 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.5852 - accuracy: 0.7986 - val_loss: 0.6794 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.5631 - accuracy: 0.7847 - val_loss: 0.6758 - val_accuracy: 0.5278\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.5573 - accuracy: 0.7639 - val_loss: 0.6736 - val_accuracy: 0.5278\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.5262 - accuracy: 0.8333 - val_loss: 0.6746 - val_accuracy: 0.5556\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.5009 - accuracy: 0.8194 - val_loss: 0.6793 - val_accuracy: 0.5556\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.4517 - accuracy: 0.8611 - val_loss: 0.6756 - val_accuracy: 0.5833\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.6793 - val_accuracy: 0.5833\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.4073 - accuracy: 0.8750 - val_loss: 0.6933 - val_accuracy: 0.6111\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.3660 - accuracy: 0.8611 - val_loss: 0.7041 - val_accuracy: 0.6389\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.3329 - accuracy: 0.9097 - val_loss: 0.7212 - val_accuracy: 0.6389\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2953 - accuracy: 0.9236 - val_loss: 0.7458 - val_accuracy: 0.6389\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2545 - accuracy: 0.9306 - val_loss: 0.7800 - val_accuracy: 0.6389\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.2571 - accuracy: 0.9306 - val_loss: 0.8145 - val_accuracy: 0.6389\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.2392 - accuracy: 0.9375 - val_loss: 0.8429 - val_accuracy: 0.6389\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.1997 - accuracy: 0.9583 - val_loss: 0.8764 - val_accuracy: 0.6389\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1927 - accuracy: 0.9514 - val_loss: 0.9079 - val_accuracy: 0.5833\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.1809 - accuracy: 0.9653 - val_loss: 0.9336 - val_accuracy: 0.5833\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.1331 - accuracy: 0.9792 - val_loss: 0.9729 - val_accuracy: 0.5833\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.1353 - accuracy: 0.9861 - val_loss: 1.0148 - val_accuracy: 0.6111\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.1272 - accuracy: 0.9792 - val_loss: 1.0588 - val_accuracy: 0.5833\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1365 - accuracy: 0.9653 - val_loss: 1.0917 - val_accuracy: 0.5833\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1294 - accuracy: 0.9861 - val_loss: 1.1194 - val_accuracy: 0.5833\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.1005 - accuracy: 0.9792 - val_loss: 1.1358 - val_accuracy: 0.6111\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1100 - accuracy: 0.9861 - val_loss: 1.1798 - val_accuracy: 0.6111\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.0744 - accuracy: 0.9861 - val_loss: 1.2126 - val_accuracy: 0.6111\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.0808 - accuracy: 0.9931 - val_loss: 1.2441 - val_accuracy: 0.6111\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0685 - accuracy: 0.9931 - val_loss: 1.2868 - val_accuracy: 0.6111\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0804 - accuracy: 0.9792 - val_loss: 1.3448 - val_accuracy: 0.5833\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.0848 - accuracy: 0.9792 - val_loss: 1.3648 - val_accuracy: 0.5833\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0631 - accuracy: 0.9861 - val_loss: 1.4036 - val_accuracy: 0.6667\n",
            "Fold 5 Validation Accuracy: 0.6667\n",
            "Fold 5 Test Accuracy: 0.5227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79706fd8c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 15ms/step\n",
            "Fold 5 ROC-AUC: 0.5776\n",
            "Fold 5 Precision: 0.5500\n",
            "Fold 5 Recall: 0.4783\n",
            "Fold 5 F1-Score: 0.5116\n",
            "Average Validation Accuracy: 0.5056\n",
            "Variance of Validation Accuracy: 0.0094\n",
            "Average Test Accuracy: 0.5401\n",
            "Variance of Test Accuracy: 0.0018\n",
            "Average ROC-AUC: 0.5780\n",
            "Average Precision: 0.5453\n",
            "Average Recall: 0.5581\n",
            "Average F1-Score: 0.5429\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18689 (73.00 KB)\n",
            "Trainable params: 18689 (73.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the balanced dataset\n",
        "#df_embeddings = pd.read_csv(\"sdne_embeddings.csv\")\n",
        "\n",
        "# Extract features and labels\n",
        "def extract_features_labels(df):\n",
        "    embeddings = []\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    for emb in df['embedding']:\n",
        "        if isinstance(emb, str):\n",
        "            emb = ast.literal_eval(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n",
        "\n",
        "X, y = extract_features_labels(df_graph_embeddings)\n",
        "\n",
        "# Split the dataset into train, validation, and test sets (60% train, 20% validation, 20% test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Load the trained model\n",
        "model = keras.models.load_model(\"node_classification_model_final.h5\")\n",
        "\n",
        "# Integrated Gradients function\n",
        "def integrated_gradients(inputs, model, baseline=None, steps=50):\n",
        "    if baseline is None:\n",
        "        baseline = np.zeros(inputs.shape)\n",
        "\n",
        "    # Scale inputs and compute gradients\n",
        "    scaled_inputs = np.array([baseline + (float(i) / steps) * (inputs - baseline) for i in range(steps + 1)], dtype=np.float32)\n",
        "    grads = np.zeros_like(inputs, dtype=np.float32)\n",
        "\n",
        "    for i, input_batch in enumerate(scaled_inputs):\n",
        "        input_batch_tensor = tf.convert_to_tensor(input_batch, dtype=tf.float32)\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(input_batch_tensor)\n",
        "            predictions = model(input_batch_tensor)\n",
        "            loss = tf.reduce_sum(predictions, axis=0)\n",
        "        grads += tape.gradient(loss, input_batch_tensor).numpy()\n",
        "\n",
        "    integrated_grads = (inputs - baseline) * grads / steps\n",
        "    return integrated_grads\n",
        "\n",
        "# Example usage of Integrated Gradients\n",
        "index_to_explain = 0  # Choose an index to explain\n",
        "embedding_to_explain = X_test[index_to_explain:index_to_explain+1]\n",
        "\n",
        "integrated_grads_result = integrated_gradients(embedding_to_explain, model)\n",
        "\n",
        "# Visualize the Integrated Gradients\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(integrated_grads_result[0])), integrated_grads_result[0], color='b')\n",
        "plt.xlabel(\"Node Features\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Integrated Gradients - Node Feature Importance\")\n",
        "plt.show()\n",
        "\n",
        "# Save Integrated Gradients to a file\n",
        "np.savetxt(\"integrated_gradients.csv\", integrated_grads_result, delimiter=\",\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wZHLfs8AOpHp",
        "outputId": "a4984e1b-8781-4202-8342-fea96a033c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAIjCAYAAABh3KjvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVwElEQVR4nO3deVwVZf//8fdhEVBZJEHc9w21NDQi15TEtMUWTaMUM63ccmnRyq0NbTW9y6VFyyxLy+6stLgzrZTUTLNMzcrcAQ0BkUSW6/eHP87XI6sIAwdez8djHsXMNXM+M3MOnjfXzDU2Y4wRAAAAAMAyLmVdAAAAAABUNgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAKCN///23bDablixZUtalXJQZM2bIZrM5zGvUqJGioqLKpqAKasmSJbLZbPr777/LuhQAQCkgiAG4aDlfEH/88ceLXjctLU0zZszQ+vXrS76wUvLaa6+Vi7CUkJCgyZMnq127dqpevbo8PT3VrFkzDRs2TN9//31Zl1fqvvjiC82YMaPMXr9Ro0ay2WwaO3ZsrmXr16+XzWbTypUry6CyosmpMa9p0KBBpfKav/32m2bMmFEuw6QznLPCvPfee5ozZ05ZlwGgmNzKugAAlUtaWppmzpwpSerRo0fZFlNEr732mmrWrFmmPT5btmxRv379dOrUKQ0aNEj333+/PDw8tH//fn3yySdasmSJNmzYoG7dupVJfXv37pWLS+n+be+LL77Qq6++WqZhTJJef/11TZkyRXXq1CnTOopr3Lhx6tSpk8O8Ro0alcpr/fbbb5o5c6Z69OhRaq9Rmb333nv69ddfNX78+LIuBUAxEMQAVCrGGJ05c0ZeXl5lXUqRnTx5Uv3795ebm5t27NihVq1aOSx/+umntXz58kL36fTp06pWrVqp1Ojh4VEq2y1v2rRpo71792rWrFmaO3duWZdTLF27dtXtt99e1mVcktJ8LzuDyr7/QEXBpYkASkRUVJSqV6+uI0eOqH///qpevboCAgL00EMPKSsrS9K5e6ICAgIkSTNnzrRfFnV+D8eePXt0++23y9/fX56enurYsaM+/fTTXK+3c+dOde/eXV5eXqpXr56efvppLV68ONc9NY0aNdINN9ygL7/8Uh07dpSXl5cWLlwoSVq8eLF69uypwMBAeXh4KDg4WPPnz3d4nUaNGmnXrl3asGGDvd7ze/KSkpI0fvx41a9fXx4eHmrWrJlmz56t7Oxsh+0kJSUpKipKvr6+8vPz09ChQ5WUlFSkY7tgwQIdO3ZMc+bMyRXCJMlms2nw4MEOvRw593H99ttvuvPOO1WjRg116dLFfuyioqLUpEkTeXp6KigoSPfcc4/++eefXNv+/vvv1alTJ3l6eqpp06b2Y3ehvO4RK8qxyblP7oUXXtCiRYvUtGlTeXh4qFOnTtq6dau9XVRUlF599VX7/uZMOZYvX66QkBB5e3vLx8dH7dq10yuvvFKEo3txGjVqpCFDhuj111/X0aNHC22/fft2XX/99fLx8VH16tXVq1cv/fDDD7na7dq1Sz179nR4P1/4HsqxZs0ade3aVdWqVZO3t7f69eunXbt2XfK+5di8ebP69OkjX19fVa1aVd27d9fGjRsd2hw4cECjRo1Sy5Yt5eXlpcsuu0wDBgxw+OwtWbJEAwYMkCRde+219nOWc1nyhZ/9HBe+l3Iuhd6wYYNGjRqlwMBA1atXr1SOR87n5vfff9ddd90lX19fBQQEaOrUqTLG6NChQ7r55pvl4+OjoKAgvfjiiw7r51zu+MEHH+ixxx5TUFCQqlWrpptuukmHDh3K9XorVqxQSEiIvLy8VLNmTd111106cuSIQ5uc361//vmn+vbtK29vb0VGRqpHjx76/PPPdeDAAfuxzel1PHv2rKZNm6aQkBD5+vqqWrVq6tq1q7755huHbRf185djz549GjhwoAICAuTl5aWWLVvq8ccfd2hz5MgR3XPPPapVq5Y8PDzUpk0bvfXWW8U5HUCFR48YgBKTlZWliIgIhYaG6oUXXtD//vc/vfjii2ratKkeeOABBQQEaP78+XrggQd0yy236NZbb5UkXX755ZLOfRnt3Lmz6tatq8mTJ6tatWr68MMP1b9/f3300Ue65ZZbJJ37hz7ni92UKVNUrVo1vfHGG/n2yuzdu1eDBw/WfffdpxEjRqhly5aSpPnz56tNmza66aab5ObmptWrV2vUqFHKzs7W6NGjJUlz5szR2LFjVb16dfsXjlq1akk6d5ll9+7ddeTIEd13331q0KCBNm3apClTptiDk3SuF+7mm2/W999/r/vvv1+tW7fWqlWrNHTo0CId19WrV8vLy8t+vC7GgAED1Lx5cz377LMyxkiSYmJi9Ndff2nYsGEKCgrSrl27tGjRIu3atUs//PCDPeD88ssv6t27twICAjRjxgxlZmZq+vTp9v0vSFGPTY733ntPp06d0n333SebzabnnntOt956q/766y+5u7vrvvvu09GjRxUTE6OlS5c6rBsTE6PBgwerV69emj17tiRp9+7d2rhxox588MGLPmaFefzxx/XOO+8U2iu2a9cude3aVT4+PnrkkUfk7u6uhQsXqkePHtqwYYNCQ0MlSXFxcbr22muVmZlpf98vWrQozx7OpUuXaujQoYqIiNDs2bOVlpam+fPnq0uXLtq+fXuRLv87deqUTpw44TDP399fLi4uWrduna6//nqFhIRo+vTpcnFxsf/B4rvvvtNVV10lSdq6das2bdqkQYMGqV69evr77781f/589ejRQ7/99puqVq2qbt26ady4cZo7d64ee+wxtW7dWpLs/71Yo0aNUkBAgKZNm6bTp0+X2PHIyx133KHWrVtr1qxZ+vzzz/X000/L399fCxcuVM+ePTV79mwtW7ZMDz30kDp16pTrkuBnnnlGNptNjz76qBISEjRnzhyFh4drx44d9vO6ZMkSDRs2TJ06dVJ0dLTi4+P1yiuvaOPGjdq+fbv8/Pzs28vMzFRERIS6dOmiF154QVWrVlVQUJCSk5N1+PBhvfzyy5Kk6tWrS5JSUlL0xhtvaPDgwRoxYoROnTqlN998UxEREdqyZYvat2/vUG9hnz/p3B9wunbtKnd3d40cOVKNGjXSn3/+qdWrV+uZZ56RJMXHx+vqq6+WzWbTmDFjFBAQoDVr1mj48OFKSUnhEkrgQgYALtLixYuNJLN161b7vKFDhxpJ5sknn3Ro26FDBxMSEmL/+fjx40aSmT59eq7t9urVy7Rr186cOXPGPi87O9tcc801pnnz5vZ5Y8eONTabzWzfvt0+759//jH+/v5Gktm/f799fsOGDY0ks3bt2lyvl5aWlmteRESEadKkicO8Nm3amO7du+dq+9RTT5lq1aqZ33//3WH+5MmTjaurqzl48KAxxphPPvnESDLPPfecvU1mZqbp2rWrkWQWL16ca9vnq1Gjhmnfvn2u+SkpKeb48eP2KTU11b5s+vTpRpIZPHhwkfb7/fffN5LMt99+a5/Xv39/4+npaQ4cOGCf99tvvxlXV1dz4T8fDRs2NEOHDrX/XNRjs3//fiPJXHbZZSYxMdHe7r///a+RZFavXm2fN3r06Fyva4wxDz74oPHx8TGZmZm5lpWkhg0bmn79+hljjBk2bJjx9PQ0R48eNcYY88033xhJZsWKFfb2/fv3N1WqVDF//vmnfd7Ro0eNt7e36datm33e+PHjjSSzefNm+7yEhATj6+vr8H4+deqU8fPzMyNGjHCoKy4uzvj6+uaaf6GcGvOa9u/fb7Kzs03z5s1NRESEyc7Otq+XlpZmGjdubK677jqHeReKjY01ksw777xjn7dixQojyXzzzTe52uf3e+DC91LO75suXbo4nOOSOh7nn7Ocz83IkSPt8zIzM029evWMzWYzs2bNss8/efKk8fLycqg1Z5t169Y1KSkp9vkffvihkWReeeUVY4wxZ8+eNYGBgaZt27bm33//tbf77LPPjCQzbdo0+7yc362TJ0/OtQ/9+vUzDRs2zDU/MzPTpKenO8w7efKkqVWrlrnnnnvs8y7m89etWzfj7e3t8PvAGOPwXhk+fLipXbu2OXHihEObQYMGGV9f3zzfN0BlxqWJAErU/fff7/Bz165d9ddffxW6XmJiotatW6eBAwfa/2J/4sQJ/fPPP4qIiNC+ffvsl+ysXbtWYWFhDn/V9ff3V2RkZJ7bbty4sSIiInLNP7/HITk5WSdOnFD37t31119/KTk5udCaV6xYoa5du6pGjRr2ek+cOKHw8HBlZWXp22+/lXRukAk3Nzc98MAD9nVdXV3zHH0vLykpKfa/dJ/v7rvvVkBAgH169NFHc7W58HxcuN9nzpzRiRMndPXVV0uSfvrpJ0nneje//PJL9e/fXw0aNLC3b926dZ7H8kJFPTY57rjjDtWoUcP+c9euXSWpSO8dPz8/nT59WjExMYW2LSlPPPGEMjMzNWvWrDyXZ2Vl6auvvlL//v3VpEkT+/zatWvrzjvv1Pfff6+UlBRJ594fV199tb23SZICAgJyvZ9jYmKUlJSkwYMHOxxTV1dXhYaG5rrsLD/Tpk1TTEyMwxQUFKQdO3Zo3759uvPOO/XPP//Yt3/69Gn16tVL3377rf1yyfPfQxkZGfrnn3/UrFkz+fn52d9DJW3EiBFydXW1/1xSxyMv9957r/3/XV1d1bFjRxljNHz4cPt8Pz8/tWzZMs/36JAhQ+Tt7W3/+fbbb1ft2rX1xRdfSJJ+/PFHJSQkaNSoUfL09LS369evn1q1aqXPP/881zbP//1RGFdXV1WpUkWSlJ2drcTERGVmZqpjx455np/CPn/Hjx/Xt99+q3vuucfh94Ekew+6MUYfffSRbrzxRhljHM5JRESEkpOTS+29ATgrLk0EUGI8PT3t94DlqFGjhk6ePFnoun/88YeMMZo6daqmTp2aZ5uEhATVrVtXBw4cUFhYWK7lzZo1y3O9xo0b5zl/48aNmj59umJjY5WWluawLDk5Wb6+vgXWvG/fPu3cuTPXPp9fr3TufpratWvnClM5l0gWxtvbW6mpqbnmP/nkkxozZowk6brrrstz3bz2PTExUTNnztTy5cvtNebICaDHjx/Xv//+q+bNm+dav2XLlvYvlPkp6rHJceGXu5wvhUV574waNUoffvihrr/+etWtW1e9e/fWwIED1adPnwLXO378uP3+RencZV15Bd68NGnSRHfffbcWLVqkyZMn57nttLS0PM9x69atlZ2drUOHDqlNmzY6cOCA/TLF81247r59+yRJPXv2zLMmHx+fItXerl07hYeH55qfs/2CLplNTk5WjRo19O+//yo6OlqLFy/WkSNH7Je95rQpDRe+l0vqeOTlwvejr6+vPD09VbNmzVzz87q38sLPjc1mU7Nmzez30B04cEBS3r8DWrVqletxFG5ubg73xRXF22+/rRdffFF79uxRRkaGfX5evxMK+/zlBLK2bdvm+3rHjx9XUlKSFi1apEWLFuXZ5sLPPVDZEcQAlJjz/1p9sXL+0v7QQw/l2+OSX9AqTF732vz555/q1auXWrVqpZdeekn169dXlSpV9MUXX+jll1/Od6CEC2u+7rrr9Mgjj+S5vEWLFsWq90KtWrXSzz//rIyMDPv9GtL/3VtXkLz2feDAgdq0aZMefvhhtW/fXtWrV1d2drb69OlTpP0uios9Nvm9d87/gp+fwMBA7dixQ19++aXWrFmjNWvWaPHixRoyZIjefvvtfNfr1KmT/QuxJE2fPv2ihsZ//PHHtXTpUs2ePVv9+/cv8nrFlXNuli5dqqCgoFzL3dwu7Z/0nO0///zzue4hypETVMeOHavFixdr/PjxCgsLk6+vr/15ZJf6Hjo/HJ/vwvdyaR6PvN6Pl/IevVQeHh4X9XiId999V1FRUerfv78efvhhBQYGytXVVdHR0frzzz9ztS+Jfcs5H3fddVe+Yb4ov7OAyoQgBsBS5490d76cy7fc3d3z/Gv9+Ro2bKg//vgj1/y85uVn9erVSk9P16effurw1+C8LmfKr+amTZsqNTW1SPV+/fXXSk1Ndehx2bt3b5FqveGGG/TDDz9o1apVGjhwYJHWyc/Jkyf19ddfa+bMmZo2bZp9fk7vQo6cUdEunF/Uuot6bC5GfudBkqpUqaIbb7xRN954o7KzszVq1CgtXLhQU6dOzTfAL1u2TP/++6/95/MvISyKpk2b6q677tLChQtz9WgFBASoatWqeR6rPXv2yMXFRfXr15d07v1RlOPctGlTSeeCZ0ke1wu37+PjU+j2V65cqaFDhzqMGnjmzJlcI4EWdM5q1KiRq/3Zs2d17Nixi6q3tI7HpbjwfBpj9Mcff9iDSMOGDSWdO8cX9ujt3bvXvrww+R3flStXqkmTJvr4448d2kyfPr3I+3C+nM/Gr7/+mm+bgIAAeXt7Kysrq9ydD6C84h4xAJaqWrWqJOX6AhYYGKgePXpo4cKFeX4RO378uP3/IyIiFBsbqx07dtjnJSYmatmyZUWuI+cvwBdeUrV48eJcbatVq5bnUPMDBw5UbGysvvzyy1zLkpKSlJmZKUnq27evMjMzHYbGz8rK0rx584pU6wMPPKBatWppwoQJ+v3333Mtv5i/Wue135JyjWLo6uqqiIgIffLJJzp48KB9/u7du/Pc3wsV9dhcjJznJl14Li68NMzFxcX+hTc9PT3f7XXu3Fnh4eH26WKDmHTuXrGMjAw999xzDvNdXV3Vu3dv/fe//3UY0j0+Pl7vvfeeunTpYr90rm/fvvrhhx+0ZcsWe7vjx4/nej9HRETIx8dHzz77rMOlZuevcylCQkLUtGlTvfDCC3leCnv+9l1dXXO9h+bNm5erNyu/cyadC1IX3iu4aNGifHvELlTax+NSvPPOOzp16pT955UrV+rYsWO6/vrrJUkdO3ZUYGCgFixY4PAeXbNmjXbv3q1+/foV6XWqVauW56WgeX3ON2/erNjY2GLtT0BAgLp166a33nrL4ffB+a/h6uqq2267TR999FGega0szwdQXtEjBsBSXl5eCg4O1gcffKAWLVrI399fbdu2Vdu2bfXqq6+qS5cuateunUaMGKEmTZooPj5esbGxOnz4sH7++WdJ0iOPPKJ3331X1113ncaOHWsfvr5BgwZKTEws8K/wOXr37m3vRbnvvvuUmpqq119/XYGBgbmCYEhIiObPn6+nn35azZo1U2BgoHr27KmHH35Yn376qW644QZFRUUpJCREp0+f1i+//KKVK1fq77//Vs2aNXXjjTeqc+fOmjx5sv7++28FBwfr448/LvK9NP7+/lq1apVuvPFGXXHFFRo0aJA6deokd3d3HTp0SCtWrJCU+z6PvPj4+Khbt2567rnnlJGRobp16+qrr77S/v37c7WdOXOm1q5dq65du2rUqFHKzMzUvHnz1KZNG+3cubPA1ynqsbkYISEhkqRx48YpIiJCrq6uGjRokO69914lJiaqZ8+eqlevng4cOKB58+apffv2xR4qvahyesXyugTy6aefVkxMjLp06aJRo0bJzc1NCxcuVHp6ukNwe+SRR7R06VL16dNHDz74oH34+oYNGzocZx8fH82fP1933323rrzySg0aNEgBAQE6ePCgPv/8c3Xu3Fn/+c9/ir0vLi4ueuONN3T99derTZs2GjZsmOrWrasjR47om2++kY+Pj1avXi3pXC/t0qVL5evrq+DgYMXGxup///ufLrvsModttm/fXq6urpo9e7aSk5Pl4eFhf3bfvffeq/vvv1+33XabrrvuOv3888/68ssvi/y+KO3jcSn8/f3VpUsXDRs2TPHx8ZozZ46aNWumESNGSDrX8z979mwNGzZM3bt31+DBg+3D1zdq1EgTJkwo0uuEhITogw8+0MSJE9WpUydVr15dN954o2644QZ9/PHHuuWWW9SvXz/t379fCxYsUHBwcJ4huyjmzp2rLl266Morr9TIkSPVuHFj/f333/r888/tfxSbNWuWvvnmG4WGhmrEiBEKDg5WYmKifvrpJ/3vf/9TYmJisV4bqLDKYKRGAE4uv+Hrq1WrlqttznDQ59u0aZMJCQkxVapUyTWE9Z9//mmGDBligoKCjLu7u6lbt6654YYbzMqVKx22sX37dtO1a1fj4eFh6tWrZ6Kjo83cuXONJBMXF2dvd/6Q4xf69NNPzeWXX248PT1No0aNzOzZs81bb72Vawj8uLg4069fP+Pt7W0kOQxlf+rUKTNlyhTTrFkzU6VKFVOzZk1zzTXXmBdeeMGcPXvW3u6ff/4xd999t/Hx8TG+vr7m7rvvNtu3by/S8PU5jh07Zh5++GETHBxsvLy8jIeHh2nSpIkZMmSIw7Dz5x/348eP59rO4cOHzS233GL8/PyMr6+vGTBggDl69Giew4lv2LDBfq6aNGliFixYkOc5vXDI8aIem5zhs59//vlcdV5YT2Zmphk7dqwJCAgwNpvNXsPKlStN7969TWBgoKlSpYpp0KCBue+++8yxY8eKdFyLKr/30r59++xD+p8/FLoxxvz0008mIiLCVK9e3VStWtVce+21ZtOmTbm2sXPnTtO9e3fj6elp6tata5566inz5ptv5novGnNuiPSIiAjj6+trPD09TdOmTU1UVJT58ccfC6w/r+Ha87J9+3Zz6623mssuu8x4eHiYhg0bmoEDB5qvv/7a3ubkyZNm2LBhpmbNmqZ69eomIiLC7NmzJ8/3weuvv26aNGliP0Y5Q9lnZWWZRx991NSsWdNUrVrVREREmD/++CPf4evP/31TWscjv89Nfr/funfvbtq0aZNrm++//76ZMmWKCQwMNF5eXqZfv365hn03xpgPPvjAdOjQwXh4eBh/f38TGRlpDh8+XKTXNsaY1NRUc+eddxo/Pz8jyT6UfXZ2tnn22WdNw4YNjYeHh+nQoYP57LPPzNChQx2Gu7+Yz58xxvz666/23x2enp6mZcuWZurUqQ5t4uPjzejRo039+vWNu7u7CQoKMr169TKLFi3Kcx+AysxmjAV3mQKABcaPH6+FCxcqNTX1kgYOAYDiWL9+va699lqtWLFCt99+e1mXA6Cc4x4xAE7p/EEWpHP3CS1dulRdunQhhAEAgHKPe8QAOKWwsDD16NFDrVu3Vnx8vN58802lpKTk+wwyAACA8oQgBsAp9e3bVytXrtSiRYtks9l05ZVX6s0331S3bt3KujQAAIBCcY8YAAAAAFiMe8QAAAAAwGIEMQAAAACwGPeIlYDs7GwdPXpU3t7eRXqQLAAAAICKyRijU6dOqU6dOnJxyb/fiyBWAo4ePar69euXdRkAAAAAyolDhw6pXr16+S4niJUAb29vSecOto+PTxlXAwAAAKCspKSkqH79+vaMkB+CWAnIuRzRx8eHIAYAAACg0FuWGKwDAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIu5lXUBAAAAKF02W+FtjCn9OgD8H3rEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYoyaCACoMBgZDgDgLAhiQDnBF0gA5R2/pwCg5HBpIgAAAABYjCAGAAAAABYjiAEAAACAxbhHDAAAALgE3D+J4iCIAaWIX8wAAADIC5cmAgAAAIDFCGIAAAAAYDGCGAAAAABYjHvEAAAAygnuLQYqD3rEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsxWAcA5KG0bpjnRnwAACDRIwYAAAAAliOIAQAAAIDFuDQRqOC4FA4AiobflwCsRBCr5PhHxzlx3gAAAJwblyYCAAAAgMUIYgAAAABgMYIYAAAAAFiMe8QAAOUa90QCKAi/I+Cs6BEDAAAAAIvRIwYAFQB/EQaAksXvVZQ2esQAAAAAwGL0iAEAAJQielZgBd5nzsfpesReffVVNWrUSJ6engoNDdWWLVsKbL9ixQq1atVKnp6eateunb744guH5cYYTZs2TbVr15aXl5fCw8O1b9++0twFAAAAAJWcUwWxDz74QBMnTtT06dP1008/6YorrlBERIQSEhLybL9p0yYNHjxYw4cP1/bt29W/f3/1799fv/76q73Nc889p7lz52rBggXavHmzqlWrpoiICJ05c8aq3cJFsNkKnwAAAIDyzmaM83RShoaGqlOnTvrPf/4jScrOzlb9+vU1duxYTZ48OVf7O+64Q6dPn9Znn31mn3f11Verffv2WrBggYwxqlOnjiZNmqSHHnpIkpScnKxatWppyZIlGjRoUJHqSklJka+vr5KTk+Xj41MCe2odZ+vGrsj1loe2+D+lddw4zxeP41B+VPTj62yf+9KqwdmUh2NWHo5veagB5xQ1GzhNj9jZs2e1bds2hYeH2+e5uLgoPDxcsbGxea4TGxvr0F6SIiIi7O3379+vuLg4hza+vr4KDQ3Nd5uSlJ6erpSUFIepPKHX6OJxzAAAF4N/N85xtuPgbPWiYnOawTpOnDihrKws1apVy2F+rVq1tGfPnjzXiYuLy7N9XFycfXnOvPza5CU6OlozZ8686H2wysX8teNi2paHvziVVr3lYbvloW1p/vWvsPblrW1p/dWwIp/n0vodUR6Ow8UoD8e3tNpe7PEoD5/l0vrcl4e2zvbvXHl4X5aHtuXhOFT0f++dhdP0iJUnU6ZMUXJysn06dOhQWZcElAhjCp8AoKzxewpAReA0PWI1a9aUq6ur4uPjHebHx8crKCgoz3WCgoIKbJ/z3/j4eNWuXduhTfv27fOtxcPDQx4eHsXZDQAljC9dKC7eO+dwHGAV3mvlB+eifHCaHrEqVaooJCREX3/9tX1edna2vv76a4WFheW5TlhYmEN7SYqJibG3b9y4sYKCghzapKSkaPPmzfluE0Dx8BdsAACA/+M0PWKSNHHiRA0dOlQdO3bUVVddpTlz5uj06dMaNmyYJGnIkCGqW7euoqOjJUkPPvigunfvrhdffFH9+vXT8uXL9eOPP2rRokWSJJvNpvHjx+vpp59W8+bN1bhxY02dOlV16tRR//79y2o3AQBACeEPPQDKK6cKYnfccYeOHz+uadOmKS4uTu3bt9fatWvtg20cPHhQLi7/18l3zTXX6L333tMTTzyhxx57TM2bN9cnn3yitm3b2ts88sgjOn36tEaOHKmkpCR16dJFa9eulaenp+X7BwAAAKBycKrniJVXzvwcsYtRHkYYq8jbdTaleRxKa2SkijjiUnGUh9H3KrLycHzLy7mo7COilbaK/O9ceaihtDjbZ5lREy9eUbOBU/WIAeVBefqgA0BFwe/Wi8cxA5wbQQwAUCL4UogL8Z5wTpy30sXxRQ6CGAAgX3xhAACgdDjN8PUAAAAAUFHQIwYAAACUQ1yVULHRIwYAAAAAFqNHDAAAAECe6JUrPfSIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABZjsA4A5Q43BgMAgIqOHjEAAAAAsBhBDAAAAAAsRhADAAAAAItxjxiKjPt2AAAAgJJBjxgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMURMBAKhgGOUWAMo/esQAAAAAwGIEMQAAAACwGEEMAAAAACzGPWIAUMlw/xAAAGWPHjEAAAAAsBhBDAAAAAAsxqWJAACUIC79BAAUBT1iAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiM4esBAHACDIsPoKKp7L/X6BEDAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYk4TxBITExUZGSkfHx/5+flp+PDhSk1NLXCdM2fOaPTo0brssstUvXp13XbbbYqPj3doY7PZck3Lly8vzV0BAAAAUMk5TRCLjIzUrl27FBMTo88++0zffvutRo4cWeA6EyZM0OrVq7VixQpt2LBBR48e1a233pqr3eLFi3Xs2DH71L9//1LaCwAAAACQbMYYU9ZFFGb37t0KDg7W1q1b1bFjR0nS2rVr1bdvXx0+fFh16tTJtU5ycrICAgL03nvv6fbbb5ck7dmzR61bt1ZsbKyuvvpqSed6xFatWnVJ4SslJUW+vr5KTk6Wj49PsbdTWdlshbcpzru0tLaLc5zx+BZWc3mrFxWfM36OACvw2XBepfVvrTP9G17UbOAUPWKxsbHy8/OzhzBJCg8Pl4uLizZv3pznOtu2bVNGRobCw8Pt81q1aqUGDRooNjbWoe3o0aNVs2ZNXXXVVXrrrbdUWDZNT09XSkqKwwQAAAAAReVW1gUURVxcnAIDAx3mubm5yd/fX3FxcfmuU6VKFfn5+TnMr1WrlsM6Tz75pHr27KmqVavqq6++0qhRo5Samqpx48blW090dLRmzpxZ/B0CAAAAUKmVaY/Y5MmT8xws4/xpz549pVrD1KlT1blzZ3Xo0EGPPvqoHnnkET3//PMFrjNlyhQlJyfbp0OHDpVqjQAAAAAqljLtEZs0aZKioqIKbNOkSRMFBQUpISHBYX5mZqYSExMVFBSU53pBQUE6e/askpKSHHrF4uPj811HkkJDQ/XUU08pPT1dHh4eebbx8PDIdxkAAAAAFKZMg1hAQIACAgIKbRcWFqakpCRt27ZNISEhkqR169YpOztboaGhea4TEhIid3d3ff3117rtttskSXv37tXBgwcVFhaW72vt2LFDNWrUIGgBAAAAKDVOcY9Y69at1adPH40YMUILFixQRkaGxowZo0GDBtlHTDxy5Ih69eqld955R1dddZV8fX01fPhwTZw4Uf7+/vLx8dHYsWMVFhZmHzFx9erVio+P19VXXy1PT0/FxMTo2Wef1UMPPVSWuwsAAADgPOVpVMSS4hRBTJKWLVumMWPGqFevXnJxcdFtt92muXPn2pdnZGRo7969SktLs897+eWX7W3T09MVERGh1157zb7c3d1dr776qiZMmCBjjJo1a6aXXnpJI0aMsHTfAAAAAFQuTvEcsfKO54hdGp4j5pyc8fg60zNIUDk44+cIsAKfDefFv7UV7DliAAAAAFCREMQAAAAAwGIEMQAAAACwGEEMAAAAACzmNKMmouKqDDdtAgAAAOejRwwAAAAALEYQAwAAAACLcWkigGLhklIAAIDio0cMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYjxHDBUWz7kCAABAeUWPGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABZzK+sCAACorIwp6woAAGWFHjEAAAAAsBg9YgAAAABKBD39RUePGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWc5oglpiYqMjISPn4+MjPz0/Dhw9XampqgessWrRIPXr0kI+Pj2w2m5KSkkpkuwAAAABwKZwmiEVGRmrXrl2KiYnRZ599pm+//VYjR44scJ20tDT16dNHjz32WIluFwAAAAAuhc0YY8q6iMLs3r1bwcHB2rp1qzp27ChJWrt2rfr27avDhw+rTp06Ba6/fv16XXvttTp58qT8/PxKbLs5UlJS5Ovrq+TkZPn4+BRvJwGUOput4OXl/7chAFQOhf2+lvidjfKrqNnAKXrEYmNj5efnZw9LkhQeHi4XFxdt3rzZ8u2mp6crJSXFYQIAAACAonKKIBYXF6fAwECHeW5ubvL391dcXJzl242Ojpavr699ql+/frFrAAAAAFD5lGkQmzx5smw2W4HTnj17yrLEPE2ZMkXJycn26dChQ2VdEgAAAAAn4laWLz5p0iRFRUUV2KZJkyYKCgpSQkKCw/zMzEwlJiYqKCio2K9f3O16eHjIw8Oj2K8LAAAAoHIr0yAWEBCggICAQtuFhYUpKSlJ27ZtU0hIiCRp3bp1ys7OVmhoaLFfv7S2CwAAAAAFcYp7xFq3bq0+ffpoxIgR2rJlizZu3KgxY8Zo0KBB9pENjxw5olatWmnLli329eLi4rRjxw798ccfkqRffvlFO3bsUGJiYpG3CwAAAAAlzSmCmCQtW7ZMrVq1Uq9evdS3b1916dJFixYtsi/PyMjQ3r17lZaWZp+3YMECdejQQSNGjJAkdevWTR06dNCnn35a5O0CAAAAQElziueIlXc8RwxwDjxHDACcA88RgzMrajYo03vEAMBK/KMNAADKC6e5NBEAAAAAKgqCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGCxYgexpUuXqnPnzqpTp44OHDggSZozZ47++9//llhxAAAAAFARFSuIzZ8/XxMnTlTfvn2VlJSkrKwsSZKfn5/mzJlTkvUBAAAAQIVTrCA2b948vf7663r88cfl6upqn9+xY0f98ssvJVYcAAAAAFRExQpi+/fvV4cOHXLN9/Dw0OnTpy+5KAAAAACoyIoVxBo3bqwdO3bkmr927Vq1bt36UmsCAAAAgArNrTgrTZw4UaNHj9aZM2dkjNGWLVv0/vvvKzo6Wm+88UZJ1wgAAAAAFUqxgti9994rLy8vPfHEE0pLS9Odd96pOnXq6JVXXtGgQYNKukYAAAAAqFBsxhhzKRtIS0tTamqqAgMDS6omp5OSkiJfX18lJyfLx8enrMsBAABwajZb4W0u7RssUHqKmg2K1SO2f/9+ZWZmqnnz5qpataqqVq0qSdq3b5/c3d3VqFGjYhUNAAAAAJVBsQbriIqK0qZNm3LN37x5s6Kioi61JgAAAACo0IoVxLZv367OnTvnmn/11VfnOZoiAAAAAOD/FCuI2Ww2nTp1Ktf85ORkZWVlXXJRAAAAAFCRFSuIdevWTdHR0Q6hKysrS9HR0erSpUuJFQcAAAAAFVGxBuuYPXu2unXrppYtW6pr166SpO+++04pKSlat25diRYIAAAAABVNsXrEgoODtXPnTg0cOFAJCQk6deqUhgwZoj179qht27YlXSMAAAAAVCiX/Bwx8BwxAACAksRzxODMSvU5YpKUlJSkLVu2KCEhQdnZ2Q7LhgwZUtzNAgAAAECFV6wgtnr1akVGRio1NVU+Pj6ynfdnC5vNRhADAAAAgAIU6x6xSZMm6Z577lFqaqqSkpJ08uRJ+5SYmFjSNQIAAABAhVKsIHbkyBGNGzdOVatWLel6AAAAAKDCK1YQi4iI0I8//ljStQAAAABApVCse8T69eunhx9+WL/99pvatWsnd3d3h+U33XRTiRQHAAAAABVRsYavd3HJvyPNZrMpKyvrkopyNgxfDwAAUHIYvh7OrFSHr79wuHoAAAAAQNEV6x4xAAAAAEDxFfuBzqdPn9aGDRt08OBBnT171mHZuHHjLrkwAAAAAKioihXEtm/frr59+yotLU2nT5+Wv7+/Tpw4oapVqyowMJAgBgAAAAAFKNaliRMmTNCNN96okydPysvLSz/88IMOHDigkJAQvfDCCyVdIwAAAABUKMUKYjt27NCkSZPk4uIiV1dXpaenq379+nruuef02GOPlXSNAAAAAFChFCuIubu724ewDwwM1MGDByVJvr6+OnToUMlVBwAAAAAVULHuEevQoYO2bt2q5s2bq3v37po2bZpOnDihpUuXqm3btiVdIwAAAABUKMXqEXv22WdVu3ZtSdIzzzyjGjVq6IEHHtDx48e1cOHCEi0QAAAAACoamzE8l/xSFfXp2QAAACiczVZ4G77BorwqajYoVo9Yz549lZSUlOeL9uzZszibBAAAAIBKo1hBbP369bke4ixJZ86c0XfffXfJRQEAAABARXZRg3Xs3LnT/v+//fab4uLi7D9nZWVp7dq1qlu3bslVBwAAAAAV0EUFsfbt28tms8lms+V5CaKXl5fmzZtXYsUBAAAAQEV0UUFs//79MsaoSZMm2rJliwICAuzLqlSposDAQLm6upZ4kQAAAABQkVxUEGvYsKEyMjI0dOhQXXbZZWrYsGFp1QUAAAAAFdZFD9bh7u6uVatWlUYtAAAAAFApFGvUxJtvvlmffPJJCZcCAAAAAJXDRV2amKN58+Z68skntXHjRoWEhKhatWoOy8eNG1cixQEAAABARWQz5uKfS964ceP8N2iz6a+//rqkopxNUZ+eDQAAgMLZbIW3ufhvsIA1ipoNitUjtn///mIXBgAAAACVXbHuETufMUbF6FS7aImJiYqMjJSPj4/8/Pw0fPhwpaamFrjOokWL1KNHD/n4+MhmsykpKSlXm0aNGtmfjZYzzZo1q5T2AgAAAAAuIYi98847ateunby8vOTl5aXLL79cS5cuLcnaHERGRmrXrl2KiYnRZ599pm+//VYjR44scJ20tDT16dNHjz32WIHtnnzySR07dsw+jR07tiRLBwAAAAAHxbo08aWXXtLUqVM1ZswYde7cWZL0/fff6/7779eJEyc0YcKEEi1y9+7dWrt2rbZu3aqOHTtKkubNm6e+ffvqhRdeUJ06dfJcb/z48ZKk9evXF7h9b29vBQUFlWTJAAAAAJCvYvWIzZs3T/Pnz9fs2bN100036aabbtJzzz2n1157TXPnzi3pGhUbGys/Pz97CJOk8PBwubi4aPPmzZe8/VmzZumyyy5Thw4d9PzzzyszM7PA9unp6UpJSXGYAAAAAKCoitUjduzYMV1zzTW55l9zzTU6duzYJRd1obi4OAUGBjrMc3Nzk7+/v+Li4i5p2+PGjdOVV14pf39/bdq0SVOmTNGxY8f00ksv5btOdHS0Zs6ceUmvCwAAAKDyKlaPWLNmzfThhx/mmv/BBx+oefPmRd7O5MmTcw2UceG0Z8+e4pRYZBMnTlSPHj10+eWX6/7779eLL76oefPmKT09Pd91pkyZouTkZPt06NChUq0RAAAAQMVSrB6xmTNn6o477tC3335rv0ds48aN+vrrr/MMaPmZNGmSoqKiCmzTpEkTBQUFKSEhwWF+ZmamEhMTS/zertDQUGVmZurvv/9Wy5Yt82zj4eEhDw+PEn1dAAAAAJVHsYLYbbfdps2bN+vll1/WJ598Iklq3bq1tmzZog4dOhR5OwEBAQoICCi0XVhYmJKSkrRt2zaFhIRIktatW6fs7GyFhoYWZxfytWPHDrm4uOS6FBIAAAAASkqxgpgkhYSE6N133y3JWvLVunVr9enTRyNGjNCCBQuUkZGhMWPGaNCgQfYRE48cOaJevXrpnXfe0VVXXSXp3L1lcXFx+uOPPyRJv/zyi7y9vdWgQQP5+/srNjZWmzdv1rXXXitvb2/FxsZqwoQJuuuuu1SjRg1L9g0AAABA5VPsIJaVlaVVq1Zp9+7dkqTg4GDdfPPNcnMr9iYLtGzZMo0ZM0a9evWSi4uLbrvtNocRGjMyMrR3716lpaXZ5y1YsMBhUI1u3bpJkhYvXqyoqCh5eHho+fLlmjFjhtLT09W4cWNNmDBBEydOLJV9AAAAAABJshljzMWutGvXLt10002Ki4uz30f1+++/KyAgQKtXr1bbtm1LvNDyLCUlRb6+vkpOTpaPj09ZlwMAAODUbLbC21z8N1jAGkXNBsUaNfHee+9VmzZtdPjwYf3000/66aefdOjQIV1++eUaOXJksYsGAAAAgMqgWNcR7tixQz/++KPDfVQ1atTQM888o06dOpVYcQAAAABQERWrR6xFixaKj4/PNT8hIUHNmjW75KIAAAAAoCIrVhCLjo7WuHHjtHLlSh0+fFiHDx/WypUrNX78eM2ePVspKSn2CQAAAADgqFiDdbi4/F9+s/3/uylzNnP+zzabTVlZWSVRZ7nGYB0AAAAlh8E64MyKmg2KdY/YN998U+zCAAAAAKCyK1YQ6969e0nXAQAAAACVRrGfvnzmzBnt3LlTCQkJys7Odlh20003XXJhAAAAAFBRFSuIrV27VkOGDNGJEydyLass94UBAAAAQHEVa9TEsWPHasCAATp27Jiys7MdJkIYAAAAABSsWEEsPj5eEydOVK1atUq6HgAAAACo8IoVxG6//XatX7++hEsBAAAAgMqhWM8RS0tL04ABAxQQEKB27drJ3d3dYfm4ceNKrEBnwHPEAAAASg7PEYMzK9XniL3//vv66quv5OnpqfXr19sf4iydG6yjsgUxAAAAALgYxQpijz/+uGbOnKnJkyfLxaVYVzcCAAAAQKVVrBR19uxZ3XHHHYQwAAAAACiGYiWpoUOH6oMPPijpWgAAAACgUijWpYlZWVl67rnn9OWXX+ryyy/PNVjHSy+9VCLFAQAAAEBFVKwg9ssvv6hDhw6SpF9//bVECwIAAACAiq5YQeybb74p6ToAAAAAoNK4qCB26623FtrGZrPpo48+KnZBAAAAAFDRXVQQ8/X1La06AAAAAKDSuKggtnjx4tKqAwAAAAAqDR4EBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAWI4gBAAAAgMUIYgAAAABgMYIYAAAAAFjMaYJYYmKiIiMj5ePjIz8/Pw0fPlypqakFth87dqxatmwpLy8vNWjQQOPGjVNycrJDu4MHD6pfv36qWrWqAgMD9fDDDyszM7O0dwcAAABAJeZW1gUUVWRkpI4dO6aYmBhlZGRo2LBhGjlypN5777082x89elRHjx7VCy+8oODgYB04cED333+/jh49qpUrV0qSsrKy1K9fPwUFBWnTpk06duyYhgwZInd3dz377LNW7h4AAACASsRmjDFlXURhdu/ereDgYG3dulUdO3aUJK1du1Z9+/bV4cOHVadOnSJtZ8WKFbrrrrt0+vRpubm5ac2aNbrhhht09OhR1apVS5K0YMECPfroozp+/LiqVKlSpO2mpKTI19dXycnJ8vHxKd5OAgAAQJJksxXepvx/g0VlVdRs4BSXJsbGxsrPz88ewiQpPDxcLi4u2rx5c5G3k3Mw3Nzc7Ntt166dPYRJUkREhFJSUrRr1658t5Oenq6UlBSHCQAAAACKyimCWFxcnAIDAx3mubm5yd/fX3FxcUXaxokTJ/TUU09p5MiRDts9P4RJsv9c0Hajo6Pl6+trn+rXr1/UXQEAAACAsg1ikydPls1mK3Das2fPJb9OSkqK+vXrp+DgYM2YMeOStzdlyhQlJyfbp0OHDl3yNgEAAABUHmU6WMekSZMUFRVVYJsmTZooKChICQkJDvMzMzOVmJiooKCgAtc/deqU+vTpI29vb61atUru7u72ZUFBQdqyZYtD+/j4ePuy/Hh4eMjDw6PA1wUAAACA/JRpEAsICFBAQECh7cLCwpSUlKRt27YpJCREkrRu3TplZ2crNDQ03/VSUlIUEREhDw8Pffrpp/L09My13WeeeUYJCQn2Sx9jYmLk4+Oj4ODgS9gzAAAAAMifU9wj1rp1a/Xp00cjRozQli1btHHjRo0ZM0aDBg2yj5h45MgRtWrVyt7DlZKSot69e+v06dN68803lZKSori4OMXFxSkrK0uS1Lt3bwUHB+vuu+/Wzz//rC+//FJPPPGERo8eTY8XAAAAgFLjNM8RW7ZsmcaMGaNevXrJxcVFt912m+bOnWtfnpGRob179yotLU2S9NNPP9lHVGzWrJnDtvbv369GjRrJ1dVVn332mR544AGFhYWpWrVqGjp0qJ588knrdgwAAABApeMUzxEr73iOGAAAQMnhOWJwZhXqOWIAAAAAUJEQxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYk4TxBITExUZGSkfHx/5+flp+PDhSk1NLbD92LFj1bJlS3l5ealBgwYaN26ckpOTHdrZbLZc0/Lly0t7dwAAAABUYm5lXUBRRUZG6tixY4qJiVFGRoaGDRumkSNH6r333suz/dGjR3X06FG98MILCg4O1oEDB3T//ffr6NGjWrlypUPbxYsXq0+fPvaf/fz8SnNXAAAAAFRyNmOMKesiCrN7924FBwdr69at6tixoyRp7dq16tu3rw4fPqw6deoUaTsrVqzQXXfdpdOnT8vN7VwGtdlsWrVqlfr371/s+lJSUuTr66vk5GT5+PgUezsAAACQbLbC25T/b7CorIqaDZzi0sTY2Fj5+fnZQ5gkhYeHy8XFRZs3by7ydnIORk4IyzF69GjVrFlTV111ld566y0Vlk3T09OVkpLiMAEAAABAUTnFpYlxcXEKDAx0mOfm5iZ/f3/FxcUVaRsnTpzQU089pZEjRzrMf/LJJ9WzZ09VrVpVX331lUaNGqXU1FSNGzcu321FR0dr5syZF78jAAAAAKAy7hGbPHlynoNlnD/t2bPnkl8nJSVF/fr1U3BwsGbMmOGwbOrUqercubM6dOigRx99VI888oief/75Arc3ZcoUJScn26dDhw5dco0AAAAAKo8y7RGbNGmSoqKiCmzTpEkTBQUFKSEhwWF+ZmamEhMTFRQUVOD6p06dUp8+feTt7a1Vq1bJ3d29wPahoaF66qmnlJ6eLg8PjzzbeHh45LsMAAAAAApTpkEsICBAAQEBhbYLCwtTUlKStm3bppCQEEnSunXrlJ2drdDQ0HzXS0lJUUREhDw8PPTpp5/K09Oz0NfasWOHatSoQdACAAAAUGqc4h6x1q1bq0+fPhoxYoQWLFigjIwMjRkzRoMGDbKPmHjkyBH16tVL77zzjq666iqlpKSod+/eSktL07vvvuswqEZAQIBcXV21evVqxcfH6+qrr5anp6diYmL07LPP6qGHHirL3QUAAABQwTlFEJOkZcuWacyYMerVq5dcXFx02223ae7cufblGRkZ2rt3r9LS0iRJP/30k31ExWbNmjlsa//+/WrUqJHc3d316quvasKECTLGqFmzZnrppZc0YsQI63YMAAAAQKXjFM8RK+94jhgAAEDJ4TlicGYV6jliAAAAAFCREMQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGJOE8QSExMVGRkpHx8f+fn5afjw4UpNTS1wnfvuu09NmzaVl5eXAgICdPPNN2vPnj0ObQ4ePKh+/fqpatWqCgwM1MMPP6zMzMzS3BUAAAAAlZzTBLHIyEjt2rVLMTEx+uyzz/Ttt99q5MiRBa4TEhKixYsXa/fu3fryyy9ljFHv3r2VlZUlScrKylK/fv109uxZbdq0SW+//baWLFmiadOmWbFLAAAAACopmzHGlHURhdm9e7eCg4O1detWdezYUZK0du1a9e3bV4cPH1adOnWKtJ2dO3fqiiuu0B9//KGmTZtqzZo1uuGGG3T06FHVqlVLkrRgwQI9+uijOn78uKpUqVKk7aakpMjX11fJycny8fEp3k4CAABAkmSzFd6m/H+DRWVV1GzgFD1isbGx8vPzs4cwSQoPD5eLi4s2b95cpG2cPn1aixcvVuPGjVW/fn37dtu1a2cPYZIUERGhlJQU7dq1K99tpaenKyUlxWECAAAAgKJyiiAWFxenwMBAh3lubm7y9/dXXFxcgeu+9tprql69uqpXr641a9YoJibG3tMVFxfnEMIk2X8uaLvR0dHy9fW1TznBDgAAAACKokyD2OTJk2Wz2QqcLhxc42JFRkZq+/bt2rBhg1q0aKGBAwfqzJkzl7TNKVOmKDk52T4dOnTokrYHAAAAoHJxK8sXnzRpkqKiogps06RJEwUFBSkhIcFhfmZmphITExUUFFTg+jm9Vs2bN9fVV1+tGjVqaNWqVRo8eLCCgoK0ZcsWh/bx8fGSVOB2PTw85OHhUeDrAgAAAEB+yjSIBQQEKCAgoNB2YWFhSkpK0rZt2xQSEiJJWrdunbKzsxUaGlrk1zPGyBij9PR0+3afeeYZJSQk2C99jImJkY+Pj4KDg4uxRwAAAABQOKe4R6x169bq06ePRowYoS1btmjjxo0aM2aMBg0aZB8x8ciRI2rVqpW9h+uvv/5SdHS0tm3bpoMHD2rTpk0aMGCAvLy81LdvX0lS7969FRwcrLvvvls///yzvvzySz3xxBMaPXo0PV4AAAAASo1TBDFJWrZsmVq1aqVevXqpb9++6tKlixYtWmRfnpGRob179yotLU2S5Onpqe+++059+/ZVs2bNdMcdd8jb21ubNm2y9365urrqs88+k6urq8LCwnTXXXdpyJAhevLJJ8tkHwEAAABUDk7xHLHyjueIAQAAlByeIwZnVqGeIwYAAAAAFQlBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLuZV1AQAAAMD5eEYYKgN6xAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAAADAYgQxAAAAALAYQQwAAAAALEYQAwAAAACLEcQAAAAAwGIEMQAAAACwGEEMAAAAACzmVtYFVATGGElSSkpKGVcCAAAAoCzlZIKcjJAfglgJOHXqlCSpfv36ZVwJAAAAgPLg1KlT8vX1zXe5zRQW1VCo7OxsHT16VN7e3rLZbGVdjoOUlBTVr19fhw4dko+PT1mXg4vAuXNOnDfnxblzTpw358R5c16cu8IZY3Tq1CnVqVNHLi753wlGj1gJcHFxUb169cq6jAL5+PjwYXFSnDvnxHlzXpw758R5c06cN+fFuStYQT1hORisAwAAAAAsRhADAAAAAIsRxCo4Dw8PTZ8+XR4eHmVdCi4S5845cd6cF+fOOXHenBPnzXlx7koOg3UAAAAAgMXoEQMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhCr4F599VU1atRInp6eCg0N1ZYtW8q6JJzn22+/1Y033qg6derIZrPpk08+cVhujNG0adNUu3ZteXl5KTw8XPv27SubYmEXHR2tTp06ydvbW4GBgerfv7/27t3r0ObMmTMaPXq0LrvsMlWvXl233Xab4uPjy6hi5Jg/f74uv/xy+4NIw8LCtGbNGvtyzptzmDVrlmw2m8aPH2+fx7krn2bMmCGbzeYwtWrVyr6c81Z+HTlyRHfddZcuu+wyeXl5qV27dvrxxx/ty/mOcukIYhXYBx98oIkTJ2r69On66aefdMUVVygiIkIJCQllXRr+v9OnT+uKK67Qq6++mufy5557TnPnztWCBQu0efNmVatWTRERETpz5ozFleJ8GzZs0OjRo/XDDz8oJiZGGRkZ6t27t06fPm1vM2HCBK1evVorVqzQhg0bdPToUd16661lWDUkqV69epo1a5a2bdumH3/8UT179tTNN9+sXbt2SeK8OYOtW7dq4cKFuvzyyx3mc+7KrzZt2ujYsWP26fvvv7cv47yVTydPnlTnzp3l7u6uNWvW6LffftOLL76oGjVq2NvwHaUEGFRYV111lRk9erT956ysLFOnTh0THR1dhlUhP5LMqlWr7D9nZ2eboKAg8/zzz9vnJSUlGQ8PD/P++++XQYXIT0JCgpFkNmzYYIw5d57c3d3NihUr7G12795tJJnY2NiyKhP5qFGjhnnjjTc4b07g1KlTpnnz5iYmJsZ0797dPPjgg8YYPnPl2fTp080VV1yR5zLOW/n16KOPmi5duuS7nO8oJYMesQrq7Nmz2rZtm8LDw+3zXFxcFB4ertjY2DKsDEW1f/9+xcXFOZxDX19fhYaGcg7LmeTkZEmSv7+/JGnbtm3KyMhwOHetWrVSgwYNOHflSFZWlpYvX67Tp08rLCyM8+YERo8erX79+jmcI4nPXHm3b98+1alTR02aNFFkZKQOHjwoifNWnn366afq2LGjBgwYoMDAQHXo0EGvv/66fTnfUUoGQayCOnHihLKyslSrVi2H+bVq1VJcXFwZVYWLkXOeOIflW3Z2tsaPH6/OnTurbdu2ks6duypVqsjPz8+hLeeufPjll19UvXp1eXh46P7779eqVasUHBzMeSvnli9frp9++knR0dG5lnHuyq/Q0FAtWbJEa9eu1fz587V//3517dpVp06d4ryVY3/99Zfmz5+v5s2b68svv9QDDzygcePG6e2335bEd5SS4lbWBQCAMxs9erR+/fVXh3seUL61bNlSO3bsUHJyslauXKmhQ4dqw4YNZV0WCnDo0CE9+OCDiomJkaenZ1mXg4tw/fXX2///8ssvV2hoqBo2bKgPP/xQXl5eZVgZCpKdna2OHTvq2WeflSR16NBBv/76qxYsWKChQ4eWcXUVBz1iFVTNmjXl6uqaa+Sh+Ph4BQUFlVFVuBg554lzWH6NGTNGn332mb755hvVq1fPPj8oKEhnz55VUlKSQ3vOXflQpUoVNWvWTCEhIYqOjtYVV1yhV155hfNWjm3btk0JCQm68sor5ebmJjc3N23YsEFz586Vm5ubatWqxblzEn5+fmrRooX++OMPPnPlWO3atRUcHOwwr3Xr1vbLSvmOUjIIYhVUlSpVFBISoq+//to+Lzs7W19//bXCwsLKsDIUVePGjRUUFORwDlNSUrR582bOYRkzxmjMmDFatWqV1q1bp8aNGzssDwkJkbu7u8O527t3rw4ePMi5K4eys7OVnp7OeSvHevXqpV9++UU7duywTx07dlRkZKT9/zl3ziE1NVV//vmnateuzWeuHOvcuXOux7L8/vvvatiwoSS+o5SYsh4tBKVn+fLlxsPDwyxZssT89ttvZuTIkcbPz8/ExcWVdWn4/06dOmW2b99utm/fbiSZl156yWzfvt0cOHDAGGPMrFmzjJ+fn/nvf/9rdu7caW6++WbTuHFj8++//5Zx5ZXbAw88YHx9fc369evNsWPH7FNaWpq9zf33328aNGhg1q1bZ3788UcTFhZmwsLCyrBqGGPM5MmTzYYNG8z+/fvNzp07zeTJk43NZjNfffWVMYbz5kzOHzXRGM5deTVp0iSzfv16s3//frNx40YTHh5uatasaRISEowxnLfyasuWLcbNzc0888wzZt++fWbZsmWmatWq5t1337W34TvKpSOIVXDz5s0zDRo0MFWqVDFXXXWV+eGHH8q6JJznm2++MZJyTUOHDjXGnBsedurUqaZWrVrGw8PD9OrVy+zdu7dsi0ae50ySWbx4sb3Nv//+a0aNGmVq1Khhqlatam655RZz7Nixsisaxhhj7rnnHtOwYUNTpUoVExAQYHr16mUPYcZw3pzJhUGMc1c+3XHHHaZ27dqmSpUqpm7duuaOO+4wf/zxh3055638Wr16tWnbtq3x8PAwrVq1MosWLXJYzneUS2czxpiy6YsDAAAAgMqJe8QAAAAAwGIEMQAAAACwGEEMAAAAACxGEAMAAAAAixHEAAAAAMBiBDEAAAAAsBhBDAAAAAAsRhADAAAAAIsRxAAAlUKjRo00Z86csi4DAABJBDEAQDkRFRUlm82mWbNmOcz/5JNPZLPZyqgqRzabLdfUpUuXEtt+jx49NH78+BLbHgCg/CKIAQDKDU9PT82ePVsnT54s61LytXjxYh07dsw+ffrpp2VdUi5nz54t6xIAAIUgiAEAyo3w8HAFBQUpOjq6wHYfffSR2rRpIw8PDzVq1Egvvviiw/KEhATdeOON8vLyUuPGjbVs2bJc20hKStK9996rgIAA+fj4qGfPnvr5558LrdHPz09BQUH2yd/fX5KUnp6uhx56SHXr1lW1atUUGhqq9evX29f7559/NHjwYNWtW1dVq1ZVu3bt9P7779uXR0VFacOGDXrllVfsvW1///23lixZIj8/P4caLuwlnDFjhtq3b6833nhDjRs3lqenZ5H28eeff9a1114rb29v+fj4KCQkRD/++GOhxwAAcOkIYgCAcsPV1VXPPvus5s2bp8OHD+fZZtu2bRo4cKAGDRqkX375RTNmzNDUqVO1ZMkSe5uoqCgdOnRI33zzjVauXKnXXntNCQkJDtsZMGCAEhIStGbNGm3btk1XXnmlevXqpcTExGLVPmbMGMXGxmr58uXauXOnBgwYoD59+mjfvn2SpDNnzigkJESff/65fv31V40cOVJ33323tmzZIkl65ZVXFBYWphEjRth72+rXr1/k1//jjz/00Ucf6eOPP9aOHTuKtI+RkZGqV6+etm7dqm3btmny5Mlyd3cv1v4DAC6SAQCgHBg6dKi5+eabjTHGXH311eaee+4xxhizatUqc/4/V3feeae57rrrHNZ9+OGHTXBwsDHGmL179xpJZsuWLfblu3fvNpLMyy+/bIwx5rvvvjM+Pj7mzJkzDttp2rSpWbhwYb41SjKenp6mWrVq9mnVqlXmwIEDxtXV1Rw5csShfa9evcyUKVPy3V6/fv3MpEmT7D93797dPPjggw5tFi9ebHx9fR3mXXhMpk+fbtzd3U1CQoJ9XlH20dvb2yxZsiTf+gAApcetTFMgAAB5mD17tnr27KmHHnoo17Ldu3fr5ptvdpjXuXNnzZkzR1lZWdq9e7fc3NwUEhJiX96qVSuHy/t+/vlnpaam6rLLLnPYzr///qs///yzwNpefvllhYeH23+uXbu21q9fr6ysLLVo0cKhbXp6uv01srKy9Oyzz+rDDz/UkSNHdPbsWaWnp6tq1aoFH4wiatiwoQICAuw/F2UfJ06cqHvvvVdLly5VeHi4BgwYoKZNm5ZIPQCAghHEAADlTrdu3RQREaEpU6YoKiqqxLefmppqD1AXuvB+rAsFBQWpWbNmubbn6uqqbdu2ydXV1WFZ9erVJUnPP/+8XnnlFc2ZM0ft2rVTtWrVNH78+EIH1nBxcZExxmFeRkZGrnbVqlXLVVNh+zhjxgzdeeed+vzzz7VmzRpNnz5dy5cv1y233FJgTQCAS0cQAwCUS7NmzVL79u3VsmVLh/mtW7fWxo0bHeZt3LhRLVq0kKurq1q1aqXMzExt27ZNnTp1kiTt3btXSUlJ9vZXXnml4uLi5ObmpkaNGl1yrR06dFBWVpYSEhLUtWvXPNts3LhRN998s+666y5JUnZ2tn7//XcFBwfb21SpUkVZWVkO6wUEBOjUqVM6ffq0PWzl3ANWkKLuY4sWLdSiRQtNmDBBgwcP1uLFiwliAGABBusAAJRL7dq1U2RkpObOneswf9KkSfr666/11FNP6ffff9fbb7+t//znP/bLGFu2bKk+ffrovvvu0+bNm7Vt2zbde++98vLysm8jPDxcYWFh6t+/v7766iv9/fff2rRpkx5//PFijRrYokULRUZGasiQIfr444+1f/9+bdmyRdHR0fr8888lSc2bN1dMTIw2bdqk3bt367777lN8fLzDdho1aqTNmzfr77//1okTJ5Sdna3Q0FBVrVpVjz32mP7880+99957DgOT5Kewffz33381ZswYrV+/XgcOHNDGjRu1detWtW7d+qL3HwBw8QhiAIBy68knn1R2drbDvCuvvFIffvihli9frrZt22ratGl68sknHS5hXLx4serUqaPu3bvr1ltv1ciRIxUYGGhfbrPZ9MUXX6hbt24aNmyYWrRooUGDBunAgQOqVatWsWpdvHixhgwZokmTJqlly5bq37+/tm7dqgYNGkiSnnjiCV155ZWKiIhQjx49FBQUpP79+zts46GHHpKrq6uCg4MVEBCggwcPyt/fX++++66++OIL+5D3M2bMKLSewvbR1dVV//zzj4YMGaIWLVpo4MCBuv766zVz5sxi7T8A4OLYzIUXngMAAAAAShU9YgAAAABgMYIYAAAAAFiMIAYAAAAAFiOIAQAAAIDFCGIAAAAAYDGCGAAAAABYjCAGAAAAABYjiAEAAACAxQhiAAAAAGAxghgAAAAAWIwgBgAAAAAW+3/91wKWyGE2OwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HOPE"
      ],
      "metadata": {
        "id": "oNeNbrv3xjgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, **node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, **edge_attributes)\n",
        "\n",
        "    return G, y.item()\n",
        "\n",
        "def balance_dataset(all_data):\n",
        "    label_0_indices = [i for i, data in enumerate(all_data) if data.y.item() == 0]\n",
        "    label_1_indices = [i for i, data in enumerate(all_data) if data.y.item() == 1]\n",
        "\n",
        "    min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "    random.shuffle(label_0_indices)\n",
        "    random.shuffle(label_1_indices)\n",
        "\n",
        "    label_0_indices = label_0_indices[:min_size_dataset]\n",
        "    label_1_indices = label_1_indices[:min_size_dataset]\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    balanced_indices = label_0_indices + label_1_indices\n",
        "    random.shuffle(balanced_indices)\n",
        "\n",
        "    balanced_data = [all_data[i] for i in balanced_indices]\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "def compute_hope_embedding(G, d=128, beta=0.01):\n",
        "    # Create adjacency matrix\n",
        "    A = nx.to_numpy_array(G)\n",
        "\n",
        "    # Compute the Katz similarity matrix\n",
        "    I = np.eye(A.shape[0])\n",
        "    S = np.linalg.inv(I - beta * A) - I\n",
        "\n",
        "    # Ensure k is valid for SVD\n",
        "    k = min(d // 2, min(S.shape) - 1)\n",
        "\n",
        "    if k <= 0:\n",
        "        # If k is invalid, return trivial embeddings\n",
        "        return np.zeros((S.shape[0], d))\n",
        "\n",
        "    # Compute SVD\n",
        "    U, s, Vt = svds(S, k=k)\n",
        "    S_sqrt = np.diag(np.sqrt(s))\n",
        "    X1 = np.dot(U, S_sqrt)\n",
        "    X2 = np.dot(Vt.T, S_sqrt)\n",
        "    X = np.concatenate((X1, X2), axis=1)\n",
        "\n",
        "    # Ensure the final embedding dimension matches d\n",
        "    if X.shape[1] < d:\n",
        "        X = np.pad(X, ((0, 0), (0, d - X.shape[1])), 'constant')\n",
        "    elif X.shape[1] > d:\n",
        "        X = X[:, :d]\n",
        "\n",
        "    return X\n",
        "\n",
        "# Generate and save embeddings for the balanced datasets\n",
        "if __name__ == \"__main__\":\n",
        "    all_graph_embeddings = []\n",
        "\n",
        "    for i in range(5):  # Loop to generate embeddings from 5 different balanced datasets\n",
        "        print(f'Generating embeddings for dataset {i + 1}')\n",
        "        balanced_data = balance_dataset(all_data)\n",
        "\n",
        "        for data in balanced_data:\n",
        "            num_nodes = data.num_nodes\n",
        "            edge_index = data.edge_index\n",
        "            edge_attr = data.edge_attr\n",
        "            x = data.x\n",
        "            y = data.y\n",
        "\n",
        "            # Create graph\n",
        "            G, y_label = create_networkx_graph(edge_index, edge_attr, x, y, num_nodes)\n",
        "\n",
        "            # Compute HOPE embeddings\n",
        "            embeddings = compute_hope_embedding(G, d=128, beta=0.01)\n",
        "\n",
        "            # Collect node embeddings and aggregate them to obtain a graph-level embedding\n",
        "            graph_embedding = np.mean(embeddings, axis=0)  # Averaging node embeddings\n",
        "            all_graph_embeddings.append((graph_embedding.tolist(), y_label))\n",
        "\n",
        "    # Convert graph-level embeddings to DataFrame\n",
        "    df_graph_embeddings = pd.DataFrame(all_graph_embeddings, columns=[\"embedding\", \"label\"])\n",
        "\n",
        "    # Save the DataFrame to a CSV file (optional)\n",
        "    df_graph_embeddings.to_csv(\"graph_embeddings.csv\", index=False)\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df_graph_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "oEJnUWgaxksk",
        "outputId": "27f7c936-8a3b-4103-bae4-ba73329c75b2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings for dataset 1\n",
            "112\n",
            "112\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-d668d5fbb62c>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Compute HOPE embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_hope_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# Collect node embeddings and aggregate them to obtain a graph-level embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-d668d5fbb62c>\u001b[0m in \u001b[0;36mcompute_hope_embedding\u001b[0;34m(G, d, beta)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Compute SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mS_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/linalg/_eigen/_svds.py\u001b[0m in \u001b[0;36msvds\u001b[0;34m(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors, solver, random_state, options)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;31m# compute the left singular vectors of X and update the right ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;31m# accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/linalg/_decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0m\u001b[1;32m    142\u001b[0m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import ast\n",
        "\n",
        "# Load the balanced dataset\n",
        "# df_graph_embeddings = pd.read_csv(\"graph_embeddings.csv\")\n",
        "\n",
        "# Extract features and labels\n",
        "def extract_features_labels(df):\n",
        "    embeddings = []\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    for emb in df['embedding']:\n",
        "        if isinstance(emb, str):\n",
        "            # Convert string representation of list back to list\n",
        "            emb = ast.literal_eval(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n",
        "\n",
        "# Assuming df_graph_embeddings is already defined and loaded\n",
        "X, y = extract_features_labels(df_graph_embeddings)\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "    raise ValueError(\"No valid embeddings found. Please check the DataFrame for formatting issues.\")\n",
        "\n",
        "# Define the neural network model\n",
        "def create_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Perform 5-fold cross-validation on the entire dataset\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "histories = []\n",
        "\n",
        "roc_aucs = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f'Fold {fold_no}')\n",
        "\n",
        "    X_train_val, X_test = X[train_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Perform an additional split to get a validation set from the training+validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Create and train the neural network\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = create_model(input_dim)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy:.4f}')\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    histories.append(history.history)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Fold {fold_no} Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_proba = model.predict(X_test).flatten()\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # Compute and store metrics\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    roc_aucs.append(roc_auc)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f'Fold {fold_no} ROC AUC: {roc_auc:.4f}')\n",
        "    print(f'Fold {fold_no} Precision: {precision:.4f}')\n",
        "    print(f'Fold {fold_no} Recall: {recall:.4f}')\n",
        "    print(f'Fold {fold_no} F1-Score: {f1:.4f}')\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Calculate and print the average metrics\n",
        "average_val_accuracy = np.mean(val_accuracies)\n",
        "variance_val_accuracy = np.var(val_accuracies)\n",
        "print(f'Average Validation Accuracy: {average_val_accuracy:.4f}')\n",
        "print(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}')\n",
        "\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "variance_test_accuracy = np.var(test_accuracies)\n",
        "print(f'Average Test Accuracy: {average_test_accuracy:.4f}')\n",
        "print(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}')\n",
        "\n",
        "average_roc_auc = np.mean(roc_aucs)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recall = np.mean(recalls)\n",
        "average_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f'Average ROC AUC: {average_roc_auc:.4f}')\n",
        "print(f'Average Precision: {average_precision:.4f}')\n",
        "print(f'Average Recall: {average_recall:.4f}')\n",
        "print(f'Average F1-Score: {average_f1:.4f}')\n",
        "\n",
        "# Save the average metrics to a file\n",
        "with open(\"model_accuracies.txt\", \"w\") as f:\n",
        "    f.write(f'Average Validation Accuracy: {average_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Average Test Accuracy: {average_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Average ROC AUC: {average_roc_auc:.4f}\\n')\n",
        "    f.write(f'Average Precision: {average_precision:.4f}\\n')\n",
        "    f.write(f'Average Recall: {average_recall:.4f}\\n')\n",
        "    f.write(f'Average F1-Score: {average_f1:.4f}\\n')\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Save training history for each fold (optional)\n",
        "with open(\"training_histories.txt\", \"w\") as f:\n",
        "    for i, history in enumerate(histories):\n",
        "        f.write(f'\\nFold {i + 1} History:\\n')\n",
        "        f.write(str(history))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Zb2A9Q1QJB",
        "outputId": "1e101474-2ab0-4496-9802-1220d50317a0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 107ms/step - loss: 0.6936 - accuracy: 0.4685 - val_loss: 0.6925 - val_accuracy: 0.5278\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6928 - accuracy: 0.5105 - val_loss: 0.6926 - val_accuracy: 0.5278\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6925 - accuracy: 0.5245 - val_loss: 0.6926 - val_accuracy: 0.5278\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6924 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5278\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6921 - val_accuracy: 0.5278\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6919 - val_accuracy: 0.5278\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6903 - accuracy: 0.5245 - val_loss: 0.6918 - val_accuracy: 0.5278\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6890 - accuracy: 0.5245 - val_loss: 0.6918 - val_accuracy: 0.5278\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6916 - accuracy: 0.5245 - val_loss: 0.6920 - val_accuracy: 0.5278\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6883 - accuracy: 0.5315 - val_loss: 0.6918 - val_accuracy: 0.5278\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6893 - accuracy: 0.5245 - val_loss: 0.6917 - val_accuracy: 0.5278\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6913 - accuracy: 0.5245 - val_loss: 0.6918 - val_accuracy: 0.5278\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6880 - accuracy: 0.5315 - val_loss: 0.6918 - val_accuracy: 0.5278\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6873 - accuracy: 0.5245 - val_loss: 0.6918 - val_accuracy: 0.5278\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6829 - accuracy: 0.5385 - val_loss: 0.6915 - val_accuracy: 0.5278\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6857 - accuracy: 0.5315 - val_loss: 0.6914 - val_accuracy: 0.5278\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.6829 - accuracy: 0.5245 - val_loss: 0.6911 - val_accuracy: 0.5278\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6807 - accuracy: 0.5315 - val_loss: 0.6910 - val_accuracy: 0.5278\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6825 - accuracy: 0.5594 - val_loss: 0.6911 - val_accuracy: 0.5278\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6826 - accuracy: 0.6014 - val_loss: 0.6907 - val_accuracy: 0.5556\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6781 - accuracy: 0.5944 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6775 - accuracy: 0.5524 - val_loss: 0.6908 - val_accuracy: 0.5278\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6737 - accuracy: 0.5524 - val_loss: 0.6909 - val_accuracy: 0.5278\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6762 - accuracy: 0.5594 - val_loss: 0.6911 - val_accuracy: 0.5278\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6761 - accuracy: 0.5734 - val_loss: 0.6915 - val_accuracy: 0.5556\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.6670 - accuracy: 0.6364 - val_loss: 0.6925 - val_accuracy: 0.5278\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6622 - accuracy: 0.6573 - val_loss: 0.6924 - val_accuracy: 0.5278\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6695 - accuracy: 0.5874 - val_loss: 0.6929 - val_accuracy: 0.5556\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6553 - accuracy: 0.6643 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6475 - accuracy: 0.6783 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6503 - accuracy: 0.7203 - val_loss: 0.6928 - val_accuracy: 0.5556\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6534 - accuracy: 0.7063 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6468 - accuracy: 0.6573 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6447 - accuracy: 0.6713 - val_loss: 0.6974 - val_accuracy: 0.4722\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6236 - accuracy: 0.6783 - val_loss: 0.6995 - val_accuracy: 0.5278\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6205 - accuracy: 0.7343 - val_loss: 0.6993 - val_accuracy: 0.5278\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6184 - accuracy: 0.6993 - val_loss: 0.7062 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6040 - accuracy: 0.7063 - val_loss: 0.7033 - val_accuracy: 0.5278\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5900 - accuracy: 0.7762 - val_loss: 0.7034 - val_accuracy: 0.5556\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5841 - accuracy: 0.7413 - val_loss: 0.7130 - val_accuracy: 0.5278\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5688 - accuracy: 0.7483 - val_loss: 0.7218 - val_accuracy: 0.5278\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5742 - accuracy: 0.7692 - val_loss: 0.7187 - val_accuracy: 0.5278\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5430 - accuracy: 0.7552 - val_loss: 0.7272 - val_accuracy: 0.5833\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5469 - accuracy: 0.7273 - val_loss: 0.7353 - val_accuracy: 0.5556\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5376 - accuracy: 0.7552 - val_loss: 0.7389 - val_accuracy: 0.5833\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5113 - accuracy: 0.7762 - val_loss: 0.7491 - val_accuracy: 0.5556\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5096 - accuracy: 0.7692 - val_loss: 0.7542 - val_accuracy: 0.5833\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5000 - accuracy: 0.7692 - val_loss: 0.7562 - val_accuracy: 0.5278\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4712 - accuracy: 0.7972 - val_loss: 0.7808 - val_accuracy: 0.5833\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4755 - accuracy: 0.7622 - val_loss: 0.7791 - val_accuracy: 0.5556\n",
            "Fold 1 Validation Accuracy: 0.5556\n",
            "Fold 1 Test Accuracy: 0.4889\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Fold 1 ROC AUC: 0.5144\n",
            "Fold 1 Precision: 0.4074\n",
            "Fold 1 Recall: 0.6111\n",
            "Fold 1 F1-Score: 0.4889\n",
            "Fold 2\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 73ms/step - loss: 0.6933 - accuracy: 0.4825 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6926 - accuracy: 0.5105 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6925 - accuracy: 0.4965 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6922 - accuracy: 0.5245 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6926 - accuracy: 0.5315 - val_loss: 0.6925 - val_accuracy: 0.5833\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6925 - accuracy: 0.5804 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5664 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6924 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6907 - accuracy: 0.5105 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6912 - accuracy: 0.5105 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6892 - accuracy: 0.5105 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6887 - accuracy: 0.5105 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6891 - accuracy: 0.5175 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6873 - accuracy: 0.5245 - val_loss: 0.6912 - val_accuracy: 0.5278\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6905 - accuracy: 0.5245 - val_loss: 0.6907 - val_accuracy: 0.5278\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6833 - accuracy: 0.5664 - val_loss: 0.6905 - val_accuracy: 0.5556\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6848 - accuracy: 0.5594 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6834 - accuracy: 0.5175 - val_loss: 0.6906 - val_accuracy: 0.5278\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6818 - accuracy: 0.5455 - val_loss: 0.6898 - val_accuracy: 0.5278\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6812 - accuracy: 0.5804 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6745 - accuracy: 0.6364 - val_loss: 0.6890 - val_accuracy: 0.5556\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6779 - accuracy: 0.5524 - val_loss: 0.6912 - val_accuracy: 0.5278\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6691 - accuracy: 0.5385 - val_loss: 0.6894 - val_accuracy: 0.5556\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6633 - accuracy: 0.6224 - val_loss: 0.6872 - val_accuracy: 0.5556\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6636 - accuracy: 0.6713 - val_loss: 0.6874 - val_accuracy: 0.5556\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6542 - accuracy: 0.6853 - val_loss: 0.6876 - val_accuracy: 0.5556\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6494 - accuracy: 0.6783 - val_loss: 0.6888 - val_accuracy: 0.5556\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6460 - accuracy: 0.6224 - val_loss: 0.6897 - val_accuracy: 0.5556\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6412 - accuracy: 0.6923 - val_loss: 0.6879 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6311 - accuracy: 0.7203 - val_loss: 0.6885 - val_accuracy: 0.5278\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6209 - accuracy: 0.7273 - val_loss: 0.6882 - val_accuracy: 0.5556\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6168 - accuracy: 0.7413 - val_loss: 0.6913 - val_accuracy: 0.4722\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6026 - accuracy: 0.6643 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5945 - accuracy: 0.7413 - val_loss: 0.6906 - val_accuracy: 0.5556\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5791 - accuracy: 0.7832 - val_loss: 0.7027 - val_accuracy: 0.5278\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5740 - accuracy: 0.7692 - val_loss: 0.6967 - val_accuracy: 0.5556\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5677 - accuracy: 0.7273 - val_loss: 0.7122 - val_accuracy: 0.5556\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.5488 - accuracy: 0.7762 - val_loss: 0.7178 - val_accuracy: 0.5833\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.5311 - accuracy: 0.7972 - val_loss: 0.7186 - val_accuracy: 0.5556\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5111 - accuracy: 0.8182 - val_loss: 0.7440 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5065 - accuracy: 0.7902 - val_loss: 0.7417 - val_accuracy: 0.5556\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.5040 - accuracy: 0.8112 - val_loss: 0.7599 - val_accuracy: 0.5278\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4852 - accuracy: 0.8112 - val_loss: 0.7713 - val_accuracy: 0.5278\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4855 - accuracy: 0.8042 - val_loss: 0.7864 - val_accuracy: 0.5833\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4632 - accuracy: 0.8322 - val_loss: 0.7848 - val_accuracy: 0.5556\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4749 - accuracy: 0.8182 - val_loss: 0.8107 - val_accuracy: 0.5556\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4536 - accuracy: 0.7972 - val_loss: 0.8219 - val_accuracy: 0.5556\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4369 - accuracy: 0.8252 - val_loss: 0.8270 - val_accuracy: 0.5278\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4092 - accuracy: 0.8252 - val_loss: 0.8864 - val_accuracy: 0.5833\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3987 - accuracy: 0.8322 - val_loss: 0.8527 - val_accuracy: 0.5278\n",
            "Fold 2 Validation Accuracy: 0.5278\n",
            "Fold 2 Test Accuracy: 0.4667\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Fold 2 ROC AUC: 0.3929\n",
            "Fold 2 Precision: 0.5000\n",
            "Fold 2 Recall: 0.5833\n",
            "Fold 2 F1-Score: 0.5385\n",
            "Fold 3\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 66ms/step - loss: 0.6934 - accuracy: 0.4685 - val_loss: 0.6928 - val_accuracy: 0.5278\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5175 - val_loss: 0.6928 - val_accuracy: 0.5278\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6930 - accuracy: 0.5175 - val_loss: 0.6928 - val_accuracy: 0.5278\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6932 - accuracy: 0.5315 - val_loss: 0.6926 - val_accuracy: 0.5278\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6914 - accuracy: 0.5245 - val_loss: 0.6925 - val_accuracy: 0.5278\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6922 - accuracy: 0.5245 - val_loss: 0.6923 - val_accuracy: 0.5278\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6912 - accuracy: 0.5245 - val_loss: 0.6922 - val_accuracy: 0.5278\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6919 - val_accuracy: 0.5278\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6903 - accuracy: 0.5245 - val_loss: 0.6919 - val_accuracy: 0.5278\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6911 - accuracy: 0.5245 - val_loss: 0.6916 - val_accuracy: 0.5278\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6913 - accuracy: 0.5245 - val_loss: 0.6916 - val_accuracy: 0.5278\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6911 - accuracy: 0.5245 - val_loss: 0.6915 - val_accuracy: 0.5278\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.5245 - val_loss: 0.6914 - val_accuracy: 0.5278\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6893 - accuracy: 0.5245 - val_loss: 0.6916 - val_accuracy: 0.5278\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6884 - accuracy: 0.5245 - val_loss: 0.6917 - val_accuracy: 0.5278\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6893 - accuracy: 0.5245 - val_loss: 0.6918 - val_accuracy: 0.5278\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6874 - accuracy: 0.5455 - val_loss: 0.6922 - val_accuracy: 0.5278\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6856 - accuracy: 0.5734 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6848 - accuracy: 0.5804 - val_loss: 0.6926 - val_accuracy: 0.5556\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6856 - accuracy: 0.5664 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6813 - accuracy: 0.6923 - val_loss: 0.6930 - val_accuracy: 0.5278\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6798 - accuracy: 0.6434 - val_loss: 0.6938 - val_accuracy: 0.4722\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6708 - accuracy: 0.7063 - val_loss: 0.6939 - val_accuracy: 0.4722\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6747 - accuracy: 0.6573 - val_loss: 0.6946 - val_accuracy: 0.4722\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6689 - accuracy: 0.6923 - val_loss: 0.6957 - val_accuracy: 0.4722\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6642 - accuracy: 0.6853 - val_loss: 0.6965 - val_accuracy: 0.4722\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6556 - accuracy: 0.6993 - val_loss: 0.6980 - val_accuracy: 0.4722\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6524 - accuracy: 0.6853 - val_loss: 0.7010 - val_accuracy: 0.4722\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6472 - accuracy: 0.7203 - val_loss: 0.7050 - val_accuracy: 0.5556\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6427 - accuracy: 0.7343 - val_loss: 0.7069 - val_accuracy: 0.4167\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6288 - accuracy: 0.6993 - val_loss: 0.7123 - val_accuracy: 0.4722\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6162 - accuracy: 0.7413 - val_loss: 0.7184 - val_accuracy: 0.5556\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5997 - accuracy: 0.7622 - val_loss: 0.7253 - val_accuracy: 0.4167\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6123 - accuracy: 0.7343 - val_loss: 0.7334 - val_accuracy: 0.4722\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5747 - accuracy: 0.7692 - val_loss: 0.7473 - val_accuracy: 0.5278\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5637 - accuracy: 0.7902 - val_loss: 0.7607 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5463 - accuracy: 0.7762 - val_loss: 0.7690 - val_accuracy: 0.3889\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5580 - accuracy: 0.7622 - val_loss: 0.7875 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.5356 - accuracy: 0.7622 - val_loss: 0.8015 - val_accuracy: 0.4167\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5412 - accuracy: 0.7413 - val_loss: 0.8171 - val_accuracy: 0.4444\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5337 - accuracy: 0.7413 - val_loss: 0.8379 - val_accuracy: 0.4722\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4880 - accuracy: 0.7972 - val_loss: 0.8426 - val_accuracy: 0.4444\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4860 - accuracy: 0.8112 - val_loss: 0.8600 - val_accuracy: 0.4444\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4820 - accuracy: 0.8042 - val_loss: 0.8957 - val_accuracy: 0.4167\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4522 - accuracy: 0.8252 - val_loss: 0.9203 - val_accuracy: 0.4167\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4345 - accuracy: 0.8252 - val_loss: 0.9457 - val_accuracy: 0.4167\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4331 - accuracy: 0.8462 - val_loss: 0.9626 - val_accuracy: 0.4444\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4472 - accuracy: 0.7902 - val_loss: 0.9803 - val_accuracy: 0.4722\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4273 - accuracy: 0.7762 - val_loss: 0.9925 - val_accuracy: 0.4444\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4144 - accuracy: 0.8042 - val_loss: 1.0126 - val_accuracy: 0.3889\n",
            "Fold 3 Validation Accuracy: 0.3889\n",
            "Fold 3 Test Accuracy: 0.4222\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Fold 3 ROC AUC: 0.4486\n",
            "Fold 3 Precision: 0.3571\n",
            "Fold 3 Recall: 0.5556\n",
            "Fold 3 F1-Score: 0.4348\n",
            "Fold 4\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 2s 103ms/step - loss: 0.6933 - accuracy: 0.4615 - val_loss: 0.6928 - val_accuracy: 0.5278\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6924 - accuracy: 0.5105 - val_loss: 0.6925 - val_accuracy: 0.5278\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6923 - accuracy: 0.5315 - val_loss: 0.6924 - val_accuracy: 0.5278\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6931 - accuracy: 0.5035 - val_loss: 0.6923 - val_accuracy: 0.5278\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6918 - accuracy: 0.5315 - val_loss: 0.6923 - val_accuracy: 0.5278\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6923 - val_accuracy: 0.5278\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6900 - accuracy: 0.5385 - val_loss: 0.6921 - val_accuracy: 0.5278\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6913 - accuracy: 0.5315 - val_loss: 0.6920 - val_accuracy: 0.5278\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6914 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5278\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6901 - accuracy: 0.5105 - val_loss: 0.6921 - val_accuracy: 0.5278\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6913 - accuracy: 0.5245 - val_loss: 0.6923 - val_accuracy: 0.5278\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6891 - accuracy: 0.5315 - val_loss: 0.6928 - val_accuracy: 0.5278\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6883 - accuracy: 0.5664 - val_loss: 0.6931 - val_accuracy: 0.5278\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6863 - accuracy: 0.5804 - val_loss: 0.6929 - val_accuracy: 0.5278\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6879 - accuracy: 0.5385 - val_loss: 0.6928 - val_accuracy: 0.5278\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6853 - accuracy: 0.5315 - val_loss: 0.6932 - val_accuracy: 0.5278\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6843 - accuracy: 0.5524 - val_loss: 0.6933 - val_accuracy: 0.5278\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6791 - accuracy: 0.5594 - val_loss: 0.6937 - val_accuracy: 0.5278\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6790 - accuracy: 0.5804 - val_loss: 0.6942 - val_accuracy: 0.5278\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6783 - accuracy: 0.5804 - val_loss: 0.6951 - val_accuracy: 0.5278\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6730 - accuracy: 0.5734 - val_loss: 0.6960 - val_accuracy: 0.5278\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6733 - accuracy: 0.6154 - val_loss: 0.6970 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6605 - accuracy: 0.6993 - val_loss: 0.6983 - val_accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6628 - accuracy: 0.7692 - val_loss: 0.6997 - val_accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6596 - accuracy: 0.7203 - val_loss: 0.7019 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6468 - accuracy: 0.6783 - val_loss: 0.7056 - val_accuracy: 0.5556\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6444 - accuracy: 0.6923 - val_loss: 0.7091 - val_accuracy: 0.3889\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6251 - accuracy: 0.8112 - val_loss: 0.7132 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6270 - accuracy: 0.6643 - val_loss: 0.7180 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6194 - accuracy: 0.7273 - val_loss: 0.7245 - val_accuracy: 0.4444\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6102 - accuracy: 0.7972 - val_loss: 0.7324 - val_accuracy: 0.3611\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5850 - accuracy: 0.7832 - val_loss: 0.7421 - val_accuracy: 0.4167\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6068 - accuracy: 0.6853 - val_loss: 0.7514 - val_accuracy: 0.5278\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5647 - accuracy: 0.7483 - val_loss: 0.7653 - val_accuracy: 0.3889\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5682 - accuracy: 0.7692 - val_loss: 0.7718 - val_accuracy: 0.3889\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5380 - accuracy: 0.7902 - val_loss: 0.7885 - val_accuracy: 0.4722\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5241 - accuracy: 0.8252 - val_loss: 0.7979 - val_accuracy: 0.4167\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4961 - accuracy: 0.8322 - val_loss: 0.8165 - val_accuracy: 0.4722\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4775 - accuracy: 0.8392 - val_loss: 0.8401 - val_accuracy: 0.4722\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4570 - accuracy: 0.8601 - val_loss: 0.8650 - val_accuracy: 0.4444\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4484 - accuracy: 0.8601 - val_loss: 0.8942 - val_accuracy: 0.4444\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4339 - accuracy: 0.8462 - val_loss: 0.9171 - val_accuracy: 0.4167\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4158 - accuracy: 0.8322 - val_loss: 0.9485 - val_accuracy: 0.4167\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4127 - accuracy: 0.8462 - val_loss: 0.9663 - val_accuracy: 0.4167\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.8601 - val_loss: 0.9919 - val_accuracy: 0.4444\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3861 - accuracy: 0.8881 - val_loss: 1.0238 - val_accuracy: 0.4167\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3542 - accuracy: 0.8531 - val_loss: 1.0559 - val_accuracy: 0.4167\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3786 - accuracy: 0.8601 - val_loss: 1.0877 - val_accuracy: 0.4444\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3315 - accuracy: 0.8881 - val_loss: 1.1195 - val_accuracy: 0.4167\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3263 - accuracy: 0.9021 - val_loss: 1.1472 - val_accuracy: 0.4167\n",
            "Fold 4 Validation Accuracy: 0.4167\n",
            "Fold 4 Test Accuracy: 0.5333\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Fold 4 ROC AUC: 0.4656\n",
            "Fold 4 Precision: 0.5862\n",
            "Fold 4 Recall: 0.6538\n",
            "Fold 4 F1-Score: 0.6182\n",
            "Fold 5\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 68ms/step - loss: 0.6936 - accuracy: 0.4444 - val_loss: 0.6931 - val_accuracy: 0.4444\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6930 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.4444\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6927 - accuracy: 0.5625 - val_loss: 0.6932 - val_accuracy: 0.4722\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6926 - accuracy: 0.5625 - val_loss: 0.6931 - val_accuracy: 0.4722\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6928 - accuracy: 0.5278 - val_loss: 0.6931 - val_accuracy: 0.5278\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5347 - val_loss: 0.6926 - val_accuracy: 0.5278\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6920 - accuracy: 0.5417 - val_loss: 0.6922 - val_accuracy: 0.5278\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5278\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6902 - accuracy: 0.5208 - val_loss: 0.6916 - val_accuracy: 0.5278\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5208 - val_loss: 0.6914 - val_accuracy: 0.5278\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6880 - accuracy: 0.5208 - val_loss: 0.6909 - val_accuracy: 0.5278\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6926 - accuracy: 0.5208 - val_loss: 0.6907 - val_accuracy: 0.5278\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6875 - accuracy: 0.5347 - val_loss: 0.6907 - val_accuracy: 0.5278\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6892 - accuracy: 0.5069 - val_loss: 0.6903 - val_accuracy: 0.5278\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.5347 - val_loss: 0.6900 - val_accuracy: 0.5278\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6865 - accuracy: 0.5694 - val_loss: 0.6898 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6894 - accuracy: 0.5417 - val_loss: 0.6897 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6858 - accuracy: 0.5833 - val_loss: 0.6892 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6787 - accuracy: 0.6042 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6846 - accuracy: 0.6042 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6795 - accuracy: 0.5625 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6812 - accuracy: 0.6319 - val_loss: 0.6865 - val_accuracy: 0.4722\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6794 - accuracy: 0.6042 - val_loss: 0.6860 - val_accuracy: 0.5556\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6741 - accuracy: 0.6875 - val_loss: 0.6848 - val_accuracy: 0.5278\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6750 - accuracy: 0.6528 - val_loss: 0.6844 - val_accuracy: 0.4722\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6653 - accuracy: 0.6319 - val_loss: 0.6848 - val_accuracy: 0.5278\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6586 - accuracy: 0.7153 - val_loss: 0.6829 - val_accuracy: 0.5278\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6536 - accuracy: 0.7292 - val_loss: 0.6833 - val_accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6519 - accuracy: 0.6806 - val_loss: 0.6854 - val_accuracy: 0.5278\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6453 - accuracy: 0.6944 - val_loss: 0.6844 - val_accuracy: 0.5278\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6407 - accuracy: 0.6875 - val_loss: 0.6804 - val_accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6287 - accuracy: 0.7292 - val_loss: 0.6811 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6364 - accuracy: 0.7083 - val_loss: 0.6849 - val_accuracy: 0.5278\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6223 - accuracy: 0.7153 - val_loss: 0.6805 - val_accuracy: 0.5556\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6068 - accuracy: 0.7153 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5931 - accuracy: 0.6736 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5837 - accuracy: 0.7569 - val_loss: 0.6878 - val_accuracy: 0.5833\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5771 - accuracy: 0.7708 - val_loss: 0.6948 - val_accuracy: 0.5278\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5724 - accuracy: 0.7222 - val_loss: 0.7057 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5684 - accuracy: 0.7431 - val_loss: 0.6948 - val_accuracy: 0.6111\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5615 - accuracy: 0.7639 - val_loss: 0.7012 - val_accuracy: 0.6111\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5539 - accuracy: 0.7361 - val_loss: 0.7394 - val_accuracy: 0.5278\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5207 - accuracy: 0.7778 - val_loss: 0.7069 - val_accuracy: 0.6111\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5302 - accuracy: 0.7986 - val_loss: 0.7163 - val_accuracy: 0.6111\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4738 - accuracy: 0.8194 - val_loss: 0.7509 - val_accuracy: 0.5278\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5004 - accuracy: 0.7500 - val_loss: 0.7565 - val_accuracy: 0.5278\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5051 - accuracy: 0.7778 - val_loss: 0.7473 - val_accuracy: 0.6111\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5227 - accuracy: 0.7569 - val_loss: 0.7664 - val_accuracy: 0.5556\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4832 - accuracy: 0.7986 - val_loss: 0.7608 - val_accuracy: 0.5833\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4923 - accuracy: 0.7639 - val_loss: 0.8013 - val_accuracy: 0.5278\n",
            "Fold 5 Validation Accuracy: 0.5278\n",
            "Fold 5 Test Accuracy: 0.3409\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Fold 5 ROC AUC: 0.4722\n",
            "Fold 5 Precision: 0.3333\n",
            "Fold 5 Recall: 0.1154\n",
            "Fold 5 F1-Score: 0.1714\n",
            "Average Validation Accuracy: 0.4833\n",
            "Variance of Validation Accuracy: 0.0045\n",
            "Average Test Accuracy: 0.4504\n",
            "Variance of Test Accuracy: 0.0043\n",
            "Average ROC AUC: 0.4587\n",
            "Average Precision: 0.4368\n",
            "Average Recall: 0.5038\n",
            "Average F1-Score: 0.4503\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_176 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_132 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_133 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_134 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26881 (105.00 KB)\n",
            "Trainable params: 26881 (105.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uujWvez105h-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2C1O3XD3xibZ",
        "pZBWOStOXUU8",
        "-Bs0fWiRsIlL",
        "oNeNbrv3xjgL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}