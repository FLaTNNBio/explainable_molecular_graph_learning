{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Experiments on GNNs and Graph Embeddings\n",
        "Experiments conducted to evaluate various GNNs and graph embedding methods for molecular classification tasks by leveraging well-known benchmarking datasets in SMILES format, i.e., HIV, BBBP, BACE, CLINTOX. Extensively used in the literature to benchmark models for molecular property prediction and drug discovery tasks. We systematically tested and compared various GNN architectures and traditional graph embedding techniques. For each dataset, we evaluated their performance to identify strengths and limitations in predicting molecular properties. We trained several different GNNs to assess their performance on the aforementioned datasets: Graph Convolutional Network (GCN), Graph Isomorphism Network (GIN), and Graph Attention Network (GAT). As for the graph embedding methods, also in this case we provide details about the models that achieved the best performance, i.e, a Fully Connected Neural Network using three well-known graph embedding techniques as input: Node2Vec, SDNE, and HOPE."
      ],
      "metadata": {
        "id": "kGbMIPsO9SEq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtVle8RHNqON"
      },
      "source": [
        "# Installation and Common Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLTzxU_DNzLi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install pysmiles\n",
        "  !pip install git+https://github.com/VenkateshwaranB/stellargraph.git\n",
        "  !pip install rdkit\n",
        "  !pip install torch_geometric\n",
        "  !pip install datasets\n",
        "  !pip3 install mxnet-mkl==1.6.0 numpy==1.23.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcuv1AHaNqOR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stellargraph import datasets\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv8jU7ilW-6t"
      },
      "outputs": [],
      "source": [
        "!pip install ogb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the script is runned on colab and the dataset are saved on the drive is possible to mount the drive in order to dowload from the drive"
      ],
      "metadata": {
        "id": "LwlFi6nUSOyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2IcVbx3jwCr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C1O3XD3xibZ"
      },
      "source": [
        "###Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download the HIV Dataset from OGBG"
      ],
      "metadata": {
        "id": "i1ACg7kHSR34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjfW3Bz-qAr-"
      },
      "outputs": [],
      "source": [
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
        "\n",
        "#qua sta anche clintox e altri vedere bene documntazione però il codice funziona anche con uun proprio dataset, però il clintox ha la y diversa dalla nostra quindi in molti casi conviene avere a che fare con db propri, dove settiamo noi la y per bene e usiamo lo script SMILEs-MOL-OGB\n",
        "all_data = dataset[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load experimental .pt dataset: Choose pre-processed *dataset.pt* (clintox.pt, bace_classification.pt, bbbp.pt) from Experiments/exp_datasets and replace the path *content/exp_dataset/dataset.pt* with the choosen dataset."
      ],
      "metadata": {
        "id": "o2wNm_oISWgA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4sCu2-XWLin"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch_geometric\n",
        "# Load Data object from file\n",
        "#COLAB DRIVE:/content/dive/MyDrive/exp_datasets/clintox.pt\n",
        "with open('/content/exp_datasets/clintox.pt', 'rb') as f:\n",
        "    all_data = pickle.load(f)\n",
        "\n",
        "# Now loaded_data contains the Data object\n",
        "print(all_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create NetworkX graph"
      ],
      "metadata": {
        "id": "5P8z0ytkLFpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzQS4IfKzcC9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import stellargraph as sg\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "from stellargraph.data import BiasedRandomWalk\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, features=node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, attributes=edge_attributes)\n",
        "\n",
        "    return G, y.item()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
        "    \"\"\"\n",
        "    Plots the confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (list or array): True labels.\n",
        "    y_pred (list or array): Predicted labels.\n",
        "    class_names (list): List of class names. If None, integer labels are used.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# y_true = [0, 1, 1, 0, 1, 0]\n",
        "# y_pred = [0, 1, 0, 0, 1, 1]\n",
        "# class_names = ['Class 0', 'Class 1']\n",
        "# plot_confusion_matrix(y_true, y_pred, class_names)\n"
      ],
      "metadata": {
        "id": "e_Ix2PETlKT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZBWOStOXUU8"
      },
      "source": [
        "#Node2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxkjURhnXcIv"
      },
      "source": [
        "Construction of the dataset using Stellargraph and Node2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import copy\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np  # Import numpy for numerical operations\n",
        "\n",
        "label_0_indices = []\n",
        "label_1_indices = []\n",
        "dfs = []\n",
        "\n",
        "for i in range(len(all_data)):\n",
        "    if all_data[i].y == 0:\n",
        "        label_0_indices.append(i)\n",
        "    elif all_data[i].y == 1:\n",
        "        label_1_indices.append(i)\n",
        "\n",
        "for iter in range(1):\n",
        "    print('iter:', iter)\n",
        "\n",
        "    min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "    random.shuffle(label_0_indices)\n",
        "    random.shuffle(label_1_indices)\n",
        "    label_0_indices = label_0_indices[:min_size_dataset]\n",
        "    label_1_indices = label_1_indices[:min_size_dataset]\n",
        "    print('size 0 data:', len(label_0_indices))\n",
        "    print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "    balanced_indices = label_0_indices + label_1_indices\n",
        "    print('size total dataset:', len(balanced_indices))\n",
        "\n",
        "    balanced_data = [all_data[i] for i in balanced_indices]\n",
        "    print(len(balanced_data))\n",
        "\n",
        "    df = pd.DataFrame(columns=['graph_emb', 'label'])\n",
        "\n",
        "    for dtb in balanced_data:\n",
        "        graph, y = create_networkx_graph(dtb.edge_index, dtb.edge_attr, dtb.x, dtb.y, dtb.num_nodes)\n",
        "\n",
        "        # Convert node features to DataFrame\n",
        "        node_features_dict = {node: graph.nodes[node]['features'] for node in graph.nodes}\n",
        "        node_df = pd.DataFrame.from_dict(node_features_dict, orient='index')\n",
        "\n",
        "        # Convert edge attributes to DataFrame\n",
        "        edge_features_dict = {(src, dst): data['attributes'] for src, dst, data in graph.edges(data=True)}\n",
        "        edge_df = pd.DataFrame.from_dict(edge_features_dict, orient='index')\n",
        "\n",
        "        # Create 'source', 'target' columns in the edge DataFrame\n",
        "        edge_df['source'] = [edge[0] for edge in edge_df.index]\n",
        "        edge_df['target'] = [edge[1] for edge in edge_df.index]\n",
        "\n",
        "        # Create a StellarGraph from the NetworkX graph and DataFrames\n",
        "        Gs = sg.StellarGraph(nodes=node_df, edges=edge_df)\n",
        "\n",
        "        rw = BiasedRandomWalk(Gs)\n",
        "\n",
        "        walks = rw.run(\n",
        "            nodes=list(Gs.nodes()),  # root nodes\n",
        "            length=100,  # maximum length of a random walk\n",
        "            n=10,  # number of random walks per root node\n",
        "            p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
        "            q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
        "            weighted=True,\n",
        "            seed=42\n",
        "        )\n",
        "\n",
        "        str_walks = [[str(n) for n in walk] for walk in walks]\n",
        "        model = Word2Vec(str_walks, window=5, min_count=0, sg=1, workers=2)\n",
        "\n",
        "        # Retrieve node embeddings and corresponding subjects\n",
        "        node_ids = model.wv.index_to_key  # list of node IDs\n",
        "        node_embeddings = model.wv.vectors  # numpy.ndarray of size number of nodes times embeddings dimensionality\n",
        "\n",
        "        # Aggregate node embeddings to form a single graph embedding\n",
        "        # Example using average pooling\n",
        "        graph_embedding = np.mean(node_embeddings, axis=0)  # Change this line for different pooling methods\n",
        "\n",
        "        # Store the graph embedding and label in the DataFrame\n",
        "        df.loc[len(df)] = [graph_embedding, y]\n",
        "\n",
        "    dfs.append(df)\n"
      ],
      "metadata": {
        "id": "OLrYMD0zXe0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Udl-HSNsLnu"
      },
      "source": [
        "Below there is the creation and training of the model from the Node2Vec Embedding\n",
        "\n",
        "The performace and the confusion matrix are showed at the end of the training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import ast\n",
        "\n",
        "\n",
        "# Extract features and labels\n",
        "def extract_features_labels(df):\n",
        "    embeddings = []\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    for emb in df['graph_emb']:\n",
        "        if isinstance(emb, str):\n",
        "            # Convert string representation of list back to list\n",
        "            emb = ast.literal_eval(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n",
        "\n",
        "X, y = extract_features_labels(df)\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "    raise ValueError(\"No valid embeddings found. Please check the DataFrame for formatting issues.\")\n",
        "\n",
        "# Define the neural network model\n",
        "def create_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Perform 5-fold cross-validation on the entire dataset\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "roc_aucs = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "histories = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f'Fold {fold_no}')\n",
        "\n",
        "    X_train_val, X_test = X[train_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Perform an additional split to get a validation set from the training+validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Create and train the neural network\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = create_model(input_dim)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy:.4f}')\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    histories.append(history.history)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Fold {fold_no} Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Predict probabilities and calculate metrics for the test set\n",
        "    y_test_pred_proba = model.predict(X_test).flatten()\n",
        "    y_test_pred = (y_test_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f'Fold {fold_no} ROC-AUC: {roc_auc:.4f}')\n",
        "    print(f'Fold {fold_no} Precision: {precision:.4f}')\n",
        "    print(f'Fold {fold_no} Recall: {recall:.4f}')\n",
        "    print(f'Fold {fold_no} F1-Score: {f1:.4f}')\n",
        "\n",
        "    roc_aucs.append(roc_auc)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Plot confusion matrix for each fold\n",
        "    plot_confusion_matrix(y_test, y_test_pred, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Calculate and print the average validation accuracy and variance\n",
        "average_val_accuracy = np.mean(val_accuracies)\n",
        "variance_val_accuracy = np.var(val_accuracies)\n",
        "print(f'Average Validation Accuracy: {average_val_accuracy:.4f}')\n",
        "print(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}')\n",
        "\n",
        "# Calculate and print the average test accuracy and variance\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "variance_test_accuracy = np.var(test_accuracies)\n",
        "print(f'Average Test Accuracy: {average_test_accuracy:.4f}')\n",
        "print(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}')\n",
        "\n",
        "# Calculate and print the average ROC-AUC, Precision, Recall, and F1-Score\n",
        "average_roc_auc = np.mean(roc_aucs)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recall = np.mean(recalls)\n",
        "average_f1_score = np.mean(f1_scores)\n",
        "\n",
        "print(f'Average ROC-AUC: {average_roc_auc:.4f}')\n",
        "print(f'Average Precision: {average_precision:.4f}')\n",
        "print(f'Average Recall: {average_recall:.4f}')\n",
        "print(f'Average F1-Score: {average_f1_score:.4f}')\n",
        "\n",
        "# Save the average validation accuracy, variance, test accuracy, and metrics to a file\n",
        "with open(\"model_accuracies.txt\", \"w\") as f:\n",
        "    f.write(f'Average Validation Accuracy: {average_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Average Test Accuracy: {average_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Average ROC-AUC: {average_roc_auc:.4f}\\n')\n",
        "    f.write(f'Average Precision: {average_precision:.4f}\\n')\n",
        "    f.write(f'Average Recall: {average_recall:.4f}\\n')\n",
        "    f.write(f'Average F1-Score: {average_f1_score:.4f}\\n')"
      ],
      "metadata": {
        "id": "3t2Ai9fbd04S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SDNE"
      ],
      "metadata": {
        "id": "-Bs0fWiRsIlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation for SDNE Experiment, the dataset is well-balanced and read to train the SDNE Model and embedding extraction from the model"
      ],
      "metadata": {
        "id": "qzDLTttsTF5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch import nn, optim\n",
        "\n",
        "# Assuming 'all_data' is already defined and contains the graph data\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, **node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, **edge_attributes)\n",
        "\n",
        "    return G, y.item()\n",
        "\n",
        "class SDNE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, alpha=1e-5, beta=5):\n",
        "        super(SDNE, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dims[1], hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dims[0], input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # Encode\n",
        "        y = self.encoder(x)\n",
        "        # Decode\n",
        "        x_hat = self.decoder(y)\n",
        "        return x_hat, y\n",
        "\n",
        "    def loss_function(self, x, x_hat, y, adj):\n",
        "        # Reconstruction loss\n",
        "        mse = nn.MSELoss()\n",
        "        L_1st = mse(x_hat, x)\n",
        "\n",
        "        # Laplacian regularization\n",
        "        L_2nd = torch.sum(adj * torch.norm(y.unsqueeze(1) - y, dim=2))\n",
        "\n",
        "        return L_1st + self.alpha * L_1st + self.beta * L_2nd\n",
        "\n",
        "def train_sdne(graph, hidden_dims=[128, 64], epochs=100, lr=0.01):\n",
        "    # Create adjacency matrix\n",
        "    adj = nx.adjacency_matrix(graph).todense()\n",
        "    adj = torch.tensor(adj, dtype=torch.float32)\n",
        "\n",
        "    # Get node features\n",
        "    node_features = np.array([list(graph.nodes[i].values()) for i in range(graph.number_of_nodes())])\n",
        "\n",
        "    # Check if node features are empty\n",
        "    if node_features.shape[1] == 0:\n",
        "        raise ValueError(\"Node features are empty. Ensure nodes have features.\")\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    node_features = scaler.fit_transform(node_features)\n",
        "    node_features = torch.tensor(node_features, dtype=torch.float32)\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = node_features.shape[1]\n",
        "    model = SDNE(input_dim, hidden_dims)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, y = model(node_features, adj)\n",
        "        loss = model.loss_function(node_features, x_hat, y, adj)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #if (epoch + 1) % 10 == 0:\n",
        "            #print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    return model, y\n",
        "\n",
        "def balance_dataset(all_data, seed=42):\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    label_0_indices = [i for i, data in enumerate(all_data) if data.y.item() == 0]\n",
        "    label_1_indices = [i for i, data in enumerate(all_data) if data.y.item() == 1]\n",
        "\n",
        "    min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "    random.shuffle(label_0_indices)\n",
        "    random.shuffle(label_1_indices)\n",
        "\n",
        "    label_0_indices = label_0_indices[:min_size_dataset]\n",
        "    label_1_indices = label_1_indices[:min_size_dataset]\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    balanced_indices = label_0_indices + label_1_indices\n",
        "    random.shuffle(balanced_indices)\n",
        "\n",
        "    balanced_data = [all_data[i] for i in balanced_indices]\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "# Generate and save embeddings for the balanced datasets\n",
        "if __name__ == \"__main__\":\n",
        "    all_graph_embeddings = []\n",
        "\n",
        "    for i in range(1):  # Loop to generate 5 different datasets\n",
        "        print(f'Generating dataset {i + 1}')\n",
        "        balanced_data = balance_dataset(all_data)\n",
        "\n",
        "        for data in balanced_data:\n",
        "            num_nodes = data.num_nodes\n",
        "            edge_index = data.edge_index\n",
        "            edge_attr = data.edge_attr\n",
        "            x = data.x\n",
        "            y = data.y\n",
        "\n",
        "            # Create graph\n",
        "            G, y_label = create_networkx_graph(edge_index, edge_attr, x, y, num_nodes)\n",
        "\n",
        "            # Train SDNE\n",
        "            model, embeddings = train_sdne(G, epochs=100)\n",
        "\n",
        "            # Collect node embeddings and aggregate them to obtain a graph-level embedding\n",
        "            embeddings_np = embeddings.detach().numpy()\n",
        "            graph_embedding = np.mean(embeddings_np, axis=0)  # Averaging node embeddings\n",
        "            all_graph_embeddings.append((graph_embedding.tolist(), y_label))\n",
        "\n",
        "    # Convert graph-level embeddings to DataFrame\n",
        "    df_graph_embeddings = pd.DataFrame(all_graph_embeddings, columns=[\"embedding\", \"label\"])\n",
        "\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df_graph_embeddings)\n"
      ],
      "metadata": {
        "id": "xxLnsdjK-Y2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and evaluation of the Fully Connected model on the SDNE Embedding"
      ],
      "metadata": {
        "id": "CuvoBEM_qYBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import ast\n",
        "\n",
        "\n",
        "# Extract features and labels\n",
        "def extract_features_labels(df):\n",
        "    embeddings = []\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    for emb in df['embedding']:\n",
        "        if isinstance(emb, str):\n",
        "            # Convert string representation of list back to list\n",
        "            emb = ast.literal_eval(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n",
        "\n",
        "X, y = extract_features_labels(df_graph_embeddings)\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "    raise ValueError(\"No valid embeddings found. Please check the DataFrame for formatting issues.\")\n",
        "\n",
        "# Define the neural network model\n",
        "def create_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Perform 5-fold cross-validation on the entire dataset\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "roc_aucs = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "histories = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f'Fold {fold_no}')\n",
        "\n",
        "    X_train_val, X_test = X[train_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Perform an additional split to get a validation set from the training+validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Create and train the neural network\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = create_model(input_dim)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy:.4f}')\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    histories.append(history.history)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Fold {fold_no} Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Predict probabilities and calculate metrics for the test set\n",
        "    y_test_pred_proba = model.predict(X_test).flatten()\n",
        "    y_test_pred = (y_test_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f'Fold {fold_no} ROC-AUC: {roc_auc:.4f}')\n",
        "    print(f'Fold {fold_no} Precision: {precision:.4f}')\n",
        "    print(f'Fold {fold_no} Recall: {recall:.4f}')\n",
        "    print(f'Fold {fold_no} F1-Score: {f1:.4f}')\n",
        "\n",
        "    roc_aucs.append(roc_auc)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Plot confusion matrix for each fold\n",
        "    plot_confusion_matrix(y_test, y_test_pred, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Calculate and print the average validation accuracy and variance\n",
        "average_val_accuracy = np.mean(val_accuracies)\n",
        "variance_val_accuracy = np.var(val_accuracies)\n",
        "print(f'Average Validation Accuracy: {average_val_accuracy:.4f}')\n",
        "print(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}')\n",
        "\n",
        "# Calculate and print the average test accuracy and variance\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "variance_test_accuracy = np.var(test_accuracies)\n",
        "print(f'Average Test Accuracy: {average_test_accuracy:.4f}')\n",
        "print(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}')\n",
        "\n",
        "# Calculate and print the average ROC-AUC, Precision, Recall, and F1-Score\n",
        "average_roc_auc = np.mean(roc_aucs)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recall = np.mean(recalls)\n",
        "average_f1_score = np.mean(f1_scores)\n",
        "\n",
        "print(f'Average ROC-AUC: {average_roc_auc:.4f}')\n",
        "print(f'Average Precision: {average_precision:.4f}')\n",
        "print(f'Average Recall: {average_recall:.4f}')\n",
        "print(f'Average F1-Score: {average_f1_score:.4f}')\n",
        "\n",
        "# Save the average validation accuracy, variance, test accuracy, and metrics to a file\n",
        "with open(\"model_accuracies.txt\", \"w\") as f:\n",
        "    f.write(f'Average Validation Accuracy: {average_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Average Test Accuracy: {average_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Average ROC-AUC: {average_roc_auc:.4f}\\n')\n",
        "    f.write(f'Average Precision: {average_precision:.4f}\\n')\n",
        "    f.write(f'Average Recall: {average_recall:.4f}\\n')\n",
        "    f.write(f'Average F1-Score: {average_f1_score:.4f}\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "EAqVMiFSQA_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HOPE"
      ],
      "metadata": {
        "id": "oNeNbrv3xjgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation for HOPE Experiment, the datasets will presents the embedding of the graph using the HOPE Techniques"
      ],
      "metadata": {
        "id": "a9AV-8VNTfS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "def create_networkx_graph(edge_index, edge_attr, x, y, num_nodes):\n",
        "    # Create an empty NetworkX graph\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes with features\n",
        "    for i in range(num_nodes):\n",
        "        node_features = {f\"feat_{j}\": x[i, j].item() for j in range(x.shape[1])}\n",
        "        G.add_node(i, **node_features)\n",
        "\n",
        "    # Add edges with attributes\n",
        "    for j in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[:, j].tolist()\n",
        "        edge_attributes = {f\"attr_{k}\": edge_attr[j, k].item() for k in range(edge_attr.shape[1])}\n",
        "        G.add_edge(src, dst, **edge_attributes)\n",
        "\n",
        "    return G, y.item()\n",
        "\n",
        "def balance_dataset(all_data, seed=42):\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    label_0_indices = [i for i, data in enumerate(all_data) if data.y.item() == 0]\n",
        "    label_1_indices = [i for i, data in enumerate(all_data) if data.y.item() == 1]\n",
        "\n",
        "    min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "    random.shuffle(label_0_indices)\n",
        "    random.shuffle(label_1_indices)\n",
        "\n",
        "    label_0_indices = label_0_indices[:min_size_dataset]\n",
        "    label_1_indices = label_1_indices[:min_size_dataset]\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    balanced_indices = label_0_indices + label_1_indices\n",
        "    random.shuffle(balanced_indices)\n",
        "\n",
        "    balanced_data = [all_data[i] for i in balanced_indices]\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "def compute_hope_embedding(G, d=128, beta=0.01):\n",
        "    # Create adjacency matrix\n",
        "    A = nx.to_numpy_array(G)\n",
        "\n",
        "    # Compute the Katz similarity matrix\n",
        "    I = np.eye(A.shape[0])\n",
        "    S = np.linalg.inv(I - beta * A) - I\n",
        "\n",
        "    # Ensure k is valid for SVD\n",
        "    k = min(d // 2, min(S.shape) - 1)\n",
        "\n",
        "    if k <= 0:\n",
        "        # If k is invalid, return trivial embeddings\n",
        "        return np.zeros((S.shape[0], d))\n",
        "\n",
        "    # Compute SVD\n",
        "    U, s, Vt = svds(S, k=k)\n",
        "    S_sqrt = np.diag(np.sqrt(s))\n",
        "    X1 = np.dot(U, S_sqrt)\n",
        "    X2 = np.dot(Vt.T, S_sqrt)\n",
        "    X = np.concatenate((X1, X2), axis=1)\n",
        "\n",
        "    # Ensure the final embedding dimension matches d\n",
        "    if X.shape[1] < d:\n",
        "        X = np.pad(X, ((0, 0), (0, d - X.shape[1])), 'constant')\n",
        "    elif X.shape[1] > d:\n",
        "        X = X[:, :d]\n",
        "\n",
        "    return X\n",
        "\n",
        "# Generate and save embeddings for the balanced datasets\n",
        "if __name__ == \"__main__\":\n",
        "    all_graph_embeddings = []\n",
        "\n",
        "    for i in range(1):  # Loop to generate embeddings from 5 different balanced datasets\n",
        "        print(f'Generating embeddings for dataset {i + 1}')\n",
        "        balanced_data = balance_dataset(all_data)\n",
        "\n",
        "        for data in balanced_data:\n",
        "            num_nodes = data.num_nodes\n",
        "            edge_index = data.edge_index\n",
        "            edge_attr = data.edge_attr\n",
        "            x = data.x\n",
        "            y = data.y\n",
        "\n",
        "            # Create graph\n",
        "            G, y_label = create_networkx_graph(edge_index, edge_attr, x, y, num_nodes)\n",
        "\n",
        "            # Compute HOPE embeddings\n",
        "            embeddings = compute_hope_embedding(G, d=128, beta=0.01)\n",
        "\n",
        "            # Collect node embeddings and aggregate them to obtain a graph-level embedding\n",
        "            graph_embedding = np.mean(embeddings, axis=0)  # Averaging node embeddings\n",
        "            all_graph_embeddings.append((graph_embedding.tolist(), y_label))\n",
        "\n",
        "    # Convert graph-level embeddings to DataFrame\n",
        "    df_graph_embeddings = pd.DataFrame(all_graph_embeddings, columns=[\"embedding\", \"label\"])\n",
        "\n",
        "    # Save the DataFrame to a CSV file (optional)\n",
        "    df_graph_embeddings.to_csv(\"graph_embeddings.csv\", index=False)\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df_graph_embeddings)\n"
      ],
      "metadata": {
        "id": "oEJnUWgaxksk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and evaluation of the Fully Connected model on the HOPE Embedding"
      ],
      "metadata": {
        "id": "pUizlSYAqyUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import ast\n",
        "\n",
        "\n",
        "# Extract features and labels\n",
        "def extract_features_labels(df):\n",
        "    embeddings = []\n",
        "    labels = df['label'].tolist()\n",
        "\n",
        "    for emb in df['embedding']:\n",
        "        if isinstance(emb, str):\n",
        "            # Convert string representation of list back to list\n",
        "            emb = ast.literal_eval(emb)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n",
        "\n",
        "# Assuming df_graph_embeddings is already defined and loaded\n",
        "X, y = extract_features_labels(df_graph_embeddings)\n",
        "\n",
        "# Check if data is loaded correctly\n",
        "if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "    raise ValueError(\"No valid embeddings found. Please check the DataFrame for formatting issues.\")\n",
        "\n",
        "# Define the neural network model\n",
        "def create_model(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Perform 5-fold cross-validation on the entire dataset\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "val_accuracies = []\n",
        "test_accuracies = []\n",
        "histories = []\n",
        "\n",
        "roc_aucs = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f'Fold {fold_no}')\n",
        "\n",
        "    X_train_val, X_test = X[train_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Perform an additional split to get a validation set from the training+validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Create and train the neural network\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = create_model(input_dim)\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f'Fold {fold_no} Validation Accuracy: {val_accuracy:.4f}')\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    histories.append(history.history)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Fold {fold_no} Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_proba = model.predict(X_test).flatten()\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # Compute and store metrics\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    roc_aucs.append(roc_auc)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Plot confusion matrix for each fold\n",
        "    plot_confusion_matrix(y_test, y_test_pred, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "    print(f'Fold {fold_no} ROC AUC: {roc_auc:.4f}')\n",
        "    print(f'Fold {fold_no} Precision: {precision:.4f}')\n",
        "    print(f'Fold {fold_no} Recall: {recall:.4f}')\n",
        "    print(f'Fold {fold_no} F1-Score: {f1:.4f}')\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Calculate and print the average metrics\n",
        "average_val_accuracy = np.mean(val_accuracies)\n",
        "variance_val_accuracy = np.var(val_accuracies)\n",
        "print(f'Average Validation Accuracy: {average_val_accuracy:.4f}')\n",
        "print(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}')\n",
        "\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "variance_test_accuracy = np.var(test_accuracies)\n",
        "print(f'Average Test Accuracy: {average_test_accuracy:.4f}')\n",
        "print(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}')\n",
        "\n",
        "average_roc_auc = np.mean(roc_aucs)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recall = np.mean(recalls)\n",
        "average_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f'Average ROC AUC: {average_roc_auc:.4f}')\n",
        "print(f'Average Precision: {average_precision:.4f}')\n",
        "print(f'Average Recall: {average_recall:.4f}')\n",
        "print(f'Average F1-Score: {average_f1:.4f}')\n",
        "\n",
        "# Save the average metrics to a file\n",
        "with open(\"model_accuracies.txt\", \"w\") as f:\n",
        "    f.write(f'Average Validation Accuracy: {average_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Validation Accuracy: {variance_val_accuracy:.4f}\\n')\n",
        "    f.write(f'Average Test Accuracy: {average_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Variance of Test Accuracy: {variance_test_accuracy:.4f}\\n')\n",
        "    f.write(f'Average ROC AUC: {average_roc_auc:.4f}\\n')\n",
        "    f.write(f'Average Precision: {average_precision:.4f}\\n')\n",
        "    f.write(f'Average Recall: {average_recall:.4f}\\n')\n",
        "    f.write(f'Average F1-Score: {average_f1:.4f}\\n')\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Save training history for each fold (optional)\n",
        "with open(\"training_histories.txt\", \"w\") as f:\n",
        "    for i, history in enumerate(histories):\n",
        "        f.write(f'\\nFold {i + 1} History:\\n')\n",
        "        f.write(str(history))\n"
      ],
      "metadata": {
        "id": "B6Zb2A9Q1QJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GNN"
      ],
      "metadata": {
        "id": "zLayspS9Mv_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg5yiVjbJkkI"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install torch_geometric\n",
        "!pip install ogb\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv, GINConv, global_mean_pool, global_add_pool, global_max_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import matplotlib\n",
        "from rdkit import Chem\n",
        "import pickle\n",
        "import torch_geometric\n",
        "import io  # Import io for in-memory file operations\n"
      ],
      "metadata": {
        "id": "LAFwe7CyXxxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models Definitions"
      ],
      "metadata": {
        "id": "K2sIuiYrq3ZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cells to define:\n",
        "\n",
        "\n",
        "*   GCN\n",
        "*   GIN\n",
        "*   GAT\n",
        "\n"
      ],
      "metadata": {
        "id": "fGFx9RRaQVHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9dF2Z8uJwPw"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 2)  # Output will be 2 classes\n",
        "\n",
        "        # Register hook on the last layer (conv3)\n",
        "        self.hook_handle = self.conv4.register_forward_hook(self._store_gradients)\n",
        "\n",
        "    def _store_gradients(self, module, input, output):\n",
        "        # Store gradients during forward pass\n",
        "        self.gradients = output\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = global_max_pool(x, batch)  # Global pooling\n",
        "        x = self.lin(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GATConv, global_max_pool\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_channels, heads=1)\n",
        "        self.conv2 = GATConv(hidden_channels, hidden_channels, heads=1)\n",
        "        self.conv3 = GATConv(hidden_channels, hidden_channels, heads=1)\n",
        "        self.conv4 = GATConv(hidden_channels, hidden_channels, heads=1)\n",
        "        self.lin = Linear(hidden_channels, 2)  # Output will be 2 classes\n",
        "\n",
        "        # Register hook on the last layer (conv3)\n",
        "        self.hook_handle = self.conv4.register_forward_hook(self._store_gradients)\n",
        "\n",
        "    def _store_gradients(self, module, input, output):\n",
        "        # Store gradients during forward pass\n",
        "        self.gradients = output\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = global_max_pool(x, batch)  # Global pooling\n",
        "        x = self.lin(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "O4-wM4JmKs1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GINConv, global_max_pool\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_channels):\n",
        "        super(GIN, self).__init__()\n",
        "        self.conv1 = GINConv(Linear(input_dim, hidden_channels))\n",
        "        self.conv2 = GINConv(Linear(hidden_channels, hidden_channels))\n",
        "        self.conv3 = GINConv(Linear(hidden_channels, hidden_channels))\n",
        "        self.conv4 = GINConv(Linear(hidden_channels, hidden_channels))\n",
        "        self.lin = Linear(hidden_channels, 2)  # Output will be 2 classes\n",
        "\n",
        "        # Register hook on the last layer (conv4)\n",
        "        self.hook_handle = self.conv4.register_forward_hook(self._store_gradients)\n",
        "\n",
        "    def _store_gradients(self, module, input, output):\n",
        "        # Store gradients during forward pass\n",
        "        self.gradients = output\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = global_max_pool(x, batch)  # Global pooling\n",
        "        x = self.lin(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "anlkMau5opFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train,Validation and Test function definitions"
      ],
      "metadata": {
        "id": "JOL3ZuCPq69X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Suw-k2LVJ8Pz"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x.float(), data.edge_index, data.batch)\n",
        "        loss = F.cross_entropy(out, data.y.view(-1).long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += int((pred == data.y.view(-1)).sum())\n",
        "        total += data.y.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            pred = model(data.x.float(), data.edge_index, data.batch)\n",
        "            pred = pred.argmax(dim=1)\n",
        "            correct += int((pred == data.y.view(-1)).sum())\n",
        "            total += data.y.size(0)\n",
        "            all_predictions.extend(pred.tolist())\n",
        "            all_labels.extend(data.y.view(-1).tolist())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy, all_predictions, all_labels\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_roc_auc(model, loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            pred = model(data.x.float(), data.edge_index, data.batch)\n",
        "            all_predictions.extend(pred[:, 1].cpu().numpy())\n",
        "            all_labels.extend(data.y.view(-1).cpu().numpy())\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels, all_predictions)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print('AUC:', roc_auc)\n",
        "    return roc_auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL3saI6HNKux"
      },
      "source": [
        "Methods for train and test the models:\n",
        "\n",
        "\n",
        "*   k fold balance\n",
        "*   k fold no balanced\n",
        "*   scatterfold balanced\n",
        "*   scatterfold no balanced\n",
        "\n",
        "The balance is based on the idea to train the model on a balanced dataset (the same number of elements for classes) or no balanced dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDVFiiQUJ45b"
      },
      "outputs": [],
      "source": [
        "def k_fold_balanced(data, num_classes, hidden_channels, iteration, k_folds, model_choosed):\n",
        "    all_best_train_acc = []\n",
        "    all_best_val_acc = []\n",
        "    all_auc = []\n",
        "    label_0_indices = []\n",
        "    label_1_indices = []\n",
        "    all_best_models = {'model':[], 'val_ACC': [], 'AUC':[]}\n",
        "\n",
        "    for i in range(len(data)):\n",
        "      if data[i].y == 0:\n",
        "        label_0_indices.append(i)\n",
        "      elif data[i].y == 1:\n",
        "        label_1_indices.append(i)\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    for iter in range(iteration):\n",
        "      all_data = copy.deepcopy(data)\n",
        "      print('iter:', iter)\n",
        "      # Define cross-validation settings\n",
        "      kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "      best_train_accuracies = []\n",
        "      best_val_accuracies = []\n",
        "      best_models = []\n",
        "\n",
        "      # Collect evaluation metrics for all folds\n",
        "      all_accuracies = []\n",
        "      all_precisions = []\n",
        "      all_recalls = []\n",
        "      all_f1_scores = []\n",
        "\n",
        "      min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "      random.shuffle(label_0_indices)\n",
        "      random.shuffle(label_1_indices)\n",
        "      label_0_indices = label_0_indices[:min_size_dataset]\n",
        "      label_1_indices = label_1_indices[:min_size_dataset]\n",
        "      print('size 0 data:' , len(label_0_indices))\n",
        "      print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "      balanced_indices = label_0_indices + label_1_indices\n",
        "      print('size total dataset:' , len(balanced_indices))\n",
        "\n",
        "      balanced_data = [all_data[i] for i in balanced_indices]\n",
        "      print(len(balanced_data))\n",
        "\n",
        "      for btd in balanced_data:\n",
        "       # Apply one-hot encoding for each column\n",
        "        one_hot_encoded = [F.one_hot(btd.x[:, i].long(), num_classes[i]) for i in range(btd.x.shape[1])]\n",
        "        one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "        btd.x = one_hot_encoded_tensor\n",
        "\n",
        "      # Training loop with cross-validation\n",
        "      for fold, (train_idx, val_idx) in enumerate(kf.split(balanced_indices)):\n",
        "          print(f\"Fold [{fold+1}/{k_folds}]\")\n",
        "          # Subset the data for this fold\n",
        "          train_data = [balanced_data[i] for i in train_idx]\n",
        "          val_data = [balanced_data[i] for i in val_idx]\n",
        "\n",
        "          train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "          val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "\n",
        "          total_features = sum(num_classes)\n",
        "          # Define the model with the correct input dimension\n",
        "          if model_choosed == 1:\n",
        "            model = GCN(total_features, hidden_channels=hidden_channels)\n",
        "          elif model_choosed == 2:\n",
        "            model = GIN(total_features, hidden_channels=hidden_channels)\n",
        "          elif model_choosed == 3:\n",
        "            model = GAT(total_features, hidden_channels=hidden_channels)\n",
        "\n",
        "          optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "          # Early stopping variables\n",
        "          best_val_acc = 0.0\n",
        "          best_train_acc = 0.0\n",
        "          patience = 25  # Stop after no improvement for 25 epochs\n",
        "          counter = 0\n",
        "\n",
        "          # Collect evaluation metrics for this fold\n",
        "          fold_accuracies = []\n",
        "          fold_precisions = []\n",
        "          fold_recalls = []\n",
        "          fold_f1_scores = []\n",
        "\n",
        "          # Training loop with validation and early stopping\n",
        "          for epoch in range(1, 200):  # Train for maximum 100 epochs\n",
        "              # Train the model and get train accuracy\n",
        "              train_acc = train(model, optimizer, train_loader)\n",
        "\n",
        "              # Validate the model\n",
        "              val_acc, _, _ = validate(model, val_loader)\n",
        "\n",
        "              print(f'Fold [{fold+1}/{k_folds}] Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "              # Check for improvement in validation accuracy\n",
        "              if val_acc > best_val_acc:\n",
        "                  best_val_acc = val_acc\n",
        "                  best_train_acc = train_acc\n",
        "                  counter = 0  # Reset counter\n",
        "              else:\n",
        "                  counter += 1  # No improvement, increase counter\n",
        "\n",
        "              # If no improvement for \"patience\" number of epochs, stop training\n",
        "              if counter >= patience:\n",
        "                  print(f'Fold [{fold+1}/{k_folds}] Early stopping at epoch {epoch}')\n",
        "                  break\n",
        "\n",
        "\n",
        "          # Store the best train and val accuracies for this fold\n",
        "          best_train_accuracies.append(best_train_acc)\n",
        "          best_val_accuracies.append(best_val_acc)\n",
        "          best_models.append(model)\n",
        "\n",
        "          # Append metrics for this fold\n",
        "          all_accuracies.append(fold_accuracies)\n",
        "          all_precisions.append(fold_precisions)\n",
        "          all_recalls.append(fold_recalls)\n",
        "          all_f1_scores.append(fold_f1_scores)\n",
        "\n",
        "          # Final evaluation on the test set\n",
        "          test_acc, all_test_predictions, all_test_labels = validate(model, val_loader)\n",
        "\n",
        "          print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "          # Convert predictions and labels to numpy arrays\n",
        "          all_test_predictions = np.array(all_test_predictions)\n",
        "          all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "          # Plot confusion matrix\n",
        "          plot_confusion_matrix(all_test_labels, all_test_predictions, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "\n",
        "          # Calculate True Positives (TP), False Positives (FP),\n",
        "          # True Negatives (TN), False Negatives (FN)\n",
        "          TP = np.sum((all_test_predictions == 1) & (all_test_labels == 1))\n",
        "          FP = np.sum((all_test_predictions == 1) & (all_test_labels == 0))\n",
        "          TN = np.sum((all_test_predictions == 0) & (all_test_labels == 0))\n",
        "          FN = np.sum((all_test_predictions == 0) & (all_test_labels == 1))\n",
        "\n",
        "          print(\"True Positives (TP):\", TP)\n",
        "          print(\"False Positives (FP):\", FP)\n",
        "          print(\"True Negatives (TN):\", TN)\n",
        "          print(\"False Negatives (FN):\", FN)\n",
        "\n",
        "          # Calculate accuracy, precision, recall, and F1-score\n",
        "          accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "          precision = TP / (TP + FP)\n",
        "          recall = TP / (TP + FN)\n",
        "          f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "          print(\"Accuracy:\", accuracy)\n",
        "          print(\"Precision:\", precision)\n",
        "          print(\"Recall:\", recall)\n",
        "          print(\"F1-Score:\", f1_score)\n",
        "\n",
        "          # Append metrics for this epoch\n",
        "          fold_accuracies.append(val_acc)\n",
        "          fold_precisions.append(precision)\n",
        "          fold_recalls.append(recall)\n",
        "          fold_f1_scores.append(f1_score)\n",
        "\n",
        "          all_best_models['model'].append(model)\n",
        "          all_best_models['val_ACC'].append(max(best_val_accuracies))\n",
        "          all_best_models['AUC'].append(evaluate_roc_auc(model, val_loader))\n",
        "\n",
        "      # Calculate median of best train and val accuracies\n",
        "      median_best_train_acc = np.median(best_train_accuracies)\n",
        "      median_best_val_acc = np.median(best_val_accuracies)\n",
        "      all_best_train_acc.append(median_best_train_acc)\n",
        "      all_best_val_acc.append(median_best_val_acc)\n",
        "\n",
        "      print(\"\\nMedian of Best Train Accuracies:\", median_best_train_acc)\n",
        "      print(\"Median of Best Validation Accuracies:\", median_best_val_acc)\n",
        "\n",
        "      # Compare median validation accuracies to choose the better model\n",
        "      if median_best_val_acc == max(median_best_train_acc, median_best_val_acc):\n",
        "          best_model_idx = best_val_accuracies.index(max(best_val_accuracies))\n",
        "      else:\n",
        "          best_model_idx = best_train_accuracies.index(max(best_train_accuracies))\n",
        "\n",
        "      best_model = best_models[best_model_idx]\n",
        "\n",
        "      # Calculate median of all metrics across all folds\n",
        "      median_accuracy = np.median(np.concatenate(all_accuracies))\n",
        "      median_precision = np.median(np.concatenate(all_precisions))\n",
        "      median_recall = np.median(np.concatenate(all_recalls))\n",
        "      median_f1_score = np.median(np.concatenate(all_f1_scores))\n",
        "\n",
        "      print(\"\\nMedian of All Accuracies:\", median_accuracy)\n",
        "      print(\"Median of All Precisions:\", median_precision)\n",
        "      print(\"Median of All Recalls:\", median_recall)\n",
        "      print(\"Median of All F1-Scores:\", median_f1_score)\n",
        "      print('\\n')\n",
        "\n",
        "    return all_best_models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_no_balanced(data, num_classes, hidden_channels, iteration, k_folds, model_choosed):\n",
        "    all_best_train_acc = []\n",
        "    all_best_val_acc = []\n",
        "    all_auc = []\n",
        "    label_0_indices = []\n",
        "    label_1_indices = []\n",
        "    all_best_models = {'model':[], 'val_ACC': [], 'AUC':[]}\n",
        "\n",
        "    for i in range(len(data)):\n",
        "      if data[i].y == 0:\n",
        "        label_0_indices.append(i)\n",
        "      elif data[i].y == 1:\n",
        "        label_1_indices.append(i)\n",
        "    print(len(label_0_indices))\n",
        "    print(len(label_1_indices))\n",
        "\n",
        "    for iter in range(iteration):\n",
        "      all_data = copy.deepcopy(data)\n",
        "      print('iter:', iter)\n",
        "      # Define cross-validation settings\n",
        "      kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "      best_train_accuracies = []\n",
        "      best_val_accuracies = []\n",
        "      best_models = []\n",
        "\n",
        "      # Collect evaluation metrics for all folds\n",
        "      all_accuracies = []\n",
        "      all_precisions = []\n",
        "      all_recalls = []\n",
        "      all_f1_scores = []\n",
        "\n",
        "      min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "      random.shuffle(label_0_indices)\n",
        "      random.shuffle(label_1_indices)\n",
        "      label_0_indices = label_0_indices[:]\n",
        "      label_1_indices = label_1_indices[:]\n",
        "      print('size 0 data:' , len(label_0_indices))\n",
        "      print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "      no_balanced_indices = label_0_indices + label_1_indices\n",
        "      print('size total dataset:' , len(no_balanced_indices))\n",
        "\n",
        "      no_balanced_data = [all_data[i] for i in no_balanced_indices]\n",
        "      print(len(no_balanced_data))\n",
        "\n",
        "      for btd in no_balanced_data:\n",
        "       # Apply one-hot encoding for each column\n",
        "        one_hot_encoded = [F.one_hot(btd.x[:, i].long(), num_classes[i]) for i in range(btd.x.shape[1])]\n",
        "        one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "        btd.x = one_hot_encoded_tensor\n",
        "\n",
        "      # Training loop with cross-validation\n",
        "      for fold, (train_idx, val_idx) in enumerate(kf.split(no_balanced_indices)):\n",
        "          print(f\"Fold [{fold+1}/{k_folds}]\")\n",
        "          # Subset the data for this fold\n",
        "          train_data = [no_balanced_data[i] for i in train_idx]\n",
        "          val_data = [no_balanced_data[i] for i in val_idx]\n",
        "\n",
        "          train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "          val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "\n",
        "          total_features = sum(num_classes)\n",
        "          # Define the model with the correct input dimension\n",
        "          if model_choosed == 1:\n",
        "            model = GCN(total_features, hidden_channels=hidden_channels)\n",
        "          elif model_choosed == 2:\n",
        "            model = GIN(total_features, hidden_channels=hidden_channels)\n",
        "          elif model_choosed == 3:\n",
        "            model = GAT(total_features, hidden_channels=hidden_channels)\n",
        "\n",
        "          optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "          # Early stopping variables\n",
        "          best_val_acc = 0.0\n",
        "          best_train_acc = 0.0\n",
        "          patience = 25  # Stop after no improvement for 25 epochs\n",
        "          counter = 0\n",
        "\n",
        "          # Collect evaluation metrics for this fold\n",
        "          fold_accuracies = []\n",
        "          fold_precisions = []\n",
        "          fold_recalls = []\n",
        "          fold_f1_scores = []\n",
        "\n",
        "          # Training loop with validation and early stopping\n",
        "          for epoch in range(1, 200):  # Train for maximum 100 epochs\n",
        "              # Train the model and get train accuracy\n",
        "              train_acc = train(model, optimizer, train_loader)\n",
        "\n",
        "              # Validate the model\n",
        "              val_acc, _, _ = validate(model, val_loader)\n",
        "\n",
        "              print(f'Fold [{fold+1}/{k_folds}] Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "              # Check for improvement in validation accuracy\n",
        "              if val_acc > best_val_acc:\n",
        "                  best_val_acc = val_acc\n",
        "                  best_train_acc = train_acc\n",
        "                  counter = 0  # Reset counter\n",
        "              else:\n",
        "                  counter += 1  # No improvement, increase counter\n",
        "\n",
        "              # If no improvement for \"patience\" number of epochs, stop training\n",
        "              if counter >= patience:\n",
        "                  print(f'Fold [{fold+1}/{k_folds}] Early stopping at epoch {epoch}')\n",
        "                  break\n",
        "\n",
        "\n",
        "          # Store the best train and val accuracies for this fold\n",
        "          best_train_accuracies.append(best_train_acc)\n",
        "          best_val_accuracies.append(best_val_acc)\n",
        "          best_models.append(model)\n",
        "\n",
        "          # Append metrics for this fold\n",
        "          all_accuracies.append(fold_accuracies)\n",
        "          all_precisions.append(fold_precisions)\n",
        "          all_recalls.append(fold_recalls)\n",
        "          all_f1_scores.append(fold_f1_scores)\n",
        "\n",
        "          # Final evaluation on the test set\n",
        "          test_acc, all_test_predictions, all_test_labels = validate(model, val_loader)\n",
        "\n",
        "          print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "          # Convert predictions and labels to numpy arrays\n",
        "          all_test_predictions = np.array(all_test_predictions)\n",
        "          all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "          # Plot confusion matrix\n",
        "          plot_confusion_matrix(all_test_labels, all_test_predictions, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "\n",
        "          # Calculate True Positives (TP), False Positives (FP),\n",
        "          # True Negatives (TN), False Negatives (FN)\n",
        "          TP = np.sum((all_test_predictions == 1) & (all_test_labels == 1))\n",
        "          FP = np.sum((all_test_predictions == 1) & (all_test_labels == 0))\n",
        "          TN = np.sum((all_test_predictions == 0) & (all_test_labels == 0))\n",
        "          FN = np.sum((all_test_predictions == 0) & (all_test_labels == 1))\n",
        "\n",
        "          print(\"True Positives (TP):\", TP)\n",
        "          print(\"False Positives (FP):\", FP)\n",
        "          print(\"True Negatives (TN):\", TN)\n",
        "          print(\"False Negatives (FN):\", FN)\n",
        "\n",
        "          # Calculate accuracy, precision, recall, and F1-score\n",
        "          accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "          precision = TP / (TP + FP)\n",
        "          recall = TP / (TP + FN)\n",
        "          f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "          print(\"Accuracy:\", accuracy)\n",
        "          print(\"Precision:\", precision)\n",
        "          print(\"Recall:\", recall)\n",
        "          print(\"F1-Score:\", f1_score)\n",
        "\n",
        "          # Append metrics for this epoch\n",
        "          fold_accuracies.append(val_acc)\n",
        "          fold_precisions.append(precision)\n",
        "          fold_recalls.append(recall)\n",
        "          fold_f1_scores.append(f1_score)\n",
        "\n",
        "          all_best_models['model'].append(model)\n",
        "          all_best_models['val_ACC'].append(max(best_val_accuracies))\n",
        "          all_best_models['AUC'].append(evaluate_roc_auc(model, val_loader))\n",
        "\n",
        "      # Calculate median of best train and val accuracies\n",
        "      median_best_train_acc = np.median(best_train_accuracies)\n",
        "      median_best_val_acc = np.median(best_val_accuracies)\n",
        "      all_best_train_acc.append(median_best_train_acc)\n",
        "      all_best_val_acc.append(median_best_val_acc)\n",
        "\n",
        "      print(\"\\nMedian of Best Train Accuracies:\", median_best_train_acc)\n",
        "      print(\"Median of Best Validation Accuracies:\", median_best_val_acc)\n",
        "\n",
        "      # Compare median validation accuracies to choose the better model\n",
        "      if median_best_val_acc == max(median_best_train_acc, median_best_val_acc):\n",
        "          best_model_idx = best_val_accuracies.index(max(best_val_accuracies))\n",
        "      else:\n",
        "          best_model_idx = best_train_accuracies.index(max(best_train_accuracies))\n",
        "\n",
        "      best_model = best_models[best_model_idx]\n",
        "\n",
        "      # Calculate median of all metrics across all folds\n",
        "      median_accuracy = np.median(np.concatenate(all_accuracies))\n",
        "      median_precision = np.median(np.concatenate(all_precisions))\n",
        "      median_recall = np.median(np.concatenate(all_recalls))\n",
        "      median_f1_score = np.median(np.concatenate(all_f1_scores))\n",
        "\n",
        "      print(\"\\nMedian of All Accuracies:\", median_accuracy)\n",
        "      print(\"Median of All Precisions:\", median_precision)\n",
        "      print(\"Median of All Recalls:\", median_recall)\n",
        "      print(\"Median of All F1-Scores:\", median_f1_score)\n",
        "      print('\\n')\n",
        "\n",
        "    return all_best_models"
      ],
      "metadata": {
        "id": "yuLFZ57TJe5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def no_balanced_scatterfold(data, num_classes, hidden_channels,model_choosed):\n",
        "    all_best_train_acc = []\n",
        "    all_best_val_acc = []\n",
        "    all_auc = []\n",
        "    all_best_models = {'model':[], 'val_ACC': [], 'AUC':[]}\n",
        "\n",
        "    for iter in range(1):\n",
        "        all_data = copy.deepcopy(data)\n",
        "        print('iter:', iter)\n",
        "        print(all_data[1].x.shape[1])\n",
        "        balanced_data = [all_data[i] for i in range(len(all_data))]\n",
        "        # One-hot encode the features\n",
        "        for btd in balanced_data:\n",
        "            one_hot_encoded = [F.one_hot(btd.x[:, i].long(), num_classes[i]) for i in range(btd.x.shape[1])]\n",
        "            one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "            btd.x = one_hot_encoded_tensor\n",
        "\n",
        "        # Split the data into training (80%), validation (20%), and test (20%) sets\n",
        "        train_val_data, test_data = train_test_split(balanced_data, test_size=0.2, random_state=42)\n",
        "        train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=42) # 0.25 * 0.8 = 0.2\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "        val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "        total_features = sum(num_classes)\n",
        "        if model_choosed == 1:\n",
        "            model = GCN(total_features, hidden_channels=hidden_channels)\n",
        "        elif model_choosed == 2:\n",
        "            model = GIN(total_features, hidden_channels=hidden_channels)\n",
        "        elif model_choosed == 3:\n",
        "            model = GAT(total_features, hidden_channels=hidden_channels)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "        best_train_acc = 0.0\n",
        "        patience = 25\n",
        "        counter = 0\n",
        "\n",
        "        for epoch in range(1, 200):\n",
        "            train_acc = train(model, optimizer, train_loader)\n",
        "            val_acc, _, _ = validate(model, val_loader)\n",
        "\n",
        "            print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_train_acc = train_acc\n",
        "                counter = 0\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "            if counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch}')\n",
        "                break\n",
        "\n",
        "        test_acc, all_test_predictions, all_test_labels = validate(model, test_loader)\n",
        "\n",
        "        print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "        all_test_predictions = np.array(all_test_predictions)\n",
        "        all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plot_confusion_matrix(all_test_labels, all_test_predictions, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "\n",
        "        TP = np.sum((all_test_predictions == 1) & (all_test_labels == 1))\n",
        "        FP = np.sum((all_test_predictions == 1) & (all_test_labels == 0))\n",
        "        TN = np.sum((all_test_predictions == 0) & (all_test_labels == 0))\n",
        "        FN = np.sum((all_test_predictions == 0) & (all_test_labels == 1))\n",
        "\n",
        "        accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"F1-Score:\", f1_score)\n",
        "\n",
        "        all_best_models['model'].append(model)\n",
        "        all_best_models['val_ACC'].append(best_val_acc)\n",
        "        all_best_models['AUC'].append(evaluate_roc_auc(model, val_loader))\n",
        "\n",
        "        all_best_train_acc.append(best_train_acc)\n",
        "        all_best_val_acc.append(best_val_acc)\n",
        "\n",
        "    return all_best_models"
      ],
      "metadata": {
        "id": "eLJryDstwyMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balanced_scatterfold(data, num_classes, hidden_channels,model_choosed):\n",
        "    all_best_train_acc = []\n",
        "    all_best_val_acc = []\n",
        "    all_auc = []\n",
        "    all_best_models = {'model':[], 'val_ACC': [], 'AUC':[]}\n",
        "    label_0_indices = []\n",
        "    label_1_indices = []\n",
        "    for i in range(len(data)):\n",
        "      if data[i].y == 0:\n",
        "        label_0_indices.append(i)\n",
        "      elif data[i].y == 1:\n",
        "        label_1_indices.append(i)\n",
        "\n",
        "    for iter in range(1):\n",
        "      all_data = copy.deepcopy(data)\n",
        "\n",
        "      print('iter:', iter)\n",
        "      print(all_data[1].x.shape[1])\n",
        "      min_size_dataset = min(len(label_0_indices), len(label_1_indices))\n",
        "\n",
        "      random.shuffle(label_0_indices)\n",
        "      random.shuffle(label_1_indices)\n",
        "      label_0_indices = label_0_indices[:min_size_dataset]\n",
        "      label_1_indices = label_1_indices[:min_size_dataset]\n",
        "      print('size 0 data:' , len(label_0_indices))\n",
        "      print('size 1 data:', len(label_1_indices))\n",
        "\n",
        "      balanced_indices = label_0_indices + label_1_indices\n",
        "      print('size total dataset:' , len(balanced_indices))\n",
        "\n",
        "      balanced_data = [all_data[i] for i in balanced_indices]\n",
        "      print(len(balanced_data))\n",
        "        #balanced_data = [all_data[i] for i in range(len(all_data))]\n",
        "        # One-hot encode the features\n",
        "      for btd in balanced_data:\n",
        "            one_hot_encoded = [F.one_hot(btd.x[:, i].long(), num_classes[i]) for i in range(btd.x.shape[1])]\n",
        "            one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "            btd.x = one_hot_encoded_tensor\n",
        "\n",
        "      # Split the data into training (80%), validation (20%), and test (20%) sets\n",
        "      train_val_data, test_data = train_test_split(balanced_data, test_size=0.2, random_state=42)\n",
        "      train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=42) # 0.25 * 0.8 = 0.2\n",
        "\n",
        "      train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "      val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "      test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "      total_features = sum(num_classes)\n",
        "      if model_choosed == 1:\n",
        "        model = GCN(total_features, hidden_channels=hidden_channels)\n",
        "      elif model_choosed == 2:\n",
        "        model = GIN(total_features, hidden_channels=hidden_channels)\n",
        "      elif model_choosed == 3:\n",
        "            model = GAT(total_features, hidden_channels=hidden_channels)\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "      best_val_acc = 0.0\n",
        "      best_train_acc = 0.0\n",
        "      patience = 25\n",
        "      counter = 0\n",
        "\n",
        "      for epoch in range(1, 200):\n",
        "        train_acc = train(model, optimizer, train_loader)\n",
        "        val_acc, _, _ = validate(model, val_loader)\n",
        "\n",
        "        print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          best_train_acc = train_acc\n",
        "          counter = 0\n",
        "        else:\n",
        "          counter += 1\n",
        "\n",
        "        if counter >= patience:\n",
        "          print(f'Early stopping at epoch {epoch}')\n",
        "          break\n",
        "\n",
        "      test_acc, all_test_predictions, all_test_labels = validate(model, test_loader)\n",
        "\n",
        "      print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "      all_test_predictions = np.array(all_test_predictions)\n",
        "      all_test_labels = np.array(all_test_labels)\n",
        "\n",
        "      # Plot confusion matrix\n",
        "      plot_confusion_matrix(all_test_labels, all_test_predictions, class_names=['Class 0', 'Class 1'])\n",
        "\n",
        "\n",
        "      TP = np.sum((all_test_predictions == 1) & (all_test_labels == 1))\n",
        "      FP = np.sum((all_test_predictions == 1) & (all_test_labels == 0))\n",
        "      TN = np.sum((all_test_predictions == 0) & (all_test_labels == 0))\n",
        "      FN = np.sum((all_test_predictions == 0) & (all_test_labels == 1))\n",
        "\n",
        "      accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "      precision = TP / (TP + FP)\n",
        "      recall = TP / (TP + FN)\n",
        "      f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "      print(\"Accuracy:\", accuracy)\n",
        "      print(\"Precision:\", precision)\n",
        "      print(\"Recall:\", recall)\n",
        "      print(\"F1-Score:\", f1_score)\n",
        "\n",
        "      all_best_models['model'].append(model)\n",
        "      all_best_models['val_ACC'].append(best_val_acc)\n",
        "      all_best_models['AUC'].append(evaluate_roc_auc(model, val_loader))\n",
        "\n",
        "      all_best_train_acc.append(best_train_acc)\n",
        "      all_best_val_acc.append(best_val_acc)\n",
        "\n",
        "    return all_best_models"
      ],
      "metadata": {
        "id": "WG7aVDFFOBh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKBqFUUxKVcg"
      },
      "source": [
        "Evaluation of the models with extraction of the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxaioY-cKUgB"
      },
      "outputs": [],
      "source": [
        "def extract_metrics_and_best_model(all_best_models):\n",
        "  max_auc_index = all_best_models['AUC'].index(max(all_best_models['AUC']))\n",
        "  # Print the index and corresponding AUC value\n",
        "  print(\"Index of Max AUC:\", max_auc_index)\n",
        "  print(\"Max AUC Value:\", max(all_best_models['AUC']))\n",
        "  mean_auc = np.mean(all_best_models['AUC'])\n",
        "  std_auc = np.std(all_best_models['AUC'])\n",
        "\n",
        "  # Print the results\n",
        "  print(\"Mean AUC Value:\", mean_auc)\n",
        "  print(\"Standard Deviation AUC:\", std_auc)\n",
        "\n",
        "  best_model = all_best_models['model'][max_auc_index]\n",
        "\n",
        "  return best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Molecular Plotting with the node importance calculated using the gradient from the model\n",
        "\n"
      ],
      "metadata": {
        "id": "urrx3ZxRr7K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import io\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit import Chem\n",
        "from IPython.display import display, Image as IPImage\n",
        "\n",
        "def plot_graph_feature_importance(data, num_classes, best_model):\n",
        "    tp = Chem.GetPeriodicTable()\n",
        "    cp_data = copy.deepcopy(data)\n",
        "    best_model.eval()\n",
        "    elements = {}\n",
        "    for i in range(data.num_nodes):\n",
        "        first_element_int = int(data.x[i][0].item())\n",
        "        elements[i] = tp.GetElementSymbol(first_element_int)\n",
        "\n",
        "    one_hot_encoded = [F.one_hot(cp_data.x[:, j].long(), num_classes[j]) for j in range(cp_data.x.shape[1])]\n",
        "    one_hot_encoded_tensor = torch.cat(one_hot_encoded, dim=-1)\n",
        "    cp_data.x = one_hot_encoded_tensor\n",
        "\n",
        "    # Forward pass to get the model output\n",
        "    output = best_model(cp_data.x.float(), cp_data.edge_index, cp_data.batch)\n",
        "\n",
        "    # Compute node importance scores\n",
        "    node_importance = best_model.gradients.norm(dim=1)\n",
        "\n",
        "    # Convert PyTorch tensor to numpy array for visualization\n",
        "    node_importance_np = node_importance.detach().numpy()\n",
        "\n",
        "    # Print node importance scores\n",
        "    #print(\"Node importance scores (raw):\", node_importance_np)\n",
        "\n",
        "    # Normalize importance scores for coloring\n",
        "    max_importance = max(node_importance_np) if len(node_importance_np) > 0 else 1\n",
        "    min_importance = min(node_importance_np) if len(node_importance_np) > 0 else 0\n",
        "    normalized_importance = (node_importance_np - min_importance) / (max_importance - min_importance + 1e-6)  # Add small epsilon to avoid division by zero\n",
        "\n",
        "    # Print normalized importance scores\n",
        "    #print(\"Node importance scores (normalized):\", normalized_importance)\n",
        "\n",
        "    # Create a NetworkX graph from edge_index\n",
        "    G = nx.Graph()\n",
        "    G.add_edges_from(cp_data.edge_index.T.numpy())\n",
        "\n",
        "    # Create a mapping from node indices to their importance scores\n",
        "    node_importance_dict = {i: importance for i, importance in enumerate(normalized_importance)}\n",
        "\n",
        "    '''\n",
        "    # Define colors based on node importance (red scale)\n",
        "    node_colors = [node_importance_dict[i] for i in range(len(G.nodes))]\n",
        "    cmap = matplotlib.colormaps['Reds']\n",
        "\n",
        "    # Determine node size based on importance (larger for higher importance)\n",
        "    node_sizes = [2000 * importance for importance in normalized_importance]\n",
        "\n",
        "    # Draw the graph with node labels and adjusted node sizes\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    pos = nx.spring_layout(G, seed=42)  # Positions for all nodes\n",
        "    nodes = nx.draw_networkx_nodes(G, pos, node_color=node_colors, cmap=cmap, node_size=node_sizes)\n",
        "    edges = nx.draw_networkx_edges(G, pos, edgelist=G.edges, alpha=0.5)\n",
        "    node_labels = nx.draw_networkx_labels(G, pos, labels=elements, font_size=10, font_color='white')\n",
        "    for _, text in node_labels.items():\n",
        "        text.set_bbox(dict(facecolor='none', edgecolor='none'))  # No box around labels\n",
        "    plt.colorbar(nodes, label='Node Importance', orientation='vertical')\n",
        "    plt.title('Graph with Node Importance')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    '''\n",
        "    return elements, node_importance_dict\n",
        "\n",
        "def visualize_molecular_graph(smiles, elements, node_importance_dict):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(\"Invalid SMILES string\")\n",
        "\n",
        "    # Create a list of atom importance scores\n",
        "    atom_importance = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        idx = atom.GetIdx()\n",
        "        atom_importance.append(node_importance_dict[idx] if idx in node_importance_dict else 0)\n",
        "\n",
        "    # Normalize importance scores for coloring\n",
        "    max_importance = max(atom_importance) if atom_importance else 1\n",
        "    min_importance = min(atom_importance) if atom_importance else 0\n",
        "    normalized_importance = [(score - min_importance) / (max_importance - min_importance + 1e-6) for score in atom_importance]\n",
        "\n",
        "    '''\n",
        "    # Print atom importance scores\n",
        "    print(\"Atom importance scores (raw):\", atom_importance)\n",
        "    print(\"Atom importance scores (normalized):\", normalized_importance)\n",
        "    '''\n",
        "    # Define the color map and normalize\n",
        "    cmap = plt.get_cmap('Reds')\n",
        "    norm = mcolors.Normalize(vmin=0, vmax=1)\n",
        "\n",
        "    # Create a dictionary of highlight colors for atoms\n",
        "    highlight_atom_colors = {}\n",
        "    for i, atom in enumerate(mol.GetAtoms()):\n",
        "        color = cmap(norm(normalized_importance[i]))\n",
        "        highlight_atom_colors[atom.GetIdx()] = (float(color[0]), float(color[1]), float(color[2]))\n",
        "\n",
        "    # Draw the molecule with highlighted atoms\n",
        "    drawer = Draw.MolDraw2DCairo(300, 300)\n",
        "    opts = drawer.drawOptions()\n",
        "    for i, atom in enumerate(mol.GetAtoms()):\n",
        "        opts.atomLabels[atom.GetIdx()] = elements[atom.GetIdx()]\n",
        "\n",
        "    drawer.DrawMolecule(mol, highlightAtoms=[atom.GetIdx() for atom in mol.GetAtoms()], highlightAtomColors=highlight_atom_colors)\n",
        "    drawer.FinishDrawing()\n",
        "\n",
        "    # Convert to PIL image\n",
        "    img_data = drawer.GetDrawingText()\n",
        "    img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "    # Display image in Colab\n",
        "    display(IPImage(img_data))\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "xdd6xVh6JtxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot confusion matrix"
      ],
      "metadata": {
        "id": "dIKx-_E-sTFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
        "    \"\"\"\n",
        "    Plots the confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (list or array): True labels.\n",
        "    y_pred (list or array): Predicted labels.\n",
        "    class_names (list): List of class names. If None, integer labels are used.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# y_true = [0, 1, 1, 0, 1, 0]\n",
        "# y_pred = [0, 1, 0, 0, 1, 1]\n",
        "# class_names = ['Class 0', 'Class 1']\n",
        "# plot_confusion_matrix(y_true, y_pred, class_names)\n"
      ],
      "metadata": {
        "id": "wOTT35pUsSJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0aDjkUbK4Aa"
      },
      "source": [
        "> **MAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load HIV dataset from OGBG"
      ],
      "metadata": {
        "id": "30sSgvrdrUGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#graphs-datasets/PROTEINS\n",
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
        "#qua sta anche clintox e altri vedere bene documntazione però il codice funziona anche con uun proprio dataset, però il clintox ha la y diversa dalla nostra quindi in molti casi conviene avere a che fare con db propri, dove settiamo noi la y per bene e usiamo lo script SMILEs-MOL-OGB\n",
        "data = dataset[:]"
      ],
      "metadata": {
        "id": "i8SfGdZGaZSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load dataset from local or drive"
      ],
      "metadata": {
        "id": "oDlclDM2rXyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/exp_datasets/clintox.pt', 'rb') as f:\n",
        "    all_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "mfEq25K0LRtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset in csv format can be found into the *Platform/datasets/* folder"
      ],
      "metadata": {
        "id": "15tqrGU7o0gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/clintox_dataset.csv')\n",
        "smiles_list = df['smiles'].tolist()"
      ],
      "metadata": {
        "id": "DQ3bjznPK-Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqvLH_Z_K6G1"
      },
      "outputs": [],
      "source": [
        "num_classes = [119, 5, 12, 12, 9, 6, 6, 2, 2]\n",
        "hidden_channels = 70\n",
        "#you can choose between: k_fold_balanced,k_fold_no_balance,balanced_scatterfold,no_balanced_scatterfold\n",
        "all_best_models = balanced_scatterfold(data, num_classes, hidden_channels,3)\n",
        "best_model = extract_metrics_and_best_model(all_best_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To depict the molecule with the node importance is important to extract the SMILES string in order to use the model to extract the *node_importance_dict*\n",
        "\n",
        "For this reason the dataset in csv format that is possible to find in *Platform/datasets* can be used to extract the SMILES list"
      ],
      "metadata": {
        "id": "cKfIlOaIm--E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_index = 16\n",
        "smiles = smiles_list[data_index]\n",
        "elements, node_importance_dict = plot_graph_feature_importance(data[data_index], num_classes, best_model)\n",
        "img = visualize_molecular_graph(smiles, elements, node_importance_dict)"
      ],
      "metadata": {
        "id": "grFW5TY3XjpJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
