{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2Z2nD-1JDvI"
      },
      "outputs": [],
      "source": [
        "!pip install Flask\n",
        "!pip install pyngrok\n",
        "!pip install rdkit\n",
        "!pip install torch_geometric\n",
        "!pip install ogb\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Authtoken ngronk](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "If u are running this code on Colab u need a ngrok authtoken"
      ],
      "metadata": {
        "id": "nLwcCguUROjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# Replace 'your-auth-token' with your actual ngrok auth token\n",
        "ngrok.set_auth_token(\"2hzxS76lhN6xT0gz4pZbFvRxy8V_728ggUQRoa9P7Sa9cacha\")"
      ],
      "metadata": {
        "id": "ueMUaFveJhw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN"
      ],
      "metadata": {
        "id": "ChMQceFttXPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template, jsonify\n",
        "from werkzeug.utils import secure_filename\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "import torch.nn.functional as F\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Use Agg backend for Matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    from pyngrok import ngrok\n",
        "    COLAB = True\n",
        "except ImportError:\n",
        "    COLAB = False\n",
        "\n",
        "# Add the path to the directory containing the Python script\n",
        "if COLAB:\n",
        "    sys.path.append('/content/Platform/scriptSAR')\n",
        "else:\n",
        "    sys.path.append('/path/to/your/local/Platform/scriptSAR')\n",
        "\n",
        "# Import the functions from the script\n",
        "from smiles2mol_script import process_SMILES_df, save_pickle\n",
        "from SAR_functions_scripts import load_pickle_file, extract_best_model, extract_metrics, plot_graph_feature_importance, visualize_molecular_graph\n",
        "from SAR_functions_scripts import k_fold_balanced, k_fold_no_balanced, no_balanced_scatterfold, balanced_scatterfold\n",
        "\n",
        "# Initialize Flask app\n",
        "if COLAB:\n",
        "    app = Flask(__name__, template_folder='/content/Platform/templatesSARFlaskApp')\n",
        "    app.config['UPLOAD_FOLDER'] = '/content/uploads'\n",
        "else:\n",
        "    app = Flask(__name__, template_folder='./templatesSARFlaskApp')  # Adjust the template folder path if necessary\n",
        "    app.config['UPLOAD_FOLDER'] = './uploads'  # Adjust the upload folder path if necessary\n",
        "\n",
        "os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n",
        "\n",
        "# Global variables to track progress and data\n",
        "progress_status = {\n",
        "    \"status\": \"idle\",\n",
        "    \"progress\": 0,\n",
        "    \"message\": \"\"\n",
        "}\n",
        "data = None  # To store processed data\n",
        "smiles_list = None  # To store SMILES strings\n",
        "target_list = None  # To store target values\n",
        "\n",
        "# Define the processing function using the imported function\n",
        "def process_smiles_dataset(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    processed_df = process_SMILES_df(df)\n",
        "    return processed_df, df['smiles'].tolist(), df['target'].tolist()\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('upload.html')\n",
        "\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    if 'file' not in request.files:\n",
        "        return \"No file part\", 400\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        return \"No selected file\", 400\n",
        "    if file:\n",
        "        filename = secure_filename(file.filename)\n",
        "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "        file.save(file_path)\n",
        "        processed_df, smiles, targets = process_smiles_dataset(file_path)\n",
        "\n",
        "        # Instead of saving to a pickle, directly process the DataFrame\n",
        "        global data  # Use a global variable to store the processed data\n",
        "        global smiles_list  # Use a global variable to store the SMILES strings\n",
        "        global target_list  # Use a global variable to store the target values\n",
        "        data = processed_df\n",
        "        smiles_list = smiles\n",
        "        target_list = targets\n",
        "\n",
        "        return \"File processed successfully. You can now select a method and model variable for further processing.\"\n",
        "\n",
        "@app.route('/process', methods=['POST'])\n",
        "def process_data():\n",
        "    method = request.form['method']\n",
        "    model_var = int(request.form['model_var'])\n",
        "    k_value = int(request.form['k_value'])\n",
        "    iteration = int(request.form['iteration'])\n",
        "\n",
        "    # Use the globally stored data\n",
        "    if data is None:\n",
        "        return \"No data available. Please upload and process a SMILES dataset first.\", 400\n",
        "\n",
        "    # Update progress status\n",
        "    global progress_status\n",
        "    progress_status[\"status\"] = \"processing\"\n",
        "    progress_status[\"progress\"] = 0\n",
        "    progress_status[\"message\"] = \"Training started\"\n",
        "\n",
        "    # Assuming the functions and their required parameters are correctly set\n",
        "    num_features = [119, 5, 12, 12, 9, 6, 6, 2, 2]\n",
        "    hidden_channels = 70\n",
        "\n",
        "    if method == \"balanced_scatterfold\":\n",
        "        all_best_models = balanced_scatterfold(data, num_features, hidden_channels, model_var)\n",
        "    elif method == \"no_balanced_scatterfold\":\n",
        "        all_best_models = no_balanced_scatterfold(data, num_features, hidden_channels, model_var)\n",
        "    elif method == \"k_fold_balanced\":\n",
        "        all_best_models = k_fold_balanced(data, num_features, hidden_channels, iteration, k_value, model_var)\n",
        "    elif method == \"k_fold_no_balanced\":\n",
        "        all_best_models = k_fold_no_balanced(data, num_features, hidden_channels, iteration, k_value, model_var)\n",
        "    else:\n",
        "        progress_status[\"status\"] = \"idle\"\n",
        "        return \"Invalid method selected.\", 400\n",
        "\n",
        "    global best_model  # Use a global variable to store the best model\n",
        "    best_model = extract_best_model(all_best_models)\n",
        "    max_auc, mean_auc, std_auc = extract_metrics(all_best_models)\n",
        "\n",
        "    # Update progress status to complete\n",
        "    progress_status[\"status\"] = \"complete\"\n",
        "    progress_status[\"progress\"] = 100\n",
        "    progress_status[\"message\"] = \"Training complete\"\n",
        "\n",
        "    return jsonify({\n",
        "        \"message\": \"Data processed successfully using {}. You can now plot the graph using the best model.\".format(method),\n",
        "        \"max_auc\": max_auc,\n",
        "        \"mean_auc\": mean_auc,\n",
        "        \"std_auc\": std_auc\n",
        "    })\n",
        "\n",
        "@app.route('/progress', methods=['GET'])\n",
        "def get_progress():\n",
        "    global progress_status\n",
        "    return jsonify(progress_status)\n",
        "\n",
        "@app.route('/visualize', methods=['POST'])\n",
        "def visualize_molecular_graph_route():\n",
        "    smiles = request.form['smiles']\n",
        "\n",
        "    if smiles not in smiles_list:\n",
        "        return \"SMILES string not found in the dataset\", 400\n",
        "\n",
        "    data_index = smiles_list.index(smiles)\n",
        "    num_features = [119, 5, 12, 12, 9, 6, 6, 2, 2]\n",
        "\n",
        "    # Use the globally stored data\n",
        "    if data is None:\n",
        "        return \"No data available. Please upload and process a SMILES dataset first.\", 400\n",
        "\n",
        "    # Use the globally stored best model\n",
        "    if best_model is None:\n",
        "        return \"No best model available. Please process the data first.\", 400\n",
        "\n",
        "    # Compute feature importance and elements\n",
        "    elements, node_importance_dict = plot_graph_feature_importance(data[data_index], num_features, best_model)\n",
        "\n",
        "    # Get the target value\n",
        "    target_value = target_list[data_index]\n",
        "\n",
        "    # Visualize the molecular graph with scaled node importance\n",
        "    img = visualize_molecular_graph(smiles, elements, node_importance_dict)\n",
        "\n",
        "    # Save image to a BytesIO object\n",
        "    buf = io.BytesIO()\n",
        "    img.save(buf, format='PNG')\n",
        "    buf.seek(0)\n",
        "\n",
        "    # Encode plot to base64\n",
        "    mol_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "    buf.close()\n",
        "\n",
        "    return jsonify({'image': mol_base64, 'target': target_value})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = None  # Initialize the global variable to store processed data\n",
        "    smiles_list = None  # Initialize the global variable to store SMILES strings\n",
        "    target_list = None  # Initialize the global variable to store target values\n",
        "    best_model = None  # Initialize the global variable to store the best model\n",
        "    if COLAB:\n",
        "        public_url = ngrok.connect(5000)\n",
        "        print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:5000\\\"\".format(public_url))\n",
        "        app.run(host=\"0.0.0.0\", port=5000)\n",
        "    else:\n",
        "        app.run(host=\"127.0.0.1\", port=5000)\n"
      ],
      "metadata": {
        "id": "V-bg1YKqtOWc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}